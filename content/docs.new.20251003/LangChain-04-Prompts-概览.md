# LangChain-04-Prompts-æ¦‚è§ˆ

## æ¨¡å—åŸºæœ¬ä¿¡æ¯

**æ¨¡å—åç§°**: langchain-core-prompts
**æ¨¡å—è·¯å¾„**: `libs/core/langchain_core/prompts/`
**æ ¸å¿ƒèŒè´£**: æä¾›çµæ´»çš„æç¤ºè¯æ¨¡æ¿ç³»ç»Ÿï¼Œæ”¯æŒå˜é‡æ’å€¼ã€æ¶ˆæ¯æ„å»ºã€å°‘æ ·æœ¬å­¦ä¹ ç­‰åŠŸèƒ½

## 1. æ¨¡å—èŒè´£

### 1.1 æ ¸å¿ƒèŒè´£

Prompts æ¨¡å—æ˜¯ LangChain åº”ç”¨çš„å…¥å£ï¼Œæä¾›ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

1. **æ¨¡æ¿å®šä¹‰**: æ”¯æŒ f-stringã€Jinja2ã€Mustache ä¸‰ç§æ¨¡æ¿è¯­æ³•
2. **å˜é‡æ’å€¼**: åŠ¨æ€æ’å…¥å˜é‡åˆ°æ¨¡æ¿ä¸­
3. **æ¶ˆæ¯æ„å»º**: ä¸ºèŠå¤©æ¨¡å‹æ„å»ºç»“æ„åŒ–æ¶ˆæ¯åˆ—è¡¨
4. **å°‘æ ·æœ¬å­¦ä¹ **: é€šè¿‡ç¤ºä¾‹æå‡æ¨¡å‹è¡¨ç°ï¼ˆFew-Shot Learningï¼‰
5. **éƒ¨åˆ†å˜é‡**: é¢„å¡«å……éƒ¨åˆ†å˜é‡ï¼Œåˆ›å»ºå¯å¤ç”¨æ¨¡æ¿
6. **æ¶ˆæ¯å ä½ç¬¦**: åŠ¨æ€æ’å…¥å¯¹è¯å†å²æˆ–ä»»æ„æ¶ˆæ¯åˆ—è¡¨
7. **ç®¡é“ç»„åˆ**: ä½œä¸º Runnable å¯æ— ç¼ç»„åˆåˆ° LCEL é“¾ä¸­

### 1.2 æ¶æ„å±‚æ¬¡

```
BasePromptTemplate (æ‰€æœ‰æç¤ºè¯æ¨¡æ¿çš„åŸºç±»)
â”œâ”€â”€ StringPromptTemplate (å­—ç¬¦ä¸²æ¨¡æ¿)
â”‚   â”œâ”€â”€ PromptTemplate (æ ‡å‡†æç¤ºè¯æ¨¡æ¿)
â”‚   â””â”€â”€ FewShotPromptTemplate (å°‘æ ·æœ¬æç¤ºè¯æ¨¡æ¿)
â””â”€â”€ BaseChatPromptTemplate (èŠå¤©æç¤ºè¯æ¨¡æ¿)
    â”œâ”€â”€ ChatPromptTemplate (æ ‡å‡†èŠå¤©æ¨¡æ¿)
    â””â”€â”€ MessagesPlaceholder (æ¶ˆæ¯å ä½ç¬¦)
```

### 1.3 è¾“å…¥/è¾“å‡º

**è¾“å…¥**:
- **æ ¼å¼åŒ–å‚æ•°**: å­—å…¸å½¢å¼çš„å˜é‡å€¼ `{"var1": "value1", "var2": "value2"}`
- **é…ç½®**: å¯é€‰çš„ `RunnableConfig`

**è¾“å‡º**:
- **PromptValue**: ç»Ÿä¸€çš„æç¤ºè¯å€¼å¯¹è±¡
  - `StringPromptValue`: å­—ç¬¦ä¸²å½¢å¼ï¼ˆç”¨äº LLMï¼‰
  - `ChatPromptValue`: æ¶ˆæ¯åˆ—è¡¨å½¢å¼ï¼ˆç”¨äºèŠå¤©æ¨¡å‹ï¼‰

**è½¬æ¢**:
```python
prompt = ChatPromptTemplate.from_template("Hello {name}")
prompt_value = prompt.invoke({"name": "Alice"})

# å¯è½¬æ¢ä¸ºä¸åŒæ ¼å¼
str_output = prompt_value.to_string()  # "Hello Alice"
messages = prompt_value.to_messages()  # [HumanMessage(content="Hello Alice")]
```

### 1.4 ä¸Šä¸‹æ¸¸ä¾èµ–

**ä¸Šæ¸¸è°ƒç”¨è€…**:
- ç”¨æˆ·åº”ç”¨ä»£ç 
- LCEL é“¾ï¼ˆä½œä¸ºé“¾çš„ç¬¬ä¸€ä¸ªç»„ä»¶ï¼‰

**ä¸‹æ¸¸ä¾èµ–**:
- `langchain_core.messages`: æ¶ˆæ¯ç±»å‹ï¼ˆ`HumanMessage`ã€`AIMessage` ç­‰ï¼‰
- `langchain_core.runnables`: Runnable åè®®
- `langchain_core.prompt_values`: PromptValue ç±»å‹
- æ¨¡æ¿å¼•æ“: Jinja2ï¼ˆå¯é€‰ï¼‰ã€`string.Formatter`ï¼ˆå†…ç½®ï¼‰

## 2. æ¨¡å—çº§æ¶æ„å›¾

```mermaid
flowchart TB
    subgraph Base["åŸºç¡€æŠ½è±¡å±‚"]
        BPT[BasePromptTemplate<br/>æ‰€æœ‰æ¨¡æ¿çš„åŸºç±»]
        SPT[StringPromptTemplate<br/>å­—ç¬¦ä¸²æ¨¡æ¿åŸºç±»]
        BCPT[BaseChatPromptTemplate<br/>èŠå¤©æ¨¡æ¿åŸºç±»]

        BPT --> SPT
        BPT --> BCPT
    end

    subgraph String["å­—ç¬¦ä¸²æ¨¡æ¿"]
        PT[PromptTemplate<br/>æ ‡å‡†æ–‡æœ¬æ¨¡æ¿]
        FST[FewShotPromptTemplate<br/>å°‘æ ·æœ¬æ¨¡æ¿]

        SPT --> PT
        SPT --> FST
    end

    subgraph Chat["èŠå¤©æ¨¡æ¿"]
        CPT[ChatPromptTemplate<br/>èŠå¤©æ¶ˆæ¯æ¨¡æ¿]
        MP[MessagesPlaceholder<br/>æ¶ˆæ¯å ä½ç¬¦]
        BMPT[BaseMessagePromptTemplate<br/>å•æ¶ˆæ¯æ¨¡æ¿]

        BCPT --> CPT
        BCPT --> MP
        BCPT --> BMPT
    end

    subgraph Message["æ¶ˆæ¯æ¨¡æ¿ç±»å‹"]
        HMT[HumanMessagePromptTemplate<br/>ç”¨æˆ·æ¶ˆæ¯]
        AMT[AIMessagePromptTemplate<br/>AIæ¶ˆæ¯]
        SMT[SystemMessagePromptTemplate<br/>ç³»ç»Ÿæ¶ˆæ¯]

        BMPT --> HMT
        BMPT --> AMT
        BMPT --> SMT
    end

    subgraph Output["è¾“å‡ºç±»å‹"]
        PV[PromptValue<br/>ç»Ÿä¸€æç¤ºè¯å€¼]
        SPV[StringPromptValue<br/>å­—ç¬¦ä¸²å½¢å¼]
        CPV[ChatPromptValue<br/>æ¶ˆæ¯åˆ—è¡¨å½¢å¼]

        PV --> SPV
        PV --> CPV
    end

    PT --> SPV
    CPT --> CPV

    style Base fill:#e1f5ff
    style String fill:#fff4e1
    style Chat fill:#e8f5e9
    style Message fill:#f3e5f5
    style Output fill:#fff3e0
```

### æ¶æ„å›¾è¯¦ç»†è¯´æ˜

**1. åŸºç¡€æŠ½è±¡å±‚**

- **BasePromptTemplate**: æ‰€æœ‰æç¤ºè¯æ¨¡æ¿çš„æ ¹åŸºç±»
  - ç»§æ‰¿è‡ª `RunnableSerializable`ï¼Œè‡ªåŠ¨æ”¯æŒ LCEL
  - å®šä¹‰ `input_variables`ï¼ˆå¿…éœ€å˜é‡ï¼‰å’Œ `optional_variables`ï¼ˆå¯é€‰å˜é‡ï¼‰
  - å¼ºåˆ¶å®ç° `format_prompt` æ–¹æ³•è¿”å› `PromptValue`
  - æä¾› `invoke` æ–¹æ³•ï¼Œè°ƒç”¨ `format_prompt`

- **StringPromptTemplate**: å­—ç¬¦ä¸²æ¨¡æ¿åŸºç±»
  - è¾“å‡ºä¸º `StringPromptValue`
  - æä¾› `format` æ–¹æ³•è¿”å›å­—ç¬¦ä¸²
  - æ”¯æŒä¸‰ç§æ¨¡æ¿æ ¼å¼ï¼šf-stringï¼ˆé»˜è®¤ï¼‰ã€jinja2ã€mustache

- **BaseChatPromptTemplate**: èŠå¤©æ¨¡æ¿åŸºç±»
  - è¾“å‡ºä¸º `ChatPromptValue`ï¼ˆæ¶ˆæ¯åˆ—è¡¨ï¼‰
  - æä¾› `format_messages` æ–¹æ³•è¿”å› `list[BaseMessage]`
  - æ”¯æŒæ¶ˆæ¯çº§åˆ«çš„æ¨¡æ¿åŒ–

**2. å­—ç¬¦ä¸²æ¨¡æ¿å®ç°**

- **PromptTemplate**: æœ€å¸¸ç”¨çš„æ–‡æœ¬æ¨¡æ¿
  - ä½¿ç”¨ f-string è¯­æ³•ï¼š`"Hello {name}"`
  - è‡ªåŠ¨æ¨æ–­ `input_variables`
  - æ”¯æŒéƒ¨åˆ†å˜é‡ï¼ˆpartial variablesï¼‰

  ```python
  prompt = PromptTemplate.from_template("Tell me about {topic}")
  # input_variables = ["topic"]
  ```

- **FewShotPromptTemplate**: å°‘æ ·æœ¬å­¦ä¹ æ¨¡æ¿
  - åŒ…å«å¤šä¸ªç¤ºä¾‹ï¼ˆexamplesï¼‰
  - æ¯ä¸ªç¤ºä¾‹ä½¿ç”¨ `example_prompt` æ ¼å¼åŒ–
  - æ”¯æŒç¤ºä¾‹é€‰æ‹©å™¨ï¼ˆExampleSelectorï¼‰åŠ¨æ€é€‰æ‹©ç¤ºä¾‹

  ```python
  examples = [
      {"input": "happy", "output": "ğŸ˜Š"},
      {"input": "sad", "output": "ğŸ˜¢"}
  ]
  prompt = FewShotPromptTemplate(
      examples=examples,
      example_prompt=PromptTemplate.from_template("Q: {input}\nA: {output}"),
      suffix="Q: {input}\nA:"
  )
  ```

**3. èŠå¤©æ¨¡æ¿å®ç°**

- **ChatPromptTemplate**: èŠå¤©æ¶ˆæ¯æ¨¡æ¿
  - ç”±å¤šä¸ªæ¶ˆæ¯æ¨¡æ¿ç»„æˆ
  - æ”¯æŒå…ƒç»„ç®€å†™ï¼š`("system", "You are a helpful assistant")`
  - æ”¯æŒæ¶ˆæ¯å ä½ç¬¦ï¼ˆMessagesPlaceholderï¼‰

  ```python
  prompt = ChatPromptTemplate.from_messages([
      ("system", "You are an expert in {domain}"),
      ("human", "{question}")
  ])
  ```

- **MessagesPlaceholder**: åŠ¨æ€æ’å…¥æ¶ˆæ¯åˆ—è¡¨
  - ç”¨äºæ’å…¥å¯¹è¯å†å²
  - å˜é‡å€¼å¿…é¡»æ˜¯ `list[BaseMessage]`

  ```python
  prompt = ChatPromptTemplate.from_messages([
      ("system", "You are helpful"),
      MessagesPlaceholder(variable_name="history"),
      ("human", "{question}")
  ])
  ```

- **BaseMessagePromptTemplate**: å•ä¸ªæ¶ˆæ¯çš„æ¨¡æ¿
  - å­ç±»ï¼š`HumanMessagePromptTemplate`ã€`AIMessagePromptTemplate`ã€`SystemMessagePromptTemplate`
  - æ ¼å¼åŒ–åç”Ÿæˆå¯¹åº”ç±»å‹çš„ `BaseMessage`

**4. è¾“å‡ºç±»å‹**

- **PromptValue**: ç»Ÿä¸€çš„æç¤ºè¯å€¼æŠ½è±¡
  - å¯è½¬æ¢ä¸ºå­—ç¬¦ä¸²æˆ–æ¶ˆæ¯åˆ—è¡¨
  - è§£è€¦æ¨¡æ¿å’Œæ¨¡å‹ç±»å‹

- **StringPromptValue**: ç”¨äºæ–‡æœ¬è¡¥å…¨æ¨¡å‹
  ```python
  value.to_string()  # "Tell me about AI"
  value.to_messages()  # [HumanMessage(content="Tell me about AI")]
  ```

- **ChatPromptValue**: ç”¨äºèŠå¤©æ¨¡å‹
  ```python
  value.to_messages()  # [SystemMessage(...), HumanMessage(...)]
  value.to_string()  # "System: ...\nHuman: ..."
  ```

## 3. æ ¸å¿ƒ API è¯¦è§£

### 3.1 PromptTemplate.from_template - åˆ›å»ºæ–‡æœ¬æ¨¡æ¿

**åŸºæœ¬ä¿¡æ¯**:
- **æ–¹æ³•**: ç±»æ–¹æ³•
- **ç­¾å**: `PromptTemplate.from_template(template: str, template_format: str = "f-string") -> PromptTemplate`

**åŠŸèƒ½**: ä»æ¨¡æ¿å­—ç¬¦ä¸²åˆ›å»ºæç¤ºè¯æ¨¡æ¿ï¼Œè‡ªåŠ¨æ¨æ–­å˜é‡ã€‚

**å‚æ•°**:

| å‚æ•°å | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| `template` | `str` | å¿…å¡« | æ¨¡æ¿å­—ç¬¦ä¸²ï¼ŒåŒ…å« `{variable}` å ä½ç¬¦ |
| `template_format` | `str` | `"f-string"` | æ¨¡æ¿æ ¼å¼ï¼š`"f-string"`, `"jinja2"`, `"mustache"` |

**è¿”å›å€¼**: `PromptTemplate` å¯¹è±¡

**æ ¸å¿ƒä»£ç **:

```python
class PromptTemplate(StringPromptTemplate):
    template: str
    template_format: str = "f-string"

    @classmethod
    def from_template(
        cls,
        template: str,
        *,
        template_format: str = "f-string",
        **kwargs: Any
    ) -> PromptTemplate:
        """
        ä»æ¨¡æ¿å­—ç¬¦ä¸²åˆ›å»º PromptTemplate

        å‚æ•°:
            template: æ¨¡æ¿å­—ç¬¦ä¸²
            template_format: æ¨¡æ¿æ ¼å¼
            **kwargs: é¢å¤–å‚æ•°ï¼ˆå¦‚ partial_variablesï¼‰

        è¿”å›:
            PromptTemplate å®ä¾‹
        """
        # è‡ªåŠ¨æ¨æ–­è¾“å…¥å˜é‡
        input_variables = get_template_variables(template, template_format)

        return cls(
            template=template,
            input_variables=input_variables,
            template_format=template_format,
            **kwargs
        )

    def format(self, **kwargs: Any) -> str:
        """
        æ ¼å¼åŒ–æ¨¡æ¿ä¸ºå­—ç¬¦ä¸²

        å‚æ•°:
            **kwargs: å˜é‡å€¼

        è¿”å›:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        # åˆå¹¶éƒ¨åˆ†å˜é‡å’Œè¿è¡Œæ—¶å˜é‡
        kwargs = self._merge_partial_and_user_variables(**kwargs)

        # æ ¹æ®æ¨¡æ¿æ ¼å¼é€‰æ‹©æ ¼å¼åŒ–æ–¹æ³•
        if self.template_format == "f-string":
            return self.template.format(**kwargs)
        elif self.template_format == "jinja2":
            return self._render_jinja2(self.template, kwargs)
        elif self.template_format == "mustache":
            return self._render_mustache(self.template, kwargs)
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
from langchain_core.prompts import PromptTemplate

# åŸºç¡€ç”¨æ³•
prompt = PromptTemplate.from_template("Tell me about {topic}")
result = prompt.format(topic="AI")
print(result)  # "Tell me about AI"

# å¤šå˜é‡
prompt = PromptTemplate.from_template(
    "You are a {role}. Answer the question: {question}"
)
result = prompt.format(role="teacher", question="What is Python?")

# åœ¨ LCEL é“¾ä¸­ä½¿ç”¨
chain = prompt | model | parser
output = chain.invoke({"topic": "Machine Learning"})

# Jinja2 æ¨¡æ¿
prompt = PromptTemplate.from_template(
    "{% for item in items %}{{ item }}{% endfor %}",
    template_format="jinja2"
)
```

### 3.2 ChatPromptTemplate.from_messages - åˆ›å»ºèŠå¤©æ¨¡æ¿

**åŸºæœ¬ä¿¡æ¯**:
- **æ–¹æ³•**: ç±»æ–¹æ³•
- **ç­¾å**: `ChatPromptTemplate.from_messages(messages: list[MessageLike]) -> ChatPromptTemplate`

**åŠŸèƒ½**: ä»æ¶ˆæ¯åˆ—è¡¨åˆ›å»ºèŠå¤©æç¤ºè¯æ¨¡æ¿ã€‚

**å‚æ•°**:

| å‚æ•°å | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| `messages` | `list[MessageLike]` | æ¶ˆæ¯åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æ ¼å¼ |

**MessageLike ç±»å‹**:
1. **å…ƒç»„ç®€å†™**: `("role", "content")`
   - role: `"system"`, `"human"`, `"ai"`, `"placeholder"`
2. **æ¶ˆæ¯å¯¹è±¡**: `HumanMessage(content="...")`, `SystemMessage(content="...")`
3. **æ¶ˆæ¯æ¨¡æ¿**: `HumanMessagePromptTemplate.from_template("...")`
4. **å ä½ç¬¦**: `MessagesPlaceholder(variable_name="history")`

**æ ¸å¿ƒä»£ç **:

```python
class ChatPromptTemplate(BaseChatPromptTemplate):
    messages: list[MessageLike]

    @classmethod
    def from_messages(
        cls,
        messages: list[MessageLike]
    ) -> ChatPromptTemplate:
        """
        ä»æ¶ˆæ¯åˆ—è¡¨åˆ›å»ºèŠå¤©æ¨¡æ¿

        å‚æ•°:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ”¯æŒå…ƒç»„ã€æ¶ˆæ¯å¯¹è±¡ã€æ¨¡æ¿ç­‰

        è¿”å›:
            ChatPromptTemplate å®ä¾‹
        """
        # è½¬æ¢ä¸ºæ ‡å‡†æ¶ˆæ¯æ¨¡æ¿
        _messages = []
        for message in messages:
            _messages.append(_convert_to_message(message))

        return cls(messages=_messages)

    def format_messages(self, **kwargs: Any) -> list[BaseMessage]:
        """
        æ ¼å¼åŒ–ä¸ºæ¶ˆæ¯åˆ—è¡¨

        å‚æ•°:
            **kwargs: å˜é‡å€¼

        è¿”å›:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        result = []
        for message_template in self.messages:
            # æ ¼å¼åŒ–æ¯ä¸ªæ¶ˆæ¯æ¨¡æ¿
            if isinstance(message_template, MessagesPlaceholder):
                # å ä½ç¬¦ï¼šç›´æ¥æ’å…¥æ¶ˆæ¯åˆ—è¡¨
                messages = kwargs[message_template.variable_name]
                result.extend(messages)
            elif isinstance(message_template, BaseMessage):
                # é™æ€æ¶ˆæ¯ï¼šç›´æ¥æ·»åŠ 
                result.append(message_template)
            else:
                # æ¶ˆæ¯æ¨¡æ¿ï¼šæ ¼å¼åŒ–åæ·»åŠ 
                result.extend(message_template.format_messages(**kwargs))

        return result
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# åŸºç¡€ç”¨æ³•ï¼šå…ƒç»„ç®€å†™
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are an expert in {domain}"),
    ("human", "{question}")
])

messages = prompt.format_messages(domain="Python", question="What is a decorator?")
# [
#   SystemMessage(content="You are an expert in Python"),
#   HumanMessage(content="What is a decorator?")
# ]

# å¸¦å¯¹è¯å†å²
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are helpful"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}")
])

history = [
    HumanMessage(content="Hi"),
    AIMessage(content="Hello! How can I help?")
]
messages = prompt.format_messages(history=history, question="Tell me more")

# åœ¨ LCEL é“¾ä¸­ä½¿ç”¨
chain = prompt | model | parser
result = chain.invoke({"domain": "AI", "question": "What is ML?"})
```

### 3.3 partial - éƒ¨åˆ†å˜é‡å¡«å……

**åŠŸèƒ½**: é¢„å¡«å……éƒ¨åˆ†å˜é‡ï¼Œåˆ›å»ºå¯å¤ç”¨çš„æ¨¡æ¿ã€‚

**ä½¿ç”¨åœºæ™¯**:
- å›ºå®šæŸäº›å˜é‡ï¼ˆå¦‚ç³»ç»Ÿæç¤ºï¼‰
- å»¶è¿Ÿæ³¨å…¥åŠ¨æ€å€¼ï¼ˆå¦‚å½“å‰æ—¶é—´ï¼‰

**æ ¸å¿ƒä»£ç **:

```python
def partial(self, **kwargs: Any) -> BasePromptTemplate:
    """
    åˆ›å»ºéƒ¨åˆ†å¡«å……çš„æ¨¡æ¿å‰¯æœ¬

    å‚æ•°:
        **kwargs: è¦é¢„å¡«å……çš„å˜é‡

    è¿”å›:
        æ–°çš„æ¨¡æ¿å®ä¾‹
    """
    prompt_dict = self.__dict__.copy()
    prompt_dict["input_variables"] = [
        v for v in self.input_variables if v not in kwargs
    ]
    prompt_dict["partial_variables"] = {
        **self.partial_variables,
        **kwargs
    }
    return self.__class__(**prompt_dict)
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# é¢„å¡«å……å›ºå®šå˜é‡
base_prompt = PromptTemplate.from_template(
    "You are a {role}. Answer: {question}"
)
teacher_prompt = base_prompt.partial(role="teacher")
result = teacher_prompt.format(question="What is Python?")
# "You are a teacher. Answer: What is Python?"

# å»¶è¿Ÿæ³¨å…¥åŠ¨æ€å€¼
from datetime import datetime

def get_current_time():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

prompt = PromptTemplate.from_template(
    "Current time: {time}. Question: {question}"
)
prompt_with_time = prompt.partial(time=get_current_time)

# æ¯æ¬¡è°ƒç”¨æ—¶ï¼Œtime ä¼šè‡ªåŠ¨è·å–å½“å‰æ—¶é—´
result = prompt_with_time.format(question="What's the weather?")
```

### 3.4 FewShotPromptTemplate - å°‘æ ·æœ¬å­¦ä¹ 

**åŠŸèƒ½**: é€šè¿‡æä¾›ç¤ºä¾‹æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆã€‚

**æ ¸å¿ƒç»„ä»¶**:
- **examples**: ç¤ºä¾‹åˆ—è¡¨
- **example_prompt**: å•ä¸ªç¤ºä¾‹çš„æ ¼å¼åŒ–æ¨¡æ¿
- **prefix**: ç¤ºä¾‹å‰çš„è¯´æ˜
- **suffix**: ç¤ºä¾‹åçš„æç¤ºï¼ˆé€šå¸¸åŒ…å«æ–°é—®é¢˜ï¼‰
- **example_selector**: åŠ¨æ€é€‰æ‹©ç¤ºä¾‹ï¼ˆå¯é€‰ï¼‰

**ä½¿ç”¨ç¤ºä¾‹**:

```python
from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate

# å®šä¹‰ç¤ºä¾‹
examples = [
    {"word": "happy", "antonym": "sad"},
    {"word": "tall", "antonym": "short"},
    {"word": "hot", "antonym": "cold"}
]

# å•ä¸ªç¤ºä¾‹çš„æ ¼å¼
example_prompt = PromptTemplate.from_template("Word: {word}\nAntonym: {antonym}")

# åˆ›å»ºå°‘æ ·æœ¬æ¨¡æ¿
few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="Give the antonym of each word:",
    suffix="Word: {input}\nAntonym:",
    input_variables=["input"]
)

result = few_shot_prompt.format(input="big")
# Give the antonym of each word:
#
# Word: happy
# Antonym: sad
#
# Word: tall
# Antonym: short
#
# Word: hot
# Antonym: cold
#
# Word: big
# Antonym:

# ä½¿ç”¨ç¤ºä¾‹é€‰æ‹©å™¨ï¼ˆåŠ¨æ€é€‰æ‹©æœ€ç›¸å…³çš„ç¤ºä¾‹ï¼‰
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,
    OpenAIEmbeddings(),
    Chroma,
    k=2  # é€‰æ‹©æœ€ç›¸å…³çš„ 2 ä¸ªç¤ºä¾‹
)

few_shot_prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    suffix="Word: {input}\nAntonym:",
    input_variables=["input"]
)
```

## 4. å…³é”®æ•°æ®ç»“æ„

### 4.1 PromptValue åŠå…¶å­ç±»

```mermaid
classDiagram
    class PromptValue {
        <<abstract>>
        +to_string() str
        +to_messages() list~BaseMessage~
    }

    class StringPromptValue {
        +text: str
        +to_string() str
        +to_messages() list~BaseMessage~
    }

    class ChatPromptValue {
        +messages: list~BaseMessage~
        +to_string() str
        +to_messages() list~BaseMessage~
    }

    PromptValue <|-- StringPromptValue
    PromptValue <|-- ChatPromptValue
```

**å­—æ®µè¯´æ˜**:

| ç±» | å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|---|------|------|------|
| `StringPromptValue` | `text` | `str` | å­—ç¬¦ä¸²å½¢å¼çš„æç¤ºè¯ |
| `ChatPromptValue` | `messages` | `list[BaseMessage]` | æ¶ˆæ¯åˆ—è¡¨å½¢å¼çš„æç¤ºè¯ |

**è½¬æ¢æ–¹æ³•**:

```python
# StringPromptValue
value = StringPromptValue(text="Hello World")
value.to_string()  # "Hello World"
value.to_messages()  # [HumanMessage(content="Hello World")]

# ChatPromptValue
value = ChatPromptValue(messages=[
    SystemMessage(content="You are helpful"),
    HumanMessage(content="Hi")
])
value.to_messages()  # [SystemMessage(...), HumanMessage(...)]
value.to_string()  # "System: You are helpful\nHuman: Hi"
```

### 4.2 BasePromptTemplate é…ç½®

```python
class BasePromptTemplate(RunnableSerializable):
    input_variables: list[str]  # å¿…éœ€å˜é‡
    optional_variables: list[str] = []  # å¯é€‰å˜é‡
    partial_variables: dict[str, Any] = {}  # éƒ¨åˆ†å˜é‡
    metadata: Optional[dict[str, Any]] = None  # å…ƒæ•°æ®
    tags: Optional[list[str]] = None  # æ ‡ç­¾
    output_parser: Optional[BaseOutputParser] = None  # è¾“å‡ºè§£æå™¨
```

## 5. æ ¸å¿ƒæµç¨‹æ—¶åºå›¾

### 5.1 PromptTemplate æ ¼å¼åŒ–æµç¨‹

```mermaid
sequenceDiagram
    autonumber
    participant User as ç”¨æˆ·ä»£ç 
    participant PT as PromptTemplate
    participant Formatter as æ¨¡æ¿å¼•æ“
    participant PV as PromptValue

    User->>PT: invoke({"topic": "AI"})
    activate PT

    PT->>PT: åˆå¹¶ partial_variables
    PT->>PT: æ ¡éªŒå¿…éœ€å˜é‡

    PT->>Formatter: format(template, variables)
    activate Formatter
    Formatter->>Formatter: æ›¿æ¢å ä½ç¬¦
    Formatter-->>PT: formatted_string
    deactivate Formatter

    PT->>PV: StringPromptValue(formatted_string)
    activate PV
    PV-->>PT: prompt_value
    deactivate PV

    PT-->>User: prompt_value
    deactivate PT
```

**æµç¨‹è¯´æ˜**:

1. **è°ƒç”¨å…¥å£**: ç”¨æˆ·é€šè¿‡ `invoke` æ–¹æ³•ä¼ å…¥å˜é‡å­—å…¸
2. **å˜é‡åˆå¹¶**: åˆå¹¶ `partial_variables` å’Œè¿è¡Œæ—¶å˜é‡
3. **å˜é‡æ ¡éªŒ**: æ£€æŸ¥æ‰€æœ‰å¿…éœ€å˜é‡æ˜¯å¦æä¾›
4. **æ¨¡æ¿æ ¼å¼åŒ–**:
   - f-string: ä½¿ç”¨ Python `str.format()`
   - Jinja2: ä½¿ç”¨ Jinja2 æ¨¡æ¿å¼•æ“
   - Mustache: ä½¿ç”¨ Mustache è§£æå™¨
5. **åˆ›å»º PromptValue**: å°è£…ä¸º `StringPromptValue`
6. **è¿”å›ç»“æœ**: è¿”å› `PromptValue` å¯¹è±¡

### 5.2 ChatPromptTemplate æ ¼å¼åŒ–æµç¨‹

```mermaid
sequenceDiagram
    autonumber
    participant User as ç”¨æˆ·ä»£ç 
    participant CPT as ChatPromptTemplate
    participant MT as MessageTemplate
    participant MP as MessagesPlaceholder
    participant PV as ChatPromptValue

    User->>CPT: invoke({"domain": "AI", "question": "..."})
    activate CPT

    loop éå†æ¯ä¸ªæ¶ˆæ¯æ¨¡æ¿
        alt é™æ€æ¶ˆæ¯
            CPT->>CPT: ç›´æ¥æ·»åŠ åˆ°ç»“æœ
        else MessagesPlaceholder
            CPT->>MP: è·å–å˜é‡å€¼
            MP-->>CPT: list[BaseMessage]
            CPT->>CPT: æ‰©å±•åˆ°ç»“æœ
        else æ¶ˆæ¯æ¨¡æ¿
            CPT->>MT: format_messages(variables)
            activate MT
            MT->>MT: æ ¼å¼åŒ–å†…å®¹
            MT-->>CPT: BaseMessage
            deactivate MT
            CPT->>CPT: æ·»åŠ åˆ°ç»“æœ
        end
    end

    CPT->>PV: ChatPromptValue(messages)
    PV-->>CPT: prompt_value
    CPT-->>User: prompt_value
    deactivate CPT
```

**æµç¨‹è¯´æ˜**:

1. **è°ƒç”¨å…¥å£**: ä¼ å…¥æ‰€æœ‰å˜é‡ï¼ˆåŒ…æ‹¬å ä½ç¬¦å˜é‡ï¼‰
2. **éå†æ¶ˆæ¯æ¨¡æ¿**: ä¾æ¬¡å¤„ç†æ¯ä¸ªæ¶ˆæ¯
3. **å¤„ç†é™æ€æ¶ˆæ¯**: æ— éœ€æ ¼å¼åŒ–ï¼Œç›´æ¥æ·»åŠ 
4. **å¤„ç†å ä½ç¬¦**:
   - ä»å˜é‡ä¸­è·å–æ¶ˆæ¯åˆ—è¡¨
   - å±•å¼€ï¼ˆextendï¼‰åˆ°ç»“æœåˆ—è¡¨
5. **å¤„ç†æ¶ˆæ¯æ¨¡æ¿**:
   - è°ƒç”¨ `format_messages` æ ¼å¼åŒ–å†…å®¹
   - ç”Ÿæˆå¯¹åº”ç±»å‹çš„ `BaseMessage`
6. **åˆ›å»º PromptValue**: å°è£…ä¸º `ChatPromptValue`
7. **è¿”å›ç»“æœ**: è¿”å›åŒ…å«å®Œæ•´æ¶ˆæ¯åˆ—è¡¨çš„ `PromptValue`

### 5.3 LCEL é“¾ä¸­çš„æç¤ºè¯æµç¨‹

```mermaid
sequenceDiagram
    autonumber
    participant User as ç”¨æˆ·ä»£ç 
    participant Chain as LCEL Chain
    participant Prompt as PromptTemplate
    participant Model as ChatModel
    participant Parser as OutputParser

    User->>Chain: invoke({"topic": "AI"})
    activate Chain

    Chain->>Prompt: invoke({"topic": "AI"})
    activate Prompt
    Prompt->>Prompt: format_prompt(variables)
    Prompt-->>Chain: PromptValue
    deactivate Prompt

    Chain->>Model: invoke(PromptValue)
    activate Model
    Model->>Model: è½¬æ¢ä¸º API æ ¼å¼
    Model-->>Chain: AIMessage
    deactivate Model

    Chain->>Parser: invoke(AIMessage)
    activate Parser
    Parser->>Parser: parse(message.content)
    Parser-->>Chain: structured_output
    deactivate Parser

    Chain-->>User: structured_output
    deactivate Chain
```

**æµç¨‹è¯´æ˜**:

1. **é“¾å¼è°ƒç”¨**: `prompt | model | parser`
2. **æç¤ºè¯æ ¼å¼åŒ–**: Prompt å°†è¾“å…¥è½¬æ¢ä¸º PromptValue
3. **æ¨¡å‹è°ƒç”¨**: Model æ¥æ”¶ PromptValue å¹¶è½¬æ¢ä¸º API æ ¼å¼
4. **è¾“å‡ºè§£æ**: Parser è§£ææ¨¡å‹è¾“å‡º
5. **ç±»å‹å®‰å…¨**: PromptValue è§£è€¦äº†æç¤ºè¯å’Œæ¨¡å‹ç±»å‹

## 6. æ¨¡æ¿æ ¼å¼å¯¹æ¯”

### 6.1 ä¸‰ç§æ¨¡æ¿æ ¼å¼

| ç‰¹æ€§ | f-string | Jinja2 | Mustache |
|------|----------|--------|----------|
| **è¯­æ³•** | `{variable}` | `{{ variable }}` | `{{variable}}` |
| **æ¡ä»¶** | âŒ ä¸æ”¯æŒ | âœ… `{% if %}` | âœ… `{{#condition}}` |
| **å¾ªç¯** | âŒ ä¸æ”¯æŒ | âœ… `{% for %}` | âœ… `{{#items}}` |
| **è¿‡æ»¤å™¨** | âŒ ä¸æ”¯æŒ | âœ… `{{ var\|upper }}` | âŒ ä¸æ”¯æŒ |
| **æ€§èƒ½** | âš¡ æœ€å¿« | ğŸ¢ è¾ƒæ…¢ | ğŸŒ æœ€æ…¢ |
| **å®‰å…¨æ€§** | âœ… å®‰å…¨ | âš ï¸ æ²™ç®±æ¨¡å¼ | âœ… å®‰å…¨ |
| **æ¨èåœºæ™¯** | ç®€å•å˜é‡æ›¿æ¢ | å¤æ‚é€»è¾‘ | è·¨è¯­è¨€æ¨¡æ¿ |

### 6.2 ä½¿ç”¨ç¤ºä¾‹

**f-stringï¼ˆæ¨èï¼‰**:
```python
prompt = PromptTemplate.from_template(
    "You are a {role}. Answer: {question}"
)
```

**Jinja2ï¼ˆå¤æ‚é€»è¾‘ï¼‰**:
```python
prompt = PromptTemplate.from_template(
    """
    {% if user_type == "premium" %}
    You have access to advanced features.
    {% else %}
    You have access to basic features.
    {% endif %}

    Question: {{ question }}
    """,
    template_format="jinja2"
)
```

**Mustacheï¼ˆè·¨å¹³å°ï¼‰**:
```python
prompt = PromptTemplate.from_template(
    """
    Hello {{name}}!
    {{#items}}
      - {{.}}
    {{/items}}
    """,
    template_format="mustache"
)
```

## 7. æœ€ä½³å®è·µ

### 7.1 é€‰æ‹©åˆé€‚çš„æ¨¡æ¿ç±»å‹

**ä½¿ç”¨ PromptTemplateï¼ˆæ–‡æœ¬æ¨¡æ¿ï¼‰**:
- âŒ ä¸æ¨èï¼šæ–°é¡¹ç›®ä¸åº”ä½¿ç”¨ï¼ˆæ¨èèŠå¤©æ¨¡å‹ï¼‰
- âœ… é€‚ç”¨åœºæ™¯ï¼š
  - é—ç•™ä»£ç ç»´æŠ¤
  - ç‰¹å®šçš„æ–‡æœ¬è¡¥å…¨ä»»åŠ¡
  - ç®€å•çš„æ¨¡æ¿æµ‹è¯•

**ä½¿ç”¨ ChatPromptTemplateï¼ˆèŠå¤©æ¨¡æ¿ï¼‰**:
- âœ… æ¨èï¼šæ–°é¡¹ç›®é¦–é€‰
- ä¼˜åŠ¿ï¼š
  - ç»“æ„åŒ–æ¶ˆæ¯ç®¡ç†
  - æ”¯æŒç³»ç»Ÿæç¤º
  - æ›´å¥½çš„å¤šè½®å¯¹è¯æ”¯æŒ
  - å·¥å…·è°ƒç”¨å‹å¥½

### 7.2 æç¤ºè¯å·¥ç¨‹æŠ€å·§

**æ˜ç¡®è§’è‰²å’Œä»»åŠ¡**:
```python
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are an expert {domain} tutor. Explain concepts clearly with examples."),
    ("human", "{question}")
])
```

**ä½¿ç”¨å°‘æ ·æœ¬å­¦ä¹ **:
```python
# é€šè¿‡ç¤ºä¾‹å¼•å¯¼è¾“å‡ºæ ¼å¼
examples = [
    {"input": "2+2", "output": "4"},
    {"input": "3*5", "output": "15"}
]
few_shot_prompt = FewShotPromptTemplate(...)
```

**æ‹†åˆ†å¤æ‚æç¤ºè¯**:
```python
# âŒ ä¸æ¨èï¼šå…¨éƒ¨å¡åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²
prompt = "You are... Do this... Consider that... Output format..."

# âœ… æ¨èï¼šç»“æ„åŒ–æ‹†åˆ†
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("human", "Context: {context}"),
    ("human", "Task: {task}"),
    ("human", "Output format: {format}"),
    ("human", "Question: {question}")
])
```

### 7.3 éƒ¨åˆ†å˜é‡çš„æœ‰æ•ˆä½¿ç”¨

**å›ºå®šç³»ç»Ÿæç¤º**:
```python
base_prompt = ChatPromptTemplate.from_messages([
    ("system", "{system_message}"),
    ("human", "{question}")
])

# ä¸ºä¸åŒè§’è‰²åˆ›å»ºä¸“ç”¨æç¤º
teacher_prompt = base_prompt.partial(
    system_message="You are a patient teacher."
)
expert_prompt = base_prompt.partial(
    system_message="You are a domain expert."
)
```

**åŠ¨æ€æ—¶é—´æˆ³**:
```python
def get_timestamp():
    return datetime.now().isoformat()

prompt = PromptTemplate.from_template(
    "[{timestamp}] User query: {query}"
).partial(timestamp=get_timestamp)

# æ¯æ¬¡è°ƒç”¨æ—¶è‡ªåŠ¨è·å–å½“å‰æ—¶é—´
```

### 7.4 æ¶ˆæ¯å ä½ç¬¦ç®¡ç†å¯¹è¯å†å²

```python
from langchain_core.runnables import RunnableWithMessageHistory
from langchain.memory import ChatMessageHistory

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are helpful"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{question}")
])

chain = prompt | model

# æ‰‹åŠ¨ç®¡ç†å†å²
history = ChatMessageHistory()
history.add_user_message("Hi")
history.add_ai_message("Hello!")

result = chain.invoke({
    "history": history.messages,
    "question": "What's the weather?"
})

# æˆ–ä½¿ç”¨ RunnableWithMessageHistory è‡ªåŠ¨ç®¡ç†
chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history=lambda session_id: ChatMessageHistory(),
    input_messages_key="question",
    history_messages_key="history"
)
```

### 7.5 è¾“å‡ºè§£æå™¨é›†æˆ

```python
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

class Person(BaseModel):
    name: str = Field(description="Person's name")
    age: int = Field(description="Person's age")

parser = PydanticOutputParser(pydantic_object=Person)

prompt = ChatPromptTemplate.from_messages([
    ("system", "Extract person information."),
    ("human", "{text}"),
    ("human", "Format instructions: {format_instructions}")
])

chain = (
    prompt.partial(format_instructions=parser.get_format_instructions())
    | model
    | parser
)

result = chain.invoke({"text": "John is 30 years old"})
# Person(name="John", age=30)
```

### 7.6 é¿å…çš„åæ¨¡å¼

**âŒ ç¡¬ç¼–ç å˜é‡å€¼**:
```python
# ä¸æ¨è
prompt = PromptTemplate.from_template("You are a teacher. Answer: {question}")
```

**âœ… ä½¿ç”¨å˜é‡å’Œéƒ¨åˆ†å˜é‡**:
```python
# æ¨è
prompt = PromptTemplate.from_template("You are a {role}. Answer: {question}")
teacher_prompt = prompt.partial(role="teacher")
```

**âŒ å­—ç¬¦ä¸²æ‹¼æ¥æ„å»ºæç¤ºè¯**:
```python
# ä¸æ¨è
prompt_str = "System: " + system_msg + "\nUser: " + user_msg
```

**âœ… ä½¿ç”¨ ChatPromptTemplate**:
```python
# æ¨è
prompt = ChatPromptTemplate.from_messages([
    ("system", system_msg),
    ("human", user_msg)
])
```

**âŒ å¿½ç•¥è¾“å…¥éªŒè¯**:
```python
# å¯èƒ½æŠ›å‡º KeyError
result = prompt.format(wrong_key="value")
```

**âœ… ä½¿ç”¨ invoke è‡ªåŠ¨éªŒè¯**:
```python
# è‡ªåŠ¨éªŒè¯å¿…éœ€å˜é‡
result = prompt.invoke({"correct_key": "value"})
```

## 8. ä¸å…¶ä»–æ¨¡å—çš„åä½œ

### 8.1 ä¸ Language Models åä½œ

```python
# æç¤ºè¯ â†’ æ¨¡å‹
chain = prompt | model
result = chain.invoke({"question": "What is AI?"})
```

### 8.2 ä¸ Output Parsers åä½œ

```python
# æç¤ºè¯ â†’ æ¨¡å‹ â†’ è§£æå™¨
chain = prompt | model | JsonOutputParser()
structured_result = chain.invoke(input)
```

### 8.3 ä¸ Retrievers åä½œï¼ˆRAGï¼‰

```python
from langchain_core.runnables import RunnablePassthrough

# æ£€ç´¢ â†’ æ ¼å¼åŒ– â†’ æç¤ºè¯ â†’ æ¨¡å‹
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)
```

### 8.4 ä¸ Agents åä½œ

```python
# Agents ä½¿ç”¨æç¤ºè¯æ„å»ºæ¨ç†æç¤º
agent = create_openai_functions_agent(
    llm=model,
    tools=tools,
    prompt=prompt  # åŒ…å«å·¥å…·æè¿°å’Œæ¨ç†æŒ‡å¯¼
)
```

## 9. æ€»ç»“

Prompts æ¨¡å—æ˜¯ LangChain åº”ç”¨çš„å…¥å£ï¼Œé€šè¿‡çµæ´»çš„æ¨¡æ¿ç³»ç»Ÿå®ç°ï¼š

1. **å£°æ˜å¼å®šä¹‰**: ä½¿ç”¨æ¨¡æ¿è¯­æ³•è€Œéå­—ç¬¦ä¸²æ‹¼æ¥
2. **ç±»å‹å®‰å…¨**: PromptValue è§£è€¦æç¤ºè¯å’Œæ¨¡å‹ç±»å‹
3. **å¯å¤ç”¨æ€§**: éƒ¨åˆ†å˜é‡å’Œæ¨¡æ¿ç»„åˆ
4. **ç»“æ„åŒ–**: èŠå¤©æ¨¡æ¿æ”¯æŒå¤šè§’è‰²æ¶ˆæ¯
5. **å°‘æ ·æœ¬å­¦ä¹ **: FewShotPromptTemplate æå‡æ¨¡å‹è¡¨ç°
6. **LCEL é›†æˆ**: ä½œä¸º Runnable æ— ç¼ç»„åˆ

**å…³é”®åŸåˆ™**:
- ä¼˜å…ˆä½¿ç”¨ `ChatPromptTemplate`
- ä½¿ç”¨å˜é‡è€Œéç¡¬ç¼–ç 
- ç»“æ„åŒ–æ‹†åˆ†å¤æ‚æç¤ºè¯
- åˆ©ç”¨éƒ¨åˆ†å˜é‡æé«˜å¤ç”¨æ€§
- é€šè¿‡ç¤ºä¾‹å¼•å¯¼æ¨¡å‹è¾“å‡º

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-03
**ç›¸å…³æ–‡æ¡£**:
- LangChain-00-æ€»è§ˆ.md
- LangChain-03-LanguageModels-æ¦‚è§ˆ.md
- LangChain-05-OutputParsers-æ¦‚è§ˆ.mdï¼ˆå¾…ç”Ÿæˆï¼‰

