---
title: "AutoGen Python AgentChatæ¨¡å—æºç æ·±åº¦è§£æ"
date: 2025-05-04T14:00:00+08:00
draft: false
featured: true
series: "autogen-architecture"
tags: ["AutoGen", "AgentChat", "Python", "å¤šä»£ç†å¯¹è¯", "å›¢é˜Ÿåä½œ", "æºç åˆ†æ"]
categories: ["autogen", "æºç åˆ†æ"]
author: "Architecture Analysis"  
description: "æ·±å…¥å‰–æAutoGen Python AgentChatæ¨¡å—çš„å¯¹è¯ä»£ç†ç³»ç»Ÿã€å›¢é˜Ÿåä½œæœºåˆ¶å’Œæ¶ˆæ¯æµè½¬å®ç°"
toc: true
tocOpen: true
showReadingTime: true
showWordCount: true
weight: 160
slug: "autogen-agentchat-analysis"
---

## æ¦‚è¿°

`autogen-agentchat`æ˜¯AutoGen Pythonå®ç°çš„é«˜çº§å¯¹è¯ä»£ç†åŒ…ï¼Œåœ¨`autogen-core`åŸºç¡€ä¸Šæ„å»ºäº†é¢å‘å¯¹è¯åœºæ™¯çš„ä»£ç†æŠ½è±¡å’Œå›¢é˜Ÿåä½œæœºåˆ¶ã€‚å…¶æ ¸å¿ƒç»„ä»¶è®¾è®¡ã€å¯¹è¯æµç¨‹å’Œå›¢é˜Ÿç®¡ç†å®ç°ã€‚

## 1. æ•´ä½“æ¶æ„è®¾è®¡

### 1.1 æ¨¡å—å±‚æ¬¡ç»“æ„

```mermaid
graph TB
    subgraph "autogen-agentchat æ¨¡å—æ¶æ„"
        subgraph "åº”ç”¨å±‚ - é¢„å®šä¹‰ä»£ç†"
            AA[AssistantAgent - åŠ©æ‰‹ä»£ç†]
            UPA[UserProxyAgent - ç”¨æˆ·ä»£ç†]
            CEA[CodeExecutorAgent - ä»£ç æ‰§è¡Œä»£ç†]
            SOMA[SocietyOfMindAgent - ç¾¤ä½“æ™ºèƒ½ä»£ç†]
            MFA[MessageFilterAgent - æ¶ˆæ¯è¿‡æ»¤ä»£ç†]
        end
        
        subgraph "ä»£ç†æŠ½è±¡å±‚"
            BCA[BaseChatAgent - èŠå¤©ä»£ç†åŸºç±»]
            CA[ChatAgent - ä»£ç†åè®®]
            TR[TaskRunner - ä»»åŠ¡è¿è¡Œå™¨]
        end
        
        subgraph "æ¶ˆæ¯ç³»ç»Ÿ"
            BCM[BaseChatMessage - èŠå¤©æ¶ˆæ¯åŸºç±»]
            BTCM[BaseTextChatMessage - æ–‡æœ¬æ¶ˆæ¯åŸºç±»]
            SM[StructuredMessage - ç»“æ„åŒ–æ¶ˆæ¯]
            BAE[BaseAgentEvent - ä»£ç†äº‹ä»¶]
            MF[MessageFactory - æ¶ˆæ¯å·¥å‚]
        end
        
        subgraph "å›¢é˜Ÿåä½œ"
            T[Team - å›¢é˜Ÿåè®®]
            BGC[BaseGroupChat - ç¾¤èŠåŸºç±»]
            BGCM[BaseGroupChatManager - ç¾¤èŠç®¡ç†å™¨]
            CAC[ChatAgentContainer - ä»£ç†å®¹å™¨]
        end
        
        subgraph "çŠ¶æ€ç®¡ç†"
            TS[TeamState - å›¢é˜ŸçŠ¶æ€]
            CACS[ChatAgentContainerState - å®¹å™¨çŠ¶æ€]
            BS[BaseState - çŠ¶æ€åŸºç±»]
        end
        
        subgraph "ç»ˆæ­¢æ¡ä»¶"
            TC[TerminationCondition - ç»ˆæ­¢æ¡ä»¶]
            TERMINATIONS[å„ç§ç»ˆæ­¢å®ç°]
        end
        
        subgraph "å·¥å…·é›†æˆ"
            AT[AgentTool - ä»£ç†å·¥å…·]
            TT[TeamTool - å›¢é˜Ÿå·¥å…·]
            TRTT[TaskRunnerTool - ä»»åŠ¡è¿è¡Œå™¨å·¥å…·]
        end
        
        subgraph "ç”¨æˆ·ç•Œé¢"
            CONSOLE[Console - æ§åˆ¶å°ç•Œé¢]
            UI[ç”¨æˆ·ç•Œé¢æŠ½è±¡]
        end
    end
    
    %% ç»§æ‰¿å…³ç³»
    AA --> BCA
    UPA --> BCA
    CEA --> BCA
    SOMA --> BCA
    MFA --> BCA
    
    BCA --> CA
    CA --> TR
    
    BCM --> SM
    BTCM --> BCM
    BAE --> BCM
    
    BGC --> T
    T --> TR
    
    BGCM --> CAC
    
    %% ä¾èµ–å…³ç³»
    BCA --> MF
    BGC --> BGCM
    T --> TS
    CA --> TC
    
    style AA fill:#e1f5fe
    style BCA fill:#f3e5f5
    style BCM fill:#e8f5e8
    style BGC fill:#fff3e0
```

### 1.2 æ ¸å¿ƒè®¾è®¡ç†å¿µ

#### 1. å¯¹è¯ä¼˜å…ˆè®¾è®¡ (Conversation-First Design)
- æ‰€æœ‰ä»£ç†å›´ç»•å¯¹è¯æ¶ˆæ¯å¤„ç†è®¾è®¡
- æ”¯æŒå¤šç§æ¶ˆæ¯ç±»å‹å’Œæ ¼å¼åŒ–è¾“å‡º
- å†…ç½®æµå¼å“åº”å’Œäº‹ä»¶å¤„ç†

#### 2. å›¢é˜Ÿåä½œæ¨¡å‹ (Team Collaboration Model)
- æ”¯æŒå¤šä»£ç†å›¢é˜Ÿåä½œ
- çµæ´»çš„è§’è‰²åˆ†å·¥å’Œä»»åŠ¡åˆ†é…
- å†…ç½®ç¾¤èŠå’Œè·¯ç”±æœºåˆ¶

#### 3. ä»»åŠ¡é©±åŠ¨æ¶æ„ (Task-Driven Architecture)
- åŸºäºä»»åŠ¡çš„ä»£ç†äº¤äº’æ¨¡å¼
- æ”¯æŒå¤æ‚å·¥ä½œæµç¼–æ’
- å†…ç½®ç»ˆæ­¢æ¡ä»¶å’ŒçŠ¶æ€ç®¡ç†

## 2. æ¶ˆæ¯ç³»ç»Ÿè¯¦è§£

### 2.1 æ¶ˆæ¯ç±»å‹å±‚æ¬¡ç»“æ„

#### åŸºç¡€æ¶ˆæ¯æŠ½è±¡

```python
class BaseMessage(BaseModel, ABC):
    """æ‰€æœ‰æ¶ˆæ¯ç±»å‹çš„æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def to_text(self) -> str:
        """è½¬æ¢ä¸ºæ–‡æœ¬è¡¨ç¤ºï¼Œç”¨äºæ§åˆ¶å°æ¸²æŸ“å’Œç”¨æˆ·æ£€æŸ¥"""
        ...
    
    def dump(self) -> Mapping[str, Any]:
        """è½¬æ¢ä¸ºJSONåºåˆ—åŒ–å­—å…¸"""
        return self.model_dump(mode="json")
    
    @classmethod  
    def load(cls, data: Mapping[str, Any]) -> Self:
        """ä»å­—å…¸æ•°æ®åˆ›å»ºæ¶ˆæ¯å®ä¾‹"""
        return cls.model_validate(data)
```

#### èŠå¤©æ¶ˆæ¯æŠ½è±¡

```python
class BaseChatMessage(BaseMessage, ABC):
    """èŠå¤©æ¶ˆæ¯åŸºç±» - ä»£ç†é—´é€šä¿¡çš„æ ¸å¿ƒæ¶ˆæ¯ç±»å‹"""
    
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    """æ¶ˆæ¯å”¯ä¸€æ ‡è¯†ç¬¦"""
    
    source: str
    """å‘é€æ­¤æ¶ˆæ¯çš„ä»£ç†åç§°"""
    
    models_usage: RequestUsage | None = None
    """ç”Ÿæˆæ­¤æ¶ˆæ¯æ—¶çš„æ¨¡å‹ä½¿ç”¨æƒ…å†µ"""
    
    metadata: Dict[str, str] = {}
    """æ¶ˆæ¯çš„é™„åŠ å…ƒæ•°æ®"""
    
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    """æ¶ˆæ¯åˆ›å»ºæ—¶é—´"""
    
    @abstractmethod
    def to_model_text(self) -> str:
        """è½¬æ¢ä¸ºæ¨¡å‹æ–‡æœ¬è¡¨ç¤ºï¼Œç”¨äºæ„é€ æ¨¡å‹è¾“å…¥"""
        ...
    
    @abstractmethod
    def to_model_message(self) -> UserMessage:
        """è½¬æ¢ä¸ºUserMessageï¼Œç”¨äºæ¨¡å‹å®¢æˆ·ç«¯"""
        ...
```

### 2.2 å…·ä½“æ¶ˆæ¯ç±»å‹å®ç°

#### æ–‡æœ¬æ¶ˆæ¯

```python
class TextMessage(BaseTextChatMessage):
    """çº¯æ–‡æœ¬èŠå¤©æ¶ˆæ¯"""
    type: Literal["TextMessage"] = "TextMessage"
    
    def to_text(self) -> str:
        return self.content
    
    def to_model_text(self) -> str:
        return self.content
    
    def to_model_message(self) -> UserMessage:
        return UserMessage(content=self.content, source=self.source)

# ä½¿ç”¨ç¤ºä¾‹
text_msg = TextMessage(
    source="assistant",
    content="Hello, how can I help you today?"
)
```

#### ç»“æ„åŒ–æ¶ˆæ¯

```python
StructuredContentType = TypeVar("StructuredContentType", bound=BaseModel, covariant=True)

class StructuredMessage(BaseChatMessage, Generic[StructuredContentType]):
    """ç»“æ„åŒ–å†…å®¹èŠå¤©æ¶ˆæ¯"""
    type: Literal["StructuredMessage"] = "StructuredMessage"
    content: StructuredContentType
    content_type: str = Field(default="")
    
    def __init__(self, **data: Any) -> None:
        super().__init__(**data)
        # è‡ªåŠ¨è®¾ç½®content_type
        if hasattr(self.content, '__class__'):
            self.content_type = f"{self.content.__class__.__module__}.{self.content.__class__.__qualname__}"
    
    def to_text(self) -> str:
        if hasattr(self.content, 'model_dump_json'):
            return self.content.model_dump_json(indent=2)
        return str(self.content)
    
    def to_model_text(self) -> str:
        return self.to_text()
    
    def to_model_message(self) -> UserMessage:
        return UserMessage(content=self.to_model_text(), source=self.source)

# ä½¿ç”¨ç¤ºä¾‹
@dataclass
class WeatherInfo(BaseModel):
    city: str
    temperature: float
    description: str

weather_msg = StructuredMessage[WeatherInfo](
    source="weather_agent",
    content=WeatherInfo(
        city="Beijing",
        temperature=25.5,
        description="Sunny"
    )
)
```

#### å·¥å…·è°ƒç”¨æ¶ˆæ¯

```python
class ToolCallMessage(BaseChatMessage):
    """å·¥å…·è°ƒç”¨æ¶ˆæ¯"""
    type: Literal["ToolCallMessage"] = "ToolCallMessage"
    tool_calls: List[FunctionCall]
    
    def to_text(self) -> str:
        return f"å·¥å…·è°ƒç”¨: {[call.name for call in self.tool_calls]}"
    
    def to_model_text(self) -> str:
        calls_text = []
        for call in self.tool_calls:
            calls_text.append(f"è°ƒç”¨ {call.name}({call.arguments})")
        return "\n".join(calls_text)
    
    def to_model_message(self) -> UserMessage:
        return UserMessage(content=self.to_model_text(), source=self.source)

class ToolCallResultMessage(BaseChatMessage):
    """å·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯"""
    type: Literal["ToolCallResultMessage"] = "ToolCallResultMessage"  
    tool_call_results: List[FunctionExecutionResult]
    
    def to_text(self) -> str:
        results = []
        for result in self.tool_call_results:
            status = "æˆåŠŸ" if not result.is_error else "å¤±è´¥"
            results.append(f"{result.call_id}: {status}")
        return f"å·¥å…·è°ƒç”¨ç»“æœ: {', '.join(results)}"
```

#### åˆ‡æ¢æ¶ˆæ¯

```python
class HandoffMessage(BaseChatMessage):
    """ä»£ç†åˆ‡æ¢æ¶ˆæ¯ - ç”¨äºå›¢é˜Ÿä¸­çš„ä»£ç†äº¤æ¥"""
    type: Literal["HandoffMessage"] = "HandoffMessage"
    target: str
    """ç›®æ ‡ä»£ç†åç§°"""
    
    context: Any = None
    """ä¼ é€’ç»™ç›®æ ‡ä»£ç†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    
    def to_text(self) -> str:
        return f"åˆ‡æ¢åˆ°: {self.target}"
    
    def to_model_text(self) -> str:
        context_text = f" (ä¸Šä¸‹æ–‡: {self.context})" if self.context else ""
        return f"åˆ‡æ¢åˆ°ä»£ç† {self.target}{context_text}"
    
    def to_model_message(self) -> UserMessage:
        return UserMessage(content=self.to_model_text(), source=self.source)
```

### 2.3 æ¶ˆæ¯å·¥å‚

```python
class MessageFactory:
    """æ¶ˆæ¯å·¥å‚ - è´Ÿè´£æ¶ˆæ¯ç±»å‹çš„æ³¨å†Œå’Œåˆ›å»º"""
    
    def __init__(self) -> None:
        self._message_types: Dict[str, type[BaseChatMessage | BaseAgentEvent]] = {}
        # æ³¨å†Œå†…ç½®æ¶ˆæ¯ç±»å‹
        self._register_builtin_types()
    
    def _register_builtin_types(self) -> None:
        """æ³¨å†Œå†…ç½®æ¶ˆæ¯ç±»å‹"""
        builtin_types = [
            TextMessage,
            StructuredMessage,
            ToolCallMessage,
            ToolCallResultMessage,
            HandoffMessage,
            MultiModalMessage,
            StopMessage,
            ModelClientStreamingChunkEvent,
        ]
        for message_type in builtin_types:
            self._message_types[message_type.__name__] = message_type
    
    def register(self, message_type: type[BaseChatMessage | BaseAgentEvent]) -> None:
        """æ³¨å†Œè‡ªå®šä¹‰æ¶ˆæ¯ç±»å‹"""
        if not hasattr(message_type, 'type'):
            raise ValueError(f"æ¶ˆæ¯ç±»å‹ {message_type.__name__} å¿…é¡»æœ‰ 'type' å­—æ®µ")
        
        self._message_types[message_type.__name__] = message_type
    
    def is_registered(self, message_type: type[BaseChatMessage | BaseAgentEvent]) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯ç±»å‹æ˜¯å¦å·²æ³¨å†Œ"""
        return message_type.__name__ in self._message_types
    
    def create_from_data(self, data: Mapping[str, Any]) -> BaseChatMessage | BaseAgentEvent:
        """ä»æ•°æ®å­—å…¸åˆ›å»ºæ¶ˆæ¯å®ä¾‹"""
        message_type_name = data.get("type")
        if not message_type_name:
            raise ValueError("æ¶ˆæ¯æ•°æ®å¿…é¡»åŒ…å« 'type' å­—æ®µ")
        
        if message_type_name not in self._message_types:
            raise ValueError(f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_type_name}")
        
        message_class = self._message_types[message_type_name]
        return message_class.load(data)

# ä½¿ç”¨ç¤ºä¾‹
factory = MessageFactory()

# æ³¨å†Œè‡ªå®šä¹‰æ¶ˆæ¯ç±»å‹
@dataclass
class CustomMessage(BaseChatMessage):
    type: Literal["CustomMessage"] = "CustomMessage"
    custom_field: str
    
    def to_text(self) -> str:
        return f"è‡ªå®šä¹‰: {self.custom_field}"

factory.register(CustomMessage)

# ä»æ•°æ®åˆ›å»ºæ¶ˆæ¯
data = {
    "type": "CustomMessage",
    "source": "agent1",
    "custom_field": "æµ‹è¯•æ•°æ®"
}
message = factory.create_from_data(data)
```

## 3. ä»£ç†ç³»ç»Ÿè¯¦è§£

### 3.1 èŠå¤©ä»£ç†åè®®

```python
class ChatAgent(ABC, TaskRunner, ComponentBase[BaseModel]):
    """èŠå¤©ä»£ç†åè®®å®šä¹‰"""
    
    component_type = "agent"
    
    @property
    @abstractmethod
    def name(self) -> str:
        """ä»£ç†åç§° - åœ¨å›¢é˜Ÿä¸­ç”¨äºå”¯ä¸€æ ‡è¯†"""
        ...
    
    @property
    @abstractmethod
    def description(self) -> str:
        """ä»£ç†æè¿° - ç”¨äºå›¢é˜Ÿå†³ç­–å’Œä»£ç†é€‰æ‹©"""
        ...
    
    @property
    @abstractmethod
    def produced_message_types(self) -> Sequence[type[BaseChatMessage]]:
        """ä»£ç†å¯äº§ç”Ÿçš„æ¶ˆæ¯ç±»å‹åˆ—è¡¨"""
        ...
    
    @abstractmethod
    async def on_messages(
        self,
        messages: Sequence[BaseChatMessage],
        cancellation_token: CancellationToken
    ) -> Response:
        """å¤„ç†è¾“å…¥æ¶ˆæ¯å¹¶è¿”å›å“åº”"""
        ...
    
    @abstractmethod
    def on_messages_stream(
        self,
        messages: Sequence[BaseChatMessage],
        cancellation_token: CancellationToken
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | Response, None]:
        """å¤„ç†æ¶ˆæ¯å¹¶è¿”å›æµå¼å“åº”"""
        ...
    
    @abstractmethod
    async def on_reset(self, cancellation_token: CancellationToken) -> None:
        """é‡ç½®ä»£ç†åˆ°åˆå§‹çŠ¶æ€"""
        ...
    
    @abstractmethod
    async def on_pause(self, cancellation_token: CancellationToken) -> None:
        """æš‚åœä»£ç†è¿è¡Œ"""
        ...
    
    @abstractmethod
    async def on_resume(self, cancellation_token: CancellationToken) -> None:
        """æ¢å¤ä»£ç†è¿è¡Œ"""
        ...
```

#### å“åº”æ•°æ®ç»“æ„

```python
@dataclass(kw_only=True)
class Response:
    """ä»£ç†å“åº”æ•°æ®ç»“æ„"""
    
    chat_message: BaseChatMessage
    """ä¸»è¦çš„èŠå¤©æ¶ˆæ¯å“åº”"""
    
    inner_messages: Sequence[BaseAgentEvent | BaseChatMessage] | None = None
    """ä»£ç†äº§ç”Ÿçš„å†…éƒ¨æ¶ˆæ¯åºåˆ—"""
```

### 3.2 åŸºç¡€èŠå¤©ä»£ç†

```python
class BaseChatAgent(ChatAgent, ABC, ComponentBase[BaseModel]):
    """èŠå¤©ä»£ç†åŸºç±»å®ç°"""
    
    component_type = "agent"
    
    def __init__(self, name: str, description: str) -> None:
        with trace_create_agent_span(
            agent_name=name,
            agent_description=description,
        ):
            self._name = name
            if not self._name.isidentifier():
                raise ValueError("ä»£ç†åç§°å¿…é¡»æ˜¯æœ‰æ•ˆçš„Pythonæ ‡è¯†ç¬¦")
            self._description = description
    
    @property
    def name(self) -> str:
        return self._name
    
    @property
    def description(self) -> str:
        return self._description
    
    # å®ç°TaskRunneræ¥å£
    async def run(
        self,
        *,
        task: str,
        cancellation_token: CancellationToken | None = None,
    ) -> TaskResult:
        """æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœ"""
        if cancellation_token is None:
            cancellation_token = CancellationToken()
        
        # åˆ›å»ºä»»åŠ¡æ¶ˆæ¯
        task_message = TextMessage(source="user", content=task)
        
        # å¤„ç†æ¶ˆæ¯
        response = await self.on_messages([task_message], cancellation_token)
        
        # æ„å»ºä»»åŠ¡ç»“æœ
        messages = [task_message, response.chat_message]
        if response.inner_messages:
            messages.extend(response.inner_messages)
        
        return TaskResult(messages=messages, stop_reason=None)
    
    def run_stream(
        self,
        *,
        task: str,
        cancellation_token: CancellationToken | None = None,
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | TaskResult, None]:
        """æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›æµå¼ç»“æœ"""
        if cancellation_token is None:
            cancellation_token = CancellationToken()
        
        return self._run_stream_impl(task, cancellation_token)
    
    async def _run_stream_impl(
        self,
        task: str,
        cancellation_token: CancellationToken,
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | TaskResult, None]:
        """æµå¼ä»»åŠ¡æ‰§è¡Œå®ç°"""
        
        # åˆ›å»ºå¹¶å‘é€ä»»åŠ¡æ¶ˆæ¯
        task_message = TextMessage(source="user", content=task)
        yield task_message
        
        messages = [task_message]
        
        # æµå¼å¤„ç†æ¶ˆæ¯
        async for item in self.on_messages_stream([task_message], cancellation_token):
            if isinstance(item, Response):
                # æœ€ç»ˆå“åº”
                messages.append(item.chat_message)
                if item.inner_messages:
                    messages.extend(item.inner_messages)
                
                yield TaskResult(messages=messages, stop_reason=None)
                return
            else:
                # ä¸­é—´æ¶ˆæ¯æˆ–äº‹ä»¶
                yield item
```

### 3.3 åŠ©æ‰‹ä»£ç†å®ç°

#### é…ç½®æ¨¡å‹

```python
class AssistantAgentConfig(BaseModel):
    """åŠ©æ‰‹ä»£ç†é…ç½®"""
    name: str
    model_client: ComponentModel
    tools: list[ComponentModel] | None = None
    workbench: ComponentModel | list[ComponentModel] | None = None
    handoffs: list[str] | None = None
    description: str = "ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ä»£ç†"
    system_message: str | None = None
    model_context: ComponentModel | None = None
    model_client_stream: bool = False
    reflect_on_tool_use: bool | None = None
    output_content_type: str | None = None
    max_tool_iterations: int = 1
    tool_call_summary_format: str = "{result}"
```

#### æ ¸å¿ƒå®ç°

```python
class AssistantAgent(BaseChatAgent, Component[AssistantAgentConfig]):
    """åŠ©æ‰‹ä»£ç† - æ”¯æŒå·¥å…·ä½¿ç”¨çš„æ™ºèƒ½åŠ©æ‰‹"""
    
    component_config_schema = AssistantAgentConfig
    
    def __init__(
        self,
        name: str,
        model_client: ChatCompletionClient,
        tools: List[BaseTool[Any, Any] | Callable[..., Any]] | None = None,
        workbench: Workbench | Sequence[Workbench] | None = None,
        handoffs: List[HandoffBase | str] | None = None,
        model_context: ChatCompletionContext | None = None,
        description: str = "ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ä»£ç†",
        system_message: str | None = None,
        model_client_stream: bool = False,
        reflect_on_tool_use: bool | None = None,
        output_content_type: type[BaseModel] | None = None,
        max_tool_iterations: int = 1,
        tool_call_summary_format: str = "{result}",
        tool_call_summary_formatter: Callable[[FunctionCall, FunctionExecutionResult], str] | None = None,
        **kwargs: Any,
    ) -> None:
        super().__init__(name, description)
        
        self._model_client = model_client
        self._tools = self._prepare_tools(tools or [])
        self._workbench = workbench
        self._handoffs = self._prepare_handoffs(handoffs or [])
        self._model_context = model_context or UnboundedChatCompletionContext()
        self._system_message = system_message
        self._model_client_stream = model_client_stream
        self._reflect_on_tool_use = reflect_on_tool_use
        self._output_content_type = output_content_type
        self._max_tool_iterations = max_tool_iterations
        self._tool_call_summary_format = tool_call_summary_format
        self._tool_call_summary_formatter = tool_call_summary_formatter
        
        # éªŒè¯é…ç½®
        if max_tool_iterations < 1:
            raise ValueError("max_tool_iterations å¿…é¡»å¤§äºç­‰äº1")
        
        if tools and workbench:
            raise ValueError("ä¸èƒ½åŒæ—¶è®¾ç½® tools å’Œ workbench")
        
        # è®¾ç½®é»˜è®¤çš„reflect_on_tool_use
        if self._reflect_on_tool_use is None:
            self._reflect_on_tool_use = output_content_type is not None
    
    @property
    def produced_message_types(self) -> Sequence[type[BaseChatMessage]]:
        """è¿”å›å¯äº§ç”Ÿçš„æ¶ˆæ¯ç±»å‹"""
        types = [TextMessage, ToolCallMessage, ToolCallResultMessage]
        if self._handoffs:
            types.append(HandoffMessage)
        if self._output_content_type:
            types.append(StructuredMessage)
        return types
    
    async def on_messages(
        self,
        messages: Sequence[BaseChatMessage],
        cancellation_token: CancellationToken,
    ) -> Response:
        """å¤„ç†æ¶ˆæ¯çš„æ ¸å¿ƒå®ç°"""
        
        with trace_invoke_agent_span(agent_name=self.name):
            # å°†æ–°æ¶ˆæ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
            for message in messages:
                self._model_context.add_message(message.to_model_message())
            
            # æ‰§è¡Œæ¨ç†å¾ªç¯
            inner_messages: List[BaseAgentEvent | BaseChatMessage] = []
            
            for iteration in range(self._max_tool_iterations):
                # æ¨¡å‹æ¨ç†
                llm_messages = self._prepare_model_messages()
                
                if self._model_client_stream:
                    # æµå¼æ¨ç†ï¼ˆåœ¨åŒæ­¥æ–¹æ³•ä¸­æ”¶é›†æ‰€æœ‰chunksï¼‰
                    chunks = []
                    async for chunk in self._model_client.create_stream(
                        llm_messages,
                        tools=self._tools,
                        cancellation_token=cancellation_token
                    ):
                        chunks.append(chunk)
                    
                    completion = self._combine_streaming_chunks(chunks)
                else:
                    # åŒæ­¥æ¨ç†
                    completion = await self._model_client.create(
                        llm_messages,
                        tools=self._tools,
                        cancellation_token=cancellation_token
                    )
                
                # å¤„ç†å®Œæˆç»“æœ
                response_message, should_continue = await self._process_completion(
                    completion, inner_messages, cancellation_token
                )
                
                if not should_continue:
                    # æ·»åŠ å“åº”åˆ°ä¸Šä¸‹æ–‡
                    if response_message:
                        assistant_message = AssistantMessage(
                            content=response_message.content,
                            source=self.name
                        )
                        self._model_context.add_message(assistant_message)
                    
                    return Response(
                        chat_message=response_message,
                        inner_messages=inner_messages
                    )
            
            # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
            raise RuntimeError(f"è¾¾åˆ°æœ€å¤§å·¥å…·è¿­ä»£æ¬¡æ•° {self._max_tool_iterations}")
    
    def on_messages_stream(
        self,
        messages: Sequence[BaseChatMessage],
        cancellation_token: CancellationToken,
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | Response, None]:
        """æµå¼æ¶ˆæ¯å¤„ç†"""
        return self._on_messages_stream_impl(messages, cancellation_token)
    
    async def _on_messages_stream_impl(
        self,
        messages: Sequence[BaseChatMessage],
        cancellation_token: CancellationToken,
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | Response, None]:
        """æµå¼å¤„ç†å®ç°"""
        
        # å°†æ–°æ¶ˆæ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
        for message in messages:
            self._model_context.add_message(message.to_model_message())
        
        inner_messages: List[BaseAgentEvent | BaseChatMessage] = []
        
        for iteration in range(self._max_tool_iterations):
            # å‡†å¤‡æ¨¡å‹æ¶ˆæ¯
            llm_messages = self._prepare_model_messages()
            
            if self._model_client_stream:
                # æµå¼æ¨ç†
                completion_chunks = []
                async for chunk in self._model_client.create_stream(
                    llm_messages,
                    tools=self._tools,
                    cancellation_token=cancellation_token
                ):
                    # å‘é€æµå¼chunkäº‹ä»¶
                    chunk_event = ModelClientStreamingChunkEvent(
                        source=self.name,
                        content=chunk.content or "",
                        models_usage=chunk.usage
                    )
                    yield chunk_event
                    completion_chunks.append(chunk)
                
                # åˆå¹¶æ‰€æœ‰chunks
                completion = self._combine_streaming_chunks(completion_chunks)
            else:
                # éæµå¼æ¨ç†
                completion = await self._model_client.create(
                    llm_messages,
                    tools=self._tools,
                    cancellation_token=cancellation_token
                )
            
            # å¤„ç†å®Œæˆç»“æœ
            response_message, should_continue = await self._process_completion(
                completion, inner_messages, cancellation_token
            )
            
            # å‘é€å†…éƒ¨æ¶ˆæ¯
            for inner_msg in inner_messages[len(inner_messages) - (1 if response_message else 0):]:
                yield inner_msg
            
            if not should_continue:
                # æ·»åŠ å“åº”åˆ°ä¸Šä¸‹æ–‡
                if response_message:
                    assistant_message = AssistantMessage(
                        content=response_message.content,
                        source=self.name
                    )
                    self._model_context.add_message(assistant_message)
                
                yield Response(
                    chat_message=response_message,
                    inner_messages=inner_messages
                )
                return
        
        raise RuntimeError(f"è¾¾åˆ°æœ€å¤§å·¥å…·è¿­ä»£æ¬¡æ•° {self._max_tool_iterations}")
    
    async def _process_completion(
        self,
        completion: ChatCompletionResponse,
        inner_messages: List[BaseAgentEvent | BaseChatMessage],
        cancellation_token: CancellationToken,
    ) -> tuple[BaseChatMessage, bool]:
        """å¤„ç†æ¨¡å‹å®Œæˆç»“æœ"""
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if completion.content and hasattr(completion.content, 'tool_calls'):
            tool_calls = completion.content.tool_calls
            if tool_calls:
                return await self._handle_tool_calls(
                    tool_calls, inner_messages, cancellation_token
                )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ‡æ¢è¯·æ±‚
        handoff = self._detect_handoff(completion.content)
        if handoff:
            return await self._handle_handoff(handoff, inner_messages)
        
        # æ™®é€šæ–‡æœ¬å“åº”
        content = completion.content if isinstance(completion.content, str) else str(completion.content)
        
        if self._output_content_type and self._reflect_on_tool_use:
            # ç»“æ„åŒ–è¾“å‡º
            try:
                structured_content = self._parse_structured_output(content)
                response_message = StructuredMessage(
                    source=self.name,
                    content=structured_content,
                    models_usage=completion.usage
                )
            except Exception as e:
                logger.warning(f"ç»“æ„åŒ–è¾“å‡ºè§£æå¤±è´¥: {e}")
                response_message = TextMessage(
                    source=self.name,
                    content=content,
                    models_usage=completion.usage
                )
        else:
            # æ–‡æœ¬è¾“å‡º
            response_message = TextMessage(
                source=self.name,
                content=content,
                models_usage=completion.usage
            )
        
        return response_message, False  # ä¸ç»§ç»­è¿­ä»£
    
    async def _handle_tool_calls(
        self,
        tool_calls: List[FunctionCall],
        inner_messages: List[BaseAgentEvent | BaseChatMessage],
        cancellation_token: CancellationToken,
    ) -> tuple[BaseChatMessage, bool]:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        
        # åˆ›å»ºå·¥å…·è°ƒç”¨æ¶ˆæ¯
        tool_call_message = ToolCallMessage(
            source=self.name,
            tool_calls=tool_calls
        )
        inner_messages.append(tool_call_message)
        
        # å¹¶å‘æ‰§è¡Œå·¥å…·è°ƒç”¨
        results = await asyncio.gather(
            *[self._execute_tool_call(call, cancellation_token) for call in tool_calls],
            return_exceptions=True
        )
        
        # å¤„ç†ç»“æœ
        tool_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                tool_results.append(FunctionExecutionResult(
                    call_id=tool_calls[i].id,
                    content=f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(result)}",
                    is_error=True
                ))
            else:
                tool_results.append(result)
        
        # åˆ›å»ºç»“æœæ¶ˆæ¯
        result_message = ToolCallResultMessage(
            source=self.name,
            tool_call_results=tool_results
        )
        inner_messages.append(result_message)
        
        # æ·»åŠ ç»“æœåˆ°æ¨¡å‹ä¸Šä¸‹æ–‡
        for result in tool_results:
            self._model_context.add_message(ToolResultMessage(
                content=result.content,
                call_id=result.call_id
            ))
        
        if self._reflect_on_tool_use:
            # ç»§ç»­è¿­ä»£ï¼Œè®©æ¨¡å‹åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå“åº”
            return result_message, True
        else:
            # ç›´æ¥è¿”å›å·¥å…·è°ƒç”¨æ‘˜è¦
            summary_content = self._create_tool_call_summary(tool_calls, tool_results)
            summary_message = TextMessage(
                source=self.name,
                content=summary_content
            )
            return summary_message, False
    
    def _create_tool_call_summary(
        self,
        tool_calls: List[FunctionCall],
        results: List[FunctionExecutionResult],
    ) -> str:
        """åˆ›å»ºå·¥å…·è°ƒç”¨æ‘˜è¦"""
        summaries = []
        
        for call, result in zip(tool_calls, results):
            if self._tool_call_summary_formatter:
                # ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼åŒ–å™¨
                summary = self._tool_call_summary_formatter(call, result)
            else:
                # ä½¿ç”¨æ ¼å¼åŒ–æ¨¡æ¿
                summary = self._tool_call_summary_format.format(
                    tool_name=call.name,
                    arguments=call.arguments,
                    result=result.content,
                    is_error=result.is_error
                )
            summaries.append(summary)
        
        return "\n".join(summaries)
```

## 4. å›¢é˜Ÿåä½œæœºåˆ¶

### 4.1 å›¢é˜ŸæŠ½è±¡

```python
class Team(ABC, TaskRunner, ComponentBase[BaseModel]):
    """å›¢é˜ŸæŠ½è±¡åè®®"""
    
    component_type = "team"
    
    @property
    @abstractmethod
    def name(self) -> str:
        """å›¢é˜Ÿåç§°"""
        ...
    
    @property
    @abstractmethod
    def description(self) -> str:
        """å›¢é˜Ÿæè¿°"""
        ...
    
    @abstractmethod
    async def reset(self) -> None:
        """é‡ç½®å›¢é˜Ÿå’Œæ‰€æœ‰å‚ä¸è€…åˆ°åˆå§‹çŠ¶æ€"""
        ...
    
    @abstractmethod
    async def pause(self) -> None:
        """æš‚åœå›¢é˜Ÿå’Œæ‰€æœ‰å‚ä¸è€…"""
        ...
    
    @abstractmethod
    async def resume(self) -> None:
        """æ¢å¤å›¢é˜Ÿå’Œæ‰€æœ‰å‚ä¸è€…"""
        ...
    
    @abstractmethod
    async def save_state(self) -> Mapping[str, Any]:
        """ä¿å­˜å›¢é˜Ÿå½“å‰çŠ¶æ€"""
        ...
    
    @abstractmethod
    async def load_state(self, state: Mapping[str, Any]) -> None:
        """åŠ è½½å›¢é˜ŸçŠ¶æ€"""
        ...
```

### 4.2 ç¾¤èŠå›¢é˜ŸåŸºç±»

```python
class BaseGroupChat(Team, ABC, ComponentBase[BaseModel]):
    """ç¾¤èŠå›¢é˜ŸåŸºç±»"""
    
    def __init__(
        self,
        name: str,
        description: str,
        participants: List[ChatAgent | Team],
        group_chat_manager_name: str,
        group_chat_manager_class: type[SequentialRoutedAgent],
        termination_condition: TerminationCondition | None = None,
        max_turns: int | None = None,
        runtime: AgentRuntime | None = None,
        custom_message_types: List[type[BaseAgentEvent | BaseChatMessage]] | None = None,
        emit_team_events: bool = False,
    ):
        self._name = name
        self._description = description
        
        if len(participants) == 0:
            raise ValueError("è‡³å°‘éœ€è¦ä¸€ä¸ªå‚ä¸è€…")
        
        # æ£€æŸ¥å‚ä¸è€…åç§°å”¯ä¸€æ€§
        names = [participant.name for participant in participants]
        if len(names) != len(set(names)):
            raise ValueError("å‚ä¸è€…åç§°å¿…é¡»å”¯ä¸€")
        
        self._participants = participants
        self._base_group_chat_manager_class = group_chat_manager_class
        self._termination_condition = termination_condition
        self._max_turns = max_turns
        self._emit_team_events = emit_team_events
        
        # åˆ›å»ºæ¶ˆæ¯å·¥å‚å¹¶æ³¨å†Œæ¶ˆæ¯ç±»å‹
        self._message_factory = MessageFactory()
        if custom_message_types:
            for message_type in custom_message_types:
                self._message_factory.register(message_type)
        
        # æ³¨å†Œå‚ä¸è€…äº§ç”Ÿçš„æ¶ˆæ¯ç±»å‹
        for participant in participants:
            if isinstance(participant, ChatAgent):
                for message_type in participant.produced_message_types:
                    if issubclass(message_type, StructuredMessage) and not self._message_factory.is_registered(message_type):
                        self._message_factory.register(message_type)
        
        # åˆ›å»ºè¿è¡Œæ—¶
        self._runtime = runtime or SingleThreadedAgentRuntime()
        self._runtime_manager = self._create_runtime_manager()
        
        # æ³¨å†Œä»£ç†å’Œç¾¤èŠç®¡ç†å™¨
        asyncio.create_task(self._setup_runtime())
    
    async def _setup_runtime(self) -> None:
        """è®¾ç½®è¿è¡Œæ—¶ç¯å¢ƒ"""
        
        # æ³¨å†Œç¾¤èŠç®¡ç†å™¨
        await self._register_group_chat_manager()
        
        # æ³¨å†Œå‚ä¸è€…å®¹å™¨
        for i, participant in enumerate(self._participants):
            container = ChatAgentContainer(
                parent_topic_type=self._group_chat_manager_name,
                output_topic_type=f"{self._group_chat_manager_name}_participant_{i}",
                agent=participant,
                message_factory=self._message_factory
            )
            
            container_agent_type = f"{self._group_chat_manager_name}_participant_{i}"
            await container.register(
                self._runtime,
                container_agent_type,
                lambda: container
            )
    
    async def _register_group_chat_manager(self) -> None:
        """æ³¨å†Œç¾¤èŠç®¡ç†å™¨"""
        manager = self._base_group_chat_manager_class(
            description=self._description,
            participants=self._participants,
            message_factory=self._message_factory,
            termination_condition=self._termination_condition,
            max_turns=self._max_turns
        )
        
        await manager.register(
            self._runtime,
            self._group_chat_manager_name,
            lambda: manager
        )
```

### 4.3 ä»£ç†å®¹å™¨

```python
class ChatAgentContainer(SequentialRoutedAgent):
    """èŠå¤©ä»£ç†å®¹å™¨ - å°†ChatAgentåŒ…è£…ä¸ºCoreä»£ç†"""
    
    def __init__(
        self,
        parent_topic_type: str,
        output_topic_type: str,
        agent: ChatAgent | Team,
        message_factory: MessageFactory,
    ) -> None:
        super().__init__(
            description=agent.description,
            sequential_message_types=[
                GroupChatStart,
                GroupChatRequestPublish,
                GroupChatReset,
                GroupChatAgentResponse,
                GroupChatTeamResponse,
            ]
        )
        self._parent_topic_type = parent_topic_type
        self._output_topic_type = output_topic_type
        self._agent = agent
        self._message_buffer: List[BaseChatMessage] = []
        self._message_factory = message_factory
    
    @event
    async def handle_start(self, message: GroupChatStart, ctx: MessageContext) -> None:
        """å¤„ç†ç¾¤èŠå¼€å§‹äº‹ä»¶"""
        # æ¸…ç©ºæ¶ˆæ¯ç¼“å†²åŒº
        self._message_buffer.clear()
        
        # å¦‚æœæœ‰åˆå§‹æ¶ˆæ¯ï¼Œæ·»åŠ åˆ°ç¼“å†²åŒº
        if message.messages:
            for msg_data in message.messages:
                chat_message = self._message_factory.create_from_data(msg_data)
                if isinstance(chat_message, BaseChatMessage):
                    self._message_buffer.append(chat_message)
    
    @event
    async def handle_request_publish(self, message: GroupChatRequestPublish, ctx: MessageContext) -> None:
        """å¤„ç†å‘å¸ƒè¯·æ±‚äº‹ä»¶"""
        try:
            if isinstance(self._agent, ChatAgent):
                # è°ƒç”¨èŠå¤©ä»£ç†
                response = await self._agent.on_messages(
                    self._message_buffer.copy(),
                    ctx.cancellation_token
                )
                
                # å‘å¸ƒä»£ç†å“åº”
                await self.publish_message(
                    GroupChatAgentResponse(
                        agent_name=self._agent.name,
                        response=response.chat_message.dump(),
                        inner_messages=[msg.dump() for msg in (response.inner_messages or [])]
                    ),
                    DefaultTopicId(self._output_topic_type, self.id.key)
                )
            
            elif isinstance(self._agent, Team):
                # è°ƒç”¨å›¢é˜Ÿ
                # æ„å»ºä»»åŠ¡å†…å®¹
                if self._message_buffer:
                    task_content = "\n".join(msg.to_text() for msg in self._message_buffer)
                else:
                    task_content = ""
                
                result = await self._agent.run(task=task_content)
                
                # å‘å¸ƒå›¢é˜Ÿå“åº”
                await self.publish_message(
                    GroupChatTeamResponse(
                        team_name=self._agent.name,
                        messages=[msg.dump() for msg in result.messages],
                        stop_reason=result.stop_reason
                    ),
                    DefaultTopicId(self._output_topic_type, self.id.key)
                )
        
        except Exception as e:
            # å‘å¸ƒé”™è¯¯ä¿¡æ¯
            await self.publish_message(
                GroupChatError(
                    agent_name=self._agent.name,
                    error=SerializableException.from_exception(e)
                ),
                DefaultTopicId(self._output_topic_type, self.id.key)
            )
    
    @event  
    async def handle_agent_response(self, message: GroupChatAgentResponse, ctx: MessageContext) -> None:
        """å¤„ç†å…¶ä»–ä»£ç†çš„å“åº”"""
        # å°†å“åº”æ¶ˆæ¯æ·»åŠ åˆ°ç¼“å†²åŒº
        if message.agent_name != self._agent.name:
            chat_message = self._message_factory.create_from_data(message.response)
            if isinstance(chat_message, BaseChatMessage):
                self._message_buffer.append(chat_message)
    
    @event
    async def handle_reset(self, message: GroupChatReset, ctx: MessageContext) -> None:
        """å¤„ç†é‡ç½®äº‹ä»¶"""
        # æ¸…ç©ºæ¶ˆæ¯ç¼“å†²åŒº
        self._message_buffer.clear()
        
        # é‡ç½®ä»£ç†
        if isinstance(self._agent, ChatAgent):
            await self._agent.on_reset(ctx.cancellation_token)
        elif isinstance(self._agent, Team):
            await self._agent.reset()
```

## 5. ä¸“ä¸šä»£ç†å®ç°è¯¦è§£

### 5.1 Orchestratoråè°ƒå™¨ä»£ç†

Orchestratoræ˜¯AutoGençš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£æ•´ä¸ªä»»åŠ¡çš„è§„åˆ’ã€è¿›åº¦è·Ÿè¸ªåŠé”™è¯¯æ¢å¤ã€‚å…¶ä¸»è¦èŒè´£åŒ…æ‹¬ï¼š

- **ä»»åŠ¡åˆ†æ**ï¼šæ·±åº¦åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œç¡®å®šå¤æ‚åº¦å’Œæ‰€éœ€èµ„æº
- **æ™ºèƒ½åˆ†å·¥**ï¼šæ ¹æ®ä»£ç†èƒ½åŠ›å’Œä»»åŠ¡ç‰¹ç‚¹è¿›è¡Œæœ€ä¼˜åˆ†é…
- **è¿›åº¦ç›‘æ§**ï¼šå®æ—¶è·Ÿè¸ªå„å­ä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€
- **é”™è¯¯æ¢å¤**ï¼šåœ¨å‡ºç°å¼‚å¸¸æ—¶è¿›è¡Œæ™ºèƒ½æ¢å¤å’Œé‡æ–°åˆ†é…

```python
async def analyze_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œç¡®å®šä»»åŠ¡çš„å¤æ‚åº¦å’Œæ‰€éœ€èµ„æº
    
    è¯¥å‡½æ•°æ˜¯Orchestratorçš„æ ¸å¿ƒæ–¹æ³•ï¼Œé€šè¿‡LLMåˆ†æä»»åŠ¡æè¿°ï¼Œ
    è¯†åˆ«æ‰€éœ€çš„ä¸“ä¸šæŠ€èƒ½ï¼Œä¼°ç®—æ‰§è¡Œæ—¶é—´ï¼Œå¹¶è¯„ä¼°æ½œåœ¨é£é™©ã€‚
    
    Args:
        task: åŒ…å«ä»»åŠ¡è¯¦ç»†ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬descriptionã€expected_outputç­‰
        
    Returns:
        Dict: è¯¦ç»†çš„åˆ†æç»“æœï¼ŒåŒ…æ‹¬ä»»åŠ¡åˆ†è§£ã€æŠ€èƒ½éœ€æ±‚ã€æ—¶é—´ä¼°ç®—ç­‰
    """
    # å®ç°ä»»åŠ¡åˆ†æçš„æ ¸å¿ƒé€»è¾‘
    pass

async def assign_subtasks(self, task_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    å°†å­ä»»åŠ¡åˆ†é…ç»™ç›¸åº”çš„ä¸“ä¸šä»£ç†
    
    è¯¥å‡½æ•°å®ç°æ™ºèƒ½çš„ä»»åŠ¡åˆ†é…ç®—æ³•ï¼Œè€ƒè™‘ä»£ç†è´Ÿè½½ã€æŠ€èƒ½åŒ¹é…åº¦ã€
    ä»»åŠ¡ä¾èµ–å…³ç³»ç­‰å› ç´ ï¼Œå®ç°æœ€ä¼˜çš„ä»»åŠ¡åˆ†é…ã€‚
    
    Args:
        task_analysis: æ¥è‡ªanalyze_taskçš„åˆ†æç»“æœ
        
    Returns:
        List[Dict]: åŒ…å«åˆ†é…è¯¦æƒ…çš„å­ä»»åŠ¡åˆ—è¡¨
    """
    # å®ç°æ™ºèƒ½ä»»åŠ¡åˆ†é…é€»è¾‘
    pass
```

### 5.2 WebSurferç½‘é¡µæµè§ˆä»£ç†

WebSurferè´Ÿè´£å¤„ç†ç½‘é¡µæµè§ˆç›¸å…³çš„æ“ä½œï¼Œé€šè¿‡å¼‚æ­¥äº‹ä»¶é©±åŠ¨æ–¹å¼æé«˜ç³»ç»Ÿæ•ˆç‡ï¼š

```python
async def fetch_web_content(self, url: str) -> str:
    """
    å¼‚æ­¥è·å–æŒ‡å®šURLçš„ç½‘é¡µå†…å®¹
    
    é‡‡ç”¨é«˜æ•ˆçš„å¼‚æ­¥HTTPå®¢æˆ·ç«¯ï¼Œæ”¯æŒè¿æ¥æ± å¤ç”¨å’Œæ™ºèƒ½ç¼“å­˜ï¼Œ
    å¤§å¹…æå‡ç½‘é¡µå†…å®¹è·å–çš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚
    
    Args:
        url: ç›®æ ‡ç½‘é¡µçš„URL
        
    Returns:
        str: ç½‘é¡µçš„HTMLå†…å®¹
    """
    # å®ç°é«˜æ€§èƒ½ç½‘é¡µå†…å®¹è·å–
    pass

async def extract_information(self, html_content: str) -> Dict[str, Any]:
    """
    ä»ç½‘é¡µHTMLå†…å®¹ä¸­æå–æ‰€éœ€ä¿¡æ¯
    
    ä½¿ç”¨å…ˆè¿›çš„HTMLè§£æå’Œä¿¡æ¯æå–ç®—æ³•ï¼Œæ”¯æŒç»“æ„åŒ–æ•°æ®æå–ã€
    æ™ºèƒ½å†…å®¹è¯†åˆ«å’Œå¤šç§æå–è§„åˆ™é…ç½®ã€‚
    
    Args:
        html_content: ç½‘é¡µçš„HTMLå†…å®¹
        
    Returns:
        Dict: æå–çš„ç»“æ„åŒ–ä¿¡æ¯
    """
    # å®ç°æ™ºèƒ½ä¿¡æ¯æå–é€»è¾‘
    pass
```

### 5.3 é«˜çº§ç‰¹æ€§

### 5.4 ç»ˆæ­¢æ¡ä»¶

```python
class TerminationCondition(ABC, ComponentBase[BaseModel]):
    """ç»ˆæ­¢æ¡ä»¶æŠ½è±¡åŸºç±»"""
    
    component_type = "termination"
    
    @abstractmethod
    async def __call__(self, messages: Sequence[BaseChatMessage]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç»ˆæ­¢æ¡ä»¶"""
        ...

class MaxMessageTermination(TerminationCondition):
    """æœ€å¤§æ¶ˆæ¯æ•°ç»ˆæ­¢æ¡ä»¶"""
    
    def __init__(self, max_messages: int):
        self._max_messages = max_messages
    
    async def __call__(self, messages: Sequence[BaseChatMessage]) -> bool:
        return len(messages) >= self._max_messages

class StopMessageTermination(TerminationCondition):
    """åœæ­¢æ¶ˆæ¯ç»ˆæ­¢æ¡ä»¶"""
    
    async def __call__(self, messages: Sequence[BaseChatMessage]) -> bool:
        if not messages:
            return False
        
        last_message = messages[-1]
        if isinstance(last_message, StopMessage):
            return True
        
        # æ£€æŸ¥æ¶ˆæ¯å†…å®¹æ˜¯å¦åŒ…å«TERMINATE
        content = last_message.to_text().upper()
        return "TERMINATE" in content

class TextMentionTermination(TerminationCondition):
    """æ–‡æœ¬æåŠç»ˆæ­¢æ¡ä»¶"""
    
    def __init__(self, text: str):
        self._text = text.upper()
    
    async def __call__(self, messages: Sequence[BaseChatMessage]) -> bool:
        if not messages:
            return False
        
        last_message = messages[-1]
        content = last_message.to_text().upper()
        return self._text in content
```

### 5.2 å·¥å…·é›†æˆ

```python
class AgentTool(TaskRunnerTool, Component[AgentToolConfig]):
    """ä»£ç†å·¥å…· - å°†ä»£ç†åŒ…è£…ä¸ºå·¥å…·"""
    
    def __init__(
        self,
        agent: ChatAgent,
        return_value_as_last_message: bool = False,
        description: str | None = None,
    ):
        if description is None:
            description = f"ä½¿ç”¨ {agent.name} ä»£ç†: {agent.description}"
        
        super().__init__(description, return_value_as_last_message)
        self._agent = agent
    
    async def run(
        self,
        task: str,
        cancellation_token: CancellationToken | None = None,
    ) -> str:
        """æ‰§è¡Œä»£ç†ä»»åŠ¡"""
        if cancellation_token is None:
            cancellation_token = CancellationToken()
        
        result = await self._agent.run(task=task, cancellation_token=cancellation_token)
        
        if self._return_value_as_last_message and result.messages:
            return result.messages[-1].to_text()
        
        # è¿”å›æ‰€æœ‰æ¶ˆæ¯çš„æ–‡æœ¬è¡¨ç¤º
        return "\n".join(msg.to_text() for msg in result.messages)

class TeamTool(TaskRunnerTool, Component[TeamToolConfig]):
    """å›¢é˜Ÿå·¥å…· - å°†å›¢é˜ŸåŒ…è£…ä¸ºå·¥å…·"""
    
    def __init__(
        self,
        team: Team,
        return_value_as_last_message: bool = False,
        description: str | None = None,
    ):
        if description is None:
            description = f"ä½¿ç”¨ {team.name} å›¢é˜Ÿ: {team.description}"
        
        super().__init__(description, return_value_as_last_message)
        self._team = team
    
    async def run(
        self,
        task: str,
        cancellation_token: CancellationToken | None = None,
    ) -> str:
        """æ‰§è¡Œå›¢é˜Ÿä»»åŠ¡"""
        if cancellation_token is None:
            cancellation_token = CancellationToken()
        
        result = await self._team.run(task=task, cancellation_token=cancellation_token)
        
        if self._return_value_as_last_message and result.messages:
            return result.messages[-1].to_text()
        
        return "\n".join(msg.to_text() for msg in result.messages)
```

### 5.3 ç”¨æˆ·ç•Œé¢

```python
class Console:
    """æ§åˆ¶å°ç”¨æˆ·ç•Œé¢"""
    
    def __init__(self, stream: AsyncGenerator[Any, None]):
        self._stream = stream
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        pass
    
    def __await__(self):
        """ä½¿Consoleå¯ç­‰å¾…"""
        return self._run().__await__()
    
    async def _run(self) -> None:
        """è¿è¡Œæ§åˆ¶å°æ˜¾ç¤º"""
        async for item in self._stream:
            self._display_item(item)
    
    def _display_item(self, item: Any) -> None:
        """æ˜¾ç¤ºå•ä¸ªé¡¹ç›®"""
        if isinstance(item, BaseChatMessage):
            self._display_chat_message(item)
        elif isinstance(item, BaseAgentEvent):
            self._display_agent_event(item)
        elif isinstance(item, TaskResult):
            self._display_task_result(item)
        elif isinstance(item, Response):
            self._display_response(item)
        else:
            print(f"æœªçŸ¥é¡¹ç›®ç±»å‹: {type(item)}")
    
    def _display_chat_message(self, message: BaseChatMessage) -> None:
        """æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯"""
        timestamp = message.created_at.strftime("%H:%M:%S")
        print(f"[{timestamp}] {message.source}: {message.to_text()}")
        
        if message.models_usage:
            usage = message.models_usage
            print(f"    ğŸ“Š æ¨¡å‹ä½¿ç”¨: {usage.prompt_tokens} + {usage.completion_tokens} = {usage.total_tokens} tokens")
    
    def _display_agent_event(self, event: BaseAgentEvent) -> None:
        """æ˜¾ç¤ºä»£ç†äº‹ä»¶"""
        timestamp = event.created_at.strftime("%H:%M:%S")
        print(f"[{timestamp}] ğŸ”” {event.source}: {event.to_text()}")
    
    def _display_task_result(self, result: TaskResult) -> None:
        """æ˜¾ç¤ºä»»åŠ¡ç»“æœ"""
        print("=" * 50)
        print("ğŸ“‹ ä»»åŠ¡å®Œæˆ")
        print(f"åœæ­¢åŸå› : {result.stop_reason or 'æ­£å¸¸å®Œæˆ'}")
        print(f"æ¶ˆæ¯æ•°é‡: {len(result.messages)}")
        print("=" * 50)
    
    def _display_response(self, response: Response) -> None:
        """æ˜¾ç¤ºå“åº”"""
        print("ğŸ’¬ ä»£ç†å“åº”:")
        self._display_chat_message(response.chat_message)
        
        if response.inner_messages:
            print("ğŸ” å†…éƒ¨æ¶ˆæ¯:")
            for msg in response.inner_messages:
                if isinstance(msg, BaseChatMessage):
                    self._display_chat_message(msg)
                else:
                    self._display_agent_event(msg)

# ä½¿ç”¨ç¤ºä¾‹
async def demo_console():
    # åˆ›å»ºä»£ç†
    model_client = OpenAIChatCompletionClient(model="gpt-4")
    agent = AssistantAgent("assistant", model_client)
    
    # è¿è¡Œå¹¶æ˜¾ç¤ºç»“æœ
    await Console(agent.run_stream(task="ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€"))
```

## 6. ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ

### 6.1 åŸºç¡€ä»£ç†ä½¿ç”¨

```python
import asyncio
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console

async def basic_agent_example():
    """åŸºç¡€ä»£ç†ä½¿ç”¨ç¤ºä¾‹"""
    
    # åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯
    model_client = OpenAIChatCompletionClient(
        model="gpt-4o",
        api_key="your_openai_api_key"
    )
    
    # åˆ›å»ºåŠ©æ‰‹ä»£ç†
    agent = AssistantAgent(
        name="assistant",
        model_client=model_client,
        description="ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹"
    )
    
    # è¿è¡Œä»»åŠ¡
    result = await agent.run(task="è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ")
    
    # æ‰“å°ç»“æœ
    for message in result.messages:
        print(f"{message.source}: {message.to_text()}")

asyncio.run(basic_agent_example())
```

### 6.2 å¸¦å·¥å…·çš„ä»£ç†

```python
async def agent_with_tools_example():
    """å¸¦å·¥å…·çš„ä»£ç†ç¤ºä¾‹"""
    
    # å®šä¹‰å·¥å…·å‡½æ•°
    async def get_weather(city: str) -> str:
        """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        await asyncio.sleep(0.1)
        return f"{city}ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ¸©åº¦25Â°C"
    
    def calculate(expression: str) -> str:
        """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
        try:
            result = eval(expression)
            return f"è®¡ç®—ç»“æœ: {result}"
        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {e}"
    
    # åˆ›å»ºä»£ç†
    model_client = OpenAIChatCompletionClient(model="gpt-4o")
    agent = AssistantAgent(
        name="assistant",
        model_client=model_client,
        tools=[get_weather, calculate],
        description="å¯ä»¥æŸ¥è¯¢å¤©æ°”å’Œè®¡ç®—æ•°å­¦è¡¨è¾¾å¼çš„åŠ©æ‰‹"
    )
    
    # è¿è¡Œå¹¶æ˜¾ç¤ºæµå¼ç»“æœ
    await Console(agent.run_stream(
        task="åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿå¦å¤–å¸®æˆ‘è®¡ç®— 123 * 456"
    ))

asyncio.run(agent_with_tools_example())
```

### 6.3 å›¢é˜Ÿåä½œç¤ºä¾‹

```python
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import MaxMessageTermination

async def team_collaboration_example():
    """å›¢é˜Ÿåä½œç¤ºä¾‹"""
    
    model_client = OpenAIChatCompletionClient(model="gpt-4o")
    
    # åˆ›å»ºä¸åŒè§’è‰²çš„ä»£ç†
    writer = AssistantAgent(
        name="writer",
        model_client=model_client,
        description="ä¸“é—¨è´Ÿè´£åˆ›ä½œå’Œå†™ä½œçš„ä»£ç†",
        system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œå„ç§ç±»å‹çš„æ–‡æœ¬å†…å®¹ã€‚"
    )
    
    reviewer = AssistantAgent(
        name="reviewer",
        model_client=model_client,
        description="ä¸“é—¨è´Ÿè´£å®¡æŸ¥å’Œæ”¹è¿›æ–‡æœ¬çš„ä»£ç†",
        system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–è¾‘ï¼Œè´Ÿè´£å®¡æŸ¥æ–‡æœ¬å¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚"
    )
    
    finalizer = AssistantAgent(
        name="finalizer",
        model_client=model_client,
        description="è´Ÿè´£æœ€ç»ˆç¡®å®šå’Œå®Œå–„æ–‡æœ¬çš„ä»£ç†",
        system_message="ä½ è´Ÿè´£æ ¹æ®åé¦ˆå®Œå–„æ–‡æœ¬ï¼Œå¹¶æä¾›æœ€ç»ˆç‰ˆæœ¬ã€‚è¯·åœ¨å®Œæˆåè¯´'TERMINATE'ã€‚"
    )
    
    # åˆ›å»ºå›¢é˜Ÿ
    team = RoundRobinGroupChat(
        name="writing_team",
        description="ä¸€ä¸ªåä½œå†™ä½œå›¢é˜Ÿ",
        participants=[writer, reviewer, finalizer],
        termination_condition=MaxMessageTermination(10)
    )
    
    # è¿è¡Œä»»åŠ¡
    await Console(team.run_stream(
        task="å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½æœªæ¥å‘å±•çš„çŸ­æ–‡ï¼Œè¦æ±‚è§‚ç‚¹æ˜ç¡®ï¼Œé€»è¾‘æ¸…æ™°ï¼Œçº¦200å­—ã€‚"
    ))

asyncio.run(team_collaboration_example())
```

### 6.4 æœ€ä½³å®è·µå»ºè®®

#### 1. ä»£ç†è®¾è®¡åŸåˆ™
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªä»£ç†ä¸“æ³¨äºç‰¹å®šçš„ä»»åŠ¡é¢†åŸŸ
- **æ˜ç¡®æè¿°**ï¼šæä¾›æ¸…æ™°çš„ä»£ç†æè¿°ï¼Œä¾¿äºå›¢é˜Ÿé€‰æ‹©
- **åˆç†å·¥å…·é…ç½®**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚é…ç½®åˆé€‚çš„å·¥å…·

#### 2. æ€§èƒ½ä¼˜åŒ–
- **æµå¼å¤„ç†**ï¼šå¯¹äºé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Œä½¿ç”¨æµå¼æ¥å£
- **å¹¶å‘å·¥å…·è°ƒç”¨**ï¼šå¯ç”¨å¹¶è¡Œå·¥å…·è°ƒç”¨ä»¥æé«˜æ•ˆç‡
- **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šåˆç†æ§åˆ¶æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦

#### 3. é”™è¯¯å¤„ç†
- **å–æ¶ˆä»¤ç‰Œ**ï¼šæ­£ç¡®å¤„ç†ä»»åŠ¡å–æ¶ˆ
- **å¼‚å¸¸æ¢å¤**ï¼šå®ç°ä¼˜é›…çš„å¼‚å¸¸å¤„ç†å’Œæ¢å¤
- **èµ„æºæ¸…ç†**ï¼šç¡®ä¿ä»£ç†å’Œå›¢é˜Ÿçš„æ­£ç¡®æ¸…ç†

#### 4. ç›‘æ§å’Œè°ƒè¯•
- **ç»“æ„åŒ–æ—¥å¿—**ï¼šä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—è®°å½•å…³é”®äº‹ä»¶
- **æ€§èƒ½ç›‘æ§**ï¼šç›‘æ§æ¨¡å‹ä½¿ç”¨å’Œå“åº”æ—¶é—´
- **è°ƒè¯•å·¥å…·**ï¼šåˆ©ç”¨Consoleç­‰å·¥å…·è¿›è¡Œè°ƒè¯•

### 6.5 å…³é”®å‡½æ•°ï¼šæ ¸å¿ƒä»£ç è¦ç‚¹ã€è°ƒç”¨é“¾ä¸æ—¶åºå›¾

- BaseChatAgent.run / run_streamï¼ˆä»»åŠ¡æ‰§è¡Œå…¥å£ï¼‰

```python
class BaseChatAgent(ChatAgent, ABC, ComponentBase[BaseModel]):
    async def run(self, *, task: str, cancellation_token: CancellationToken | None = None) -> TaskResult:
        if cancellation_token is None:
            cancellation_token = CancellationToken()
        task_message = TextMessage(source="user", content=task)
        response = await self.on_messages([task_message], cancellation_token)
        messages = [task_message, response.chat_message]
        if response.inner_messages:
            messages.extend(response.inner_messages)
        return TaskResult(messages=messages, stop_reason=None)

    def run_stream(self, *, task: str, cancellation_token: CancellationToken | None = None):
        if cancellation_token is None:
            cancellation_token = CancellationToken()
        return self._run_stream_impl(task, cancellation_token)
```

è°ƒç”¨é“¾ï¼ˆå…¸å‹ï¼‰ï¼š

- è°ƒç”¨æ–¹ â†’ `BaseChatAgent.run` â†’ `on_messages` â†’ `Response` â†’ `TaskResult`

æ—¶åºå›¾ï¼š

```mermaid
sequenceDiagram
    participant C as Caller
    participant A as BaseChatAgent
    participant IM as on_messages
    C->>A: run(task)
    A->>IM: on_messages([TextMessage], ct)
    IM-->>A: Response
    A-->>C: TaskResult
```

- AssistantAgent.on_messages/_process_completion/_handle_tool_callsï¼ˆæ¨ç†ä¸»å¾ªç¯ï¼‰

```python
class AssistantAgent(BaseChatAgent, Component[AssistantAgentConfig]):
    async def on_messages(self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken) -> Response:
        for m in messages:
            self._model_context.add_message(m.to_model_message())
        inner: list[BaseAgentEvent | BaseChatMessage] = []
        for _ in range(self._max_tool_iterations):
            completion = await self._model_client.create(
                self._prepare_model_messages(), tools=self._tools, cancellation_token=cancellation_token
            )
            rsp, cont = await self._process_completion(completion, inner, cancellation_token)
            if not cont:
                if rsp:
                    self._model_context.add_message(AssistantMessage(content=rsp.content, source=self.name))
                return Response(chat_message=rsp, inner_messages=inner)
        raise RuntimeError("è¾¾åˆ°æœ€å¤§å·¥å…·è¿­ä»£æ¬¡æ•°")
```

è°ƒç”¨é“¾ï¼ˆå…¸å‹ï¼‰ï¼š

- `BaseChatAgent.run`/Team â†’ `AssistantAgent.on_messages` â†’ `ModelClient.create` â†’ `_process_completion` â†’ [å¯é€‰]`_handle_tool_calls`

æ—¶åºå›¾ï¼š

```mermaid
sequenceDiagram
    participant A as AssistantAgent
    participant MC as ModelClient
    participant TL as Tools
    A->>MC: create(messages, tools)
    MC-->>A: completion
    alt åŒ…å«å·¥å…·è°ƒç”¨
        A->>TL: å¹¶å‘æ‰§è¡Œ tool_calls
        TL-->>A: results
        A->>MC: ï¼ˆå¯é€‰ï¼‰å†æ¨ç†
        MC-->>A: completion'
    end
    A-->>A: ç”Ÿæˆ Response
```

- ChatAgentContainer.handle_request_publishï¼ˆå›¢é˜Ÿå®¹å™¨è½¬å‘ï¼‰

```python
class ChatAgentContainer(SequentialRoutedAgent):
    @event
    async def handle_request_publish(self, message: GroupChatRequestPublish, ctx: MessageContext) -> None:
        if isinstance(self._agent, ChatAgent):
            response = await self._agent.on_messages(self._message_buffer.copy(), ctx.cancellation_token)
            await self.publish_message(
                GroupChatAgentResponse(
                    agent_name=self._agent.name,
                    response=response.chat_message.dump(),
                    inner_messages=[msg.dump() for msg in (response.inner_messages or [])]
                ),
                DefaultTopicId(self._output_topic_type, self.id.key)
            )
```

è°ƒç”¨é“¾ï¼ˆå…¸å‹ï¼‰ï¼š

- GroupChatManager â†’ `ChatAgentContainer.handle_request_publish` â†’ å‚ä¸è€… `on_messages` â†’ å›å‘ `GroupChatAgentResponse`

æ—¶åºå›¾ï¼š

```mermaid
sequenceDiagram
    participant GM as GroupChatManager
    participant CC as ChatAgentContainer
    participant P as Participant(ChatAgent)
    GM->>CC: GroupChatRequestPublish
    CC->>P: on_messages(buffer)
    P-->>CC: Response
    CC-->>GM: GroupChatAgentResponse
```

- MessageFactory.create_from_dataï¼ˆæ¶ˆæ¯æ„é€ ï¼‰

```python
class MessageFactory:
    def create_from_data(self, data: Mapping[str, Any]) -> BaseChatMessage | BaseAgentEvent:
        message_type_name = data.get("type")
        if not message_type_name or message_type_name not in self._message_types:
            raise ValueError("æœªçŸ¥æˆ–ç¼ºå¤±çš„æ¶ˆæ¯ç±»å‹")
        message_class = self._message_types[message_type_name]
        return message_class.load(data)
```

è°ƒç”¨é“¾ï¼ˆå…¸å‹ï¼‰ï¼š

- ååºåˆ—åŒ–/å®¹å™¨ â†’ `MessageFactory.create_from_data` â†’ å…·ä½“ `Message.load`

### 6.6 å…³é”®ç»“æ„ä½“ä¸ç±»ï¼šç»“æ„å›¾ä¸ç»§æ‰¿å…³ç³»

```mermaid
classDiagram
    class ChatAgent
    class BaseChatAgent
    class AssistantAgent
    class Team
    class BaseGroupChat
    class ChatAgentContainer

    ChatAgent <|.. BaseChatAgent
    BaseChatAgent <|-- AssistantAgent
    Team <|.. BaseGroupChat
    BaseGroupChat o--> ChatAgentContainer : contains
```

## 7. æ€»ç»“

AutoGen Python AgentChatæ¨¡å—é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æŠ½è±¡å±‚æ¬¡ï¼Œä¸ºæ„å»ºæ™ºèƒ½å¯¹è¯ç³»ç»Ÿæä¾›äº†å¼ºå¤§è€Œçµæ´»çš„åŸºç¡€è®¾æ–½ã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ï¼š

1. **ä¸°å¯Œçš„æ¶ˆæ¯ç±»å‹ç³»ç»Ÿ**ï¼šæ”¯æŒæ–‡æœ¬ã€ç»“æ„åŒ–ã€å·¥å…·è°ƒç”¨ç­‰å¤šç§æ¶ˆæ¯æ ¼å¼
2. **çµæ´»çš„ä»£ç†æŠ½è±¡**ï¼šä»åŸºç¡€åè®®åˆ°å…·ä½“å®ç°çš„å®Œæ•´å±‚æ¬¡
3. **å¼ºå¤§çš„å›¢é˜Ÿåä½œæœºåˆ¶**ï¼šæ”¯æŒå¤æ‚çš„å¤šä»£ç†åä½œåœºæ™¯
4. **å®Œå–„çš„å·¥å…·é›†æˆ**ï¼šæ— ç¼é›†æˆå¤–éƒ¨å·¥å…·å’ŒAPI
5. **ä¼˜ç§€çš„ç”¨æˆ·ä½“éªŒ**ï¼šæä¾›æµå¼å“åº”å’Œç›´è§‚çš„æ§åˆ¶å°ç•Œé¢

é€šè¿‡æ·±å…¥ç†è§£è¿™äº›è®¾è®¡åŸç†å’Œå®ç°ç»†èŠ‚ï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºå‡ºåŠŸèƒ½å¼ºå¤§ã€ç”¨æˆ·å‹å¥½çš„AIå¯¹è¯åº”ç”¨ã€‚

---
