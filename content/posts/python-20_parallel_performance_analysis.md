---
title: "Python3 å¹¶è¡Œä¸æ€§èƒ½ä¼˜åŒ–æ·±åº¦æºç åˆ†æ"
date: 2025-09-28T01:46:41+08:00
draft: false
tags: ['æºç åˆ†æ', 'Python']
categories: ['Python']
description: "Python3 å¹¶è¡Œä¸æ€§èƒ½ä¼˜åŒ–æ·±åº¦æºç åˆ†æçš„æ·±å…¥æŠ€æœ¯åˆ†ææ–‡æ¡£"
keywords: ['æºç åˆ†æ', 'Python']
author: "æŠ€æœ¯åˆ†æå¸ˆ"
weight: 1
---

## ğŸ“‹ æ¦‚è¿°

å¹¶è¡Œå¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–æ˜¯ç°ä»£Pythonåº”ç”¨çš„å…³é”®éœ€æ±‚ã€‚æœ¬æ–‡æ¡£å°†æ·±å…¥åˆ†æCPythonä¸­çš„å¹¶è¡Œå¤„ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬å¤šçº¿ç¨‹ã€å¤šè¿›ç¨‹ã€å¼‚æ­¥ç¼–ç¨‹ã€GILæœºåˆ¶ã€æ€§èƒ½åˆ†æå·¥å…·ç­‰ï¼Œä»¥åŠå„ç§æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯å’Œæœ€ä½³å®è·µã€‚

## ğŸ¯ å¹¶è¡Œå¤„ç†æ¶æ„

```mermaid
graph TB
    subgraph "çº¿ç¨‹å±‚"
        A[threadingæ¨¡å—] --> B[Threadå¯¹è±¡]
        B --> C[GILæœºåˆ¶]
        C --> D[çº¿ç¨‹åŒæ­¥]
    end

    subgraph "è¿›ç¨‹å±‚"
        E[multiprocessingæ¨¡å—] --> F[Processå¯¹è±¡]
        F --> G[è¿›ç¨‹é—´é€šä¿¡]
        G --> H[å…±äº«å†…å­˜]
    end

    subgraph "å¼‚æ­¥å±‚"
        I[asyncioæ¨¡å—] --> J[äº‹ä»¶å¾ªç¯]
        J --> K[åç¨‹è°ƒåº¦]
        K --> L[å¹¶å‘ä»»åŠ¡]
    end

    subgraph "æ€§èƒ½å·¥å…·"
        M[cProfile] --> N[æ€§èƒ½åˆ†æ]
        N --> O[ç“¶é¢ˆè¯†åˆ«]
        O --> P[ä¼˜åŒ–ç­–ç•¥]
    end

    A --> E
    E --> I
    I --> M
```

## 1. GILæœºåˆ¶æ·±åº¦åˆ†æ

### 1.1 GILå®ç°åŸç†

```c
/* Python/ceval_gil.c - GILå®ç° */

/* GILçŠ¶æ€ç»“æ„ */
struct _gil_runtime_state {
    /* GILçš„å½“å‰çŠ¶æ€ */
    unsigned long locked;       /* GILæ˜¯å¦è¢«é”å®š */
    unsigned long interval;     /* åˆ‡æ¢é—´éš”(å¾®ç§’) */
    PyThreadState *last_holder; /* ä¸Šä¸€ä¸ªæŒæœ‰GILçš„çº¿ç¨‹ */

    /* ç­‰å¾…GILçš„çº¿ç¨‹ */
    COND_T cond;               /* æ¡ä»¶å˜é‡ */
    MUTEX_T mutex;             /* äº’æ–¥é” */

    /* å¼ºåˆ¶åˆ‡æ¢æ ‡å¿— */
    _Py_atomic_int gil_drop_request;
    _Py_atomic_int eval_breaker;

    /* åˆ‡æ¢ç»Ÿè®¡ */
    unsigned long switch_number;
};

/* è·å–GIL */
static void
take_gil(PyThreadState *tstate)
{
    int err;
    _PyRuntimeState *runtime = &_PyRuntime;
    struct _gil_runtime_state *gil = &runtime->gil;

    if (tstate == NULL) {
        Py_FatalError("take_gil: NULL tstate");
    }

    err = PyMUTEX_LOCK(gil->mutex);
    if (err) {
        Py_FatalError("take_gil: PyMUTEX_LOCK failed");
    }

    if (!_Py_atomic_load_relaxed(&gil->locked)) {
        /* GILç©ºé—²ï¼Œç›´æ¥è·å– */
        goto _ready;
    }

    /* GILè¢«å ç”¨ï¼Œç­‰å¾…é‡Šæ”¾ */
    while (_Py_atomic_load_relaxed(&gil->locked)) {
        /* è®¾ç½®ç­‰å¾…æ ‡å¿— */
        _Py_atomic_store_relaxed(&gil->gil_drop_request, 1);

        /* ç­‰å¾…æ¡ä»¶å˜é‡ */
        err = PyCOND_WAIT(gil->cond, gil->mutex);
        if (err) {
            Py_FatalError("take_gil: PyCOND_WAIT failed");
        }
    }

_ready:
    /* æˆåŠŸè·å–GIL */
    _Py_atomic_store_relaxed(&gil->locked, 1);
    _Py_atomic_store_relaxed(&gil->gil_drop_request, 0);

    if (tstate != gil->last_holder) {
        gil->last_holder = tstate;
        gil->switch_number++;
    }

    /* æ¸…é™¤eval_breakeræ ‡å¿— */
    _Py_atomic_store_relaxed(&gil->eval_breaker, 0);

    PyMUTEX_UNLOCK(gil->mutex);

    if (_Py_atomic_load_relaxed(&gil->gil_drop_request)) {
        /* æœ‰å…¶ä»–çº¿ç¨‹åœ¨ç­‰å¾…ï¼Œå‡†å¤‡é‡Šæ”¾ */
        RESET_GIL_DROP_REQUEST(runtime);
    }
}

/* é‡Šæ”¾GIL */
static void
drop_gil(PyThreadState *tstate)
{
    _PyRuntimeState *runtime = &_PyRuntime;
    struct _gil_runtime_state *gil = &runtime->gil;

    if (!_Py_atomic_load_relaxed(&gil->locked)) {
        Py_FatalError("drop_gil: GIL is not locked");
    }

    /* é‡Šæ”¾GIL */
    PyMUTEX_LOCK(gil->mutex);
    _Py_atomic_store_relaxed(&gil->locked, 0);
    PyCOND_SIGNAL(gil->cond);  /* å”¤é†’ç­‰å¾…çš„çº¿ç¨‹ */
    PyMUTEX_UNLOCK(gil->mutex);
}

/* GILæ£€æŸ¥ç‚¹ - åœ¨å­—èŠ‚ç æ‰§è¡Œä¸­å®šæœŸè°ƒç”¨ */
int
_Py_CheckInterval()
{
    PyThreadState *tstate = _PyThreadState_GET();

    /* æ£€æŸ¥æ˜¯å¦éœ€è¦é‡Šæ”¾GIL */
    if (_Py_atomic_load_relaxed(&_PyRuntime.gil.gil_drop_request)) {
        /* æœ‰çº¿ç¨‹è¯·æ±‚GILï¼Œé‡Šæ”¾å¹¶é‡æ–°è·å– */
        if (tstate->async_exc != NULL) {
            /* å¤„ç†å¼‚æ­¥å¼‚å¸¸ */
            return -1;
        }

        drop_gil(tstate);
        /* è®©å…¶ä»–çº¿ç¨‹æœ‰æœºä¼šè¿è¡Œ */
        _Py_ANNOTATE_RWLOCK_RELEASED(&_PyRuntime.gil.locked, 1);
        take_gil(tstate);
        _Py_ANNOTATE_RWLOCK_ACQUIRED(&_PyRuntime.gil.locked, 1);

        if (tstate->async_exc != NULL) {
            return -1;
        }
    }

    return 0;
}
```

### 1.2 GILæ€§èƒ½å½±å“åˆ†æ

```python
# GILæ€§èƒ½å½±å“åˆ†æ
import threading
import time
import queue
import multiprocessing
import concurrent.futures
from typing import List
import sys

def gil_impact_analysis():
    """åˆ†æGILå¯¹æ€§èƒ½çš„å½±å“"""

    print("=== GILæ€§èƒ½å½±å“åˆ†æ ===")

    # 1. CPUå¯†é›†å‹ä»»åŠ¡ - GILé™åˆ¶æ˜æ˜¾
    def cpu_intensive_task(n: int) -> int:
        """CPUå¯†é›†å‹ä»»åŠ¡"""
        count = 0
        for i in range(n):
            count += i * i
        return count

    def test_cpu_intensive():
        """æµ‹è¯•CPUå¯†é›†å‹ä»»åŠ¡çš„å¹¶è¡Œæ€§èƒ½"""
        task_size = 1000000
        num_tasks = 4

        # å•çº¿ç¨‹æ‰§è¡Œ
        start = time.time()
        results_single = []
        for i in range(num_tasks):
            result = cpu_intensive_task(task_size)
            results_single.append(result)
        single_thread_time = time.time() - start

        # å¤šçº¿ç¨‹æ‰§è¡Œï¼ˆå—GILé™åˆ¶ï¼‰
        start = time.time()
        results_multi = []
        threads = []
        result_queue = queue.Queue()

        def worker():
            result = cpu_intensive_task(task_size)
            result_queue.put(result)

        for i in range(num_tasks):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        while not result_queue.empty():
            results_multi.append(result_queue.get())

        multi_thread_time = time.time() - start

        # å¤šè¿›ç¨‹æ‰§è¡Œï¼ˆç»•è¿‡GILï¼‰
        start = time.time()
        with multiprocessing.Pool(num_tasks) as pool:
            results_multi_proc = pool.map(cpu_intensive_task, [task_size] * num_tasks)
        multi_process_time = time.time() - start

        print(f"CPUå¯†é›†å‹ä»»åŠ¡æ€§èƒ½å¯¹æ¯”:")
        print(f"å•çº¿ç¨‹: {single_thread_time:.3f}ç§’")
        print(f"å¤šçº¿ç¨‹: {multi_thread_time:.3f}ç§’ (æ•ˆç‡: {single_thread_time/multi_thread_time:.2f}x)")
        print(f"å¤šè¿›ç¨‹: {multi_process_time:.3f}ç§’ (æ•ˆç‡: {single_thread_time/multi_process_time:.2f}x)")

        return single_thread_time, multi_thread_time, multi_process_time

    # 2. I/Oå¯†é›†å‹ä»»åŠ¡ - GILå½±å“è¾ƒå°
    def io_intensive_task(duration: float) -> str:
        """I/Oå¯†é›†å‹ä»»åŠ¡æ¨¡æ‹Ÿ"""
        import time
        time.sleep(duration)  # æ¨¡æ‹ŸI/Oç­‰å¾…
        return f"Task completed after {duration}s"

    def test_io_intensive():
        """æµ‹è¯•I/Oå¯†é›†å‹ä»»åŠ¡çš„å¹¶è¡Œæ€§èƒ½"""
        task_duration = 0.1
        num_tasks = 10

        # ä¸²è¡Œæ‰§è¡Œ
        start = time.time()
        results_serial = []
        for i in range(num_tasks):
            result = io_intensive_task(task_duration)
            results_serial.append(result)
        serial_time = time.time() - start

        # å¤šçº¿ç¨‹æ‰§è¡Œ
        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_tasks) as executor:
            results_thread = list(executor.map(io_intensive_task, [task_duration] * num_tasks))
        thread_time = time.time() - start

        # å¤šè¿›ç¨‹æ‰§è¡Œ
        start = time.time()
        with concurrent.futures.ProcessPoolExecutor(max_workers=num_tasks) as executor:
            results_process = list(executor.map(io_intensive_task, [task_duration] * num_tasks))
        process_time = time.time() - start

        print(f"\nI/Oå¯†é›†å‹ä»»åŠ¡æ€§èƒ½å¯¹æ¯”:")
        print(f"ä¸²è¡Œæ‰§è¡Œ: {serial_time:.3f}ç§’")
        print(f"å¤šçº¿ç¨‹: {thread_time:.3f}ç§’ (æ•ˆç‡: {serial_time/thread_time:.2f}x)")
        print(f"å¤šè¿›ç¨‹: {process_time:.3f}ç§’ (æ•ˆç‡: {serial_time/process_time:.2f}x)")

        return serial_time, thread_time, process_time

    # 3. æ··åˆå‹ä»»åŠ¡
    def mixed_task(cpu_work: int, io_duration: float) -> int:
        """æ··åˆCPUå’ŒI/Oçš„ä»»åŠ¡"""
        # CPUéƒ¨åˆ†
        count = 0
        for i in range(cpu_work):
            count += i

        # I/Oéƒ¨åˆ†
        time.sleep(io_duration)

        return count

    def test_mixed_workload():
        """æµ‹è¯•æ··åˆå·¥ä½œè´Ÿè½½"""
        cpu_work = 100000
        io_duration = 0.05
        num_tasks = 6

        # å•çº¿ç¨‹
        start = time.time()
        results_single = []
        for i in range(num_tasks):
            result = mixed_task(cpu_work, io_duration)
            results_single.append(result)
        single_time = time.time() - start

        # å¤šçº¿ç¨‹
        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_tasks) as executor:
            futures = [executor.submit(mixed_task, cpu_work, io_duration) for _ in range(num_tasks)]
            results_thread = [f.result() for f in futures]
        thread_time = time.time() - start

        print(f"\næ··åˆå‹ä»»åŠ¡æ€§èƒ½å¯¹æ¯”:")
        print(f"å•çº¿ç¨‹: {single_time:.3f}ç§’")
        print(f"å¤šçº¿ç¨‹: {thread_time:.3f}ç§’ (æ•ˆç‡: {single_time/thread_time:.2f}x)")

    # è¿è¡Œæµ‹è¯•
    test_cpu_intensive()
    test_io_intensive()
    test_mixed_workload()

    # 4. GILé‡Šæ”¾é¢‘ç‡åˆ†æ
    def gil_release_analysis():
        """åˆ†æGILé‡Šæ”¾é¢‘ç‡"""

        import sys

        print(f"\n=== GILé…ç½®ä¿¡æ¯ ===")
        print(f"Pythonç‰ˆæœ¬: {sys.version}")
        print(f"GILåˆ‡æ¢é—´éš”: {sys.getswitchinterval():.6f}ç§’")

        # æµ‹è¯•GILåˆ‡æ¢çš„å®é™…å½±å“
        def busy_thread(name: str, duration: float):
            """å¿™ç­‰çº¿ç¨‹"""
            start = time.time()
            count = 0
            while time.time() - start < duration:
                count += 1
            print(f"çº¿ç¨‹ {name}: æ‰§è¡Œäº† {count} æ¬¡å¾ªç¯")
            return count

        print(f"\nGILåˆ‡æ¢æµ‹è¯• (2ç§’):")
        threads = []
        for i in range(3):
            thread = threading.Thread(target=busy_thread, args=(f"T{i}", 2.0))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    gil_release_analysis()

# è¿è¡ŒGILåˆ†æ
if __name__ == "__main__":
    gil_impact_analysis()
```

## 2. å¤šçº¿ç¨‹ç¼–ç¨‹æ·±åº¦åˆ†æ

### 2.1 çº¿ç¨‹å¯¹è±¡å®ç°

```c
/* Modules/_threadmodule.c - çº¿ç¨‹æ¨¡å—å®ç° */

/* çº¿ç¨‹çŠ¶æ€ç»“æ„ */
typedef struct {
    PyObject_HEAD
    pthread_t ident;           /* çº¿ç¨‹æ ‡è¯†ç¬¦ */
    PyObject *args;            /* çº¿ç¨‹å‚æ•° */
    PyObject *kwargs;          /* å…³é”®å­—å‚æ•° */
    PyObject *func;            /* çº¿ç¨‹å‡½æ•° */
    PyObject *name;            /* çº¿ç¨‹åç§° */
    PyObject *target;          /* ç›®æ ‡å‡½æ•° */
    int daemon;                /* æ˜¯å¦ä¸ºå®ˆæŠ¤çº¿ç¨‹ */
    int started;               /* æ˜¯å¦å·²å¯åŠ¨ */
    int stopped;               /* æ˜¯å¦å·²åœæ­¢ */
    pthread_cond_t finished;   /* å®Œæˆæ¡ä»¶å˜é‡ */
    pthread_mutex_t lock;      /* çº¿ç¨‹é” */
} ThreadObject;

/* çº¿ç¨‹å¯åŠ¨å‡½æ•° */
static void *
thread_run(void *arg)
{
    ThreadObject *self = (ThreadObject *)arg;
    PyObject *result = NULL;
    PyThreadState *tstate = NULL;

    /* åˆ›å»ºçº¿ç¨‹çŠ¶æ€ */
    tstate = PyThreadState_New(PyInterpreterState_Main());
    if (tstate == NULL) {
        return NULL;
    }

    /* è®¾ç½®çº¿ç¨‹çŠ¶æ€ */
    PyEval_AcquireThread(tstate);

    /* æ‰§è¡Œçº¿ç¨‹å‡½æ•° */
    if (self->target) {
        if (self->args && self->kwargs) {
            result = PyObject_Call(self->target, self->args, self->kwargs);
        } else if (self->args) {
            result = PyObject_CallObject(self->target, self->args);
        } else {
            result = PyObject_CallObject(self->target, NULL);
        }
    }

    /* å¤„ç†å¼‚å¸¸ */
    if (result == NULL) {
        PyErr_WriteUnraisable(self->target);
    } else {
        Py_DECREF(result);
    }

    /* æ¸…ç†çº¿ç¨‹çŠ¶æ€ */
    PyThreadState_Clear(tstate);
    PyEval_ReleaseThread(tstate);
    PyThreadState_Delete(tstate);

    /* æ ‡è®°çº¿ç¨‹å®Œæˆ */
    pthread_mutex_lock(&self->lock);
    self->stopped = 1;
    pthread_cond_broadcast(&self->finished);
    pthread_mutex_unlock(&self->lock);

    return NULL;
}

/* å¯åŠ¨çº¿ç¨‹ */
static PyObject *
thread_start(ThreadObject *self, PyObject *Py_UNUSED(ignored))
{
    if (self->started) {
        PyErr_SetString(PyExc_RuntimeError, "thread already started");
        return NULL;
    }

    self->started = 1;

    /* åˆ›å»ºç³»ç»Ÿçº¿ç¨‹ */
    int err = pthread_create(&self->ident, NULL, thread_run, (void *)self);
    if (err) {
        self->started = 0;
        PyErr_SetString(PyExc_RuntimeError, "can't start new thread");
        return NULL;
    }

    Py_RETURN_NONE;
}

/* ç­‰å¾…çº¿ç¨‹ç»“æŸ */
static PyObject *
thread_join(ThreadObject *self, PyObject *args)
{
    double timeout = -1.0;

    if (!PyArg_ParseTuple(args, "|d:join", &timeout)) {
        return NULL;
    }

    if (!self->started) {
        PyErr_SetString(PyExc_RuntimeError, "cannot join thread before it is started");
        return NULL;
    }

    if (self->ident == pthread_self()) {
        PyErr_SetString(PyExc_RuntimeError, "cannot join current thread");
        return NULL;
    }

    /* ç­‰å¾…çº¿ç¨‹å®Œæˆ */
    pthread_mutex_lock(&self->lock);

    if (timeout < 0.0) {
        /* æ— é™ç­‰å¾… */
        while (!self->stopped) {
            pthread_cond_wait(&self->finished, &self->lock);
        }
    } else {
        /* è¶…æ—¶ç­‰å¾… */
        struct timespec ts;
        clock_gettime(CLOCK_REALTIME, &ts);
        ts.tv_sec += (time_t)timeout;
        ts.tv_nsec += (long)((timeout - (time_t)timeout) * 1e9);

        while (!self->stopped) {
            int err = pthread_cond_timedwait(&self->finished, &self->lock, &ts);
            if (err == ETIMEDOUT) {
                break;
            }
        }
    }

    pthread_mutex_unlock(&self->lock);
    Py_RETURN_NONE;
}
```

### 2.2 çº¿ç¨‹åŒæ­¥æœºåˆ¶

```python
# çº¿ç¨‹åŒæ­¥æœºåˆ¶æ·±åº¦åˆ†æ
import threading
import time
import queue
import random
from typing import List, Any
import concurrent.futures
from contextlib import contextmanager

def threading_synchronization_analysis():
    """çº¿ç¨‹åŒæ­¥æœºåˆ¶åˆ†æ"""

    print("=== çº¿ç¨‹åŒæ­¥æœºåˆ¶åˆ†æ ===")

    # 1. Lock - åŸºç¡€äº’æ–¥é”
    def test_basic_lock():
        """æµ‹è¯•åŸºç¡€é”æœºåˆ¶"""
        shared_resource = 0
        lock = threading.Lock()
        results = []

        def increment_with_lock(iterations: int):
            nonlocal shared_resource
            local_increments = 0

            for _ in range(iterations):
                with lock:  # ä½¿ç”¨é”ä¿æŠ¤ä¸´ç•ŒåŒº
                    old_value = shared_resource
                    time.sleep(0.0001)  # æ¨¡æ‹Ÿç«äº‰æ¡ä»¶
                    shared_resource = old_value + 1
                    local_increments += 1

            results.append(local_increments)

        def increment_without_lock(iterations: int):
            nonlocal shared_resource
            local_increments = 0

            for _ in range(iterations):
                old_value = shared_resource
                time.sleep(0.0001)  # æ¨¡æ‹Ÿç«äº‰æ¡ä»¶
                shared_resource = old_value + 1
                local_increments += 1

            results.append(local_increments)

        print("1. Lockæœºåˆ¶æµ‹è¯•:")

        # æ— é”æµ‹è¯•
        shared_resource = 0
        results.clear()
        threads = []
        for i in range(3):
            thread = threading.Thread(target=increment_without_lock, args=(10,))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        print(f"   æ— é”: æœŸæœ›å€¼=30, å®é™…å€¼={shared_resource}, å·®å¼‚={30-shared_resource}")

        # æœ‰é”æµ‹è¯•
        shared_resource = 0
        results.clear()
        threads = []
        for i in range(3):
            thread = threading.Thread(target=increment_with_lock, args=(10,))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        print(f"   æœ‰é”: æœŸæœ›å€¼=30, å®é™…å€¼={shared_resource}, å·®å¼‚={30-shared_resource}")

    test_basic_lock()

    # 2. RLock - å¯é‡å…¥é”
    def test_reentrant_lock():
        """æµ‹è¯•å¯é‡å…¥é”"""
        rlock = threading.RLock()
        call_depth = 0

        def recursive_function(depth: int):
            nonlocal call_depth

            with rlock:
                call_depth += 1
                print(f"   é€’å½’æ·±åº¦: {call_depth}, å‚æ•°: {depth}")

                if depth > 0:
                    recursive_function(depth - 1)  # é€’å½’è°ƒç”¨ï¼Œé‡æ–°è·å–åŒä¸€ä¸ªé”

                call_depth -= 1

        print(f"\n2. RLockå¯é‡å…¥é”æµ‹è¯•:")
        recursive_function(3)

    test_reentrant_lock()

    # 3. Condition - æ¡ä»¶å˜é‡
    def test_condition_variable():
        """æµ‹è¯•æ¡ä»¶å˜é‡"""
        condition = threading.Condition()
        items = []

        def consumer(name: str):
            with condition:
                while len(items) == 0:
                    print(f"   æ¶ˆè´¹è€… {name} ç­‰å¾…å•†å“...")
                    condition.wait()  # ç­‰å¾…æ¡ä»¶æ»¡è¶³

                item = items.pop(0)
                print(f"   æ¶ˆè´¹è€… {name} æ¶ˆè´¹äº† {item}")

        def producer(name: str, count: int):
            for i in range(count):
                time.sleep(0.1)  # æ¨¡æ‹Ÿç”Ÿäº§æ—¶é—´

                with condition:
                    item = f"{name}-item-{i}"
                    items.append(item)
                    print(f"   ç”Ÿäº§è€… {name} ç”Ÿäº§äº† {item}")
                    condition.notify_all()  # é€šçŸ¥æ‰€æœ‰ç­‰å¾…çš„æ¶ˆè´¹è€…

        print(f"\n3. Conditionæ¡ä»¶å˜é‡æµ‹è¯•:")

        # å¯åŠ¨æ¶ˆè´¹è€…çº¿ç¨‹
        consumer_threads = []
        for i in range(2):
            thread = threading.Thread(target=consumer, args=(f"C{i}",))
            consumer_threads.append(thread)
            thread.start()

        time.sleep(0.5)  # è®©æ¶ˆè´¹è€…å…ˆç­‰å¾…

        # å¯åŠ¨ç”Ÿäº§è€…çº¿ç¨‹
        producer_thread = threading.Thread(target=producer, args=("P1", 3))
        producer_thread.start()

        # ç­‰å¾…å®Œæˆ
        producer_thread.join()
        for thread in consumer_threads:
            thread.join(timeout=1.0)  # è®¾ç½®è¶…æ—¶é¿å…æ­»é”

    test_condition_variable()

    # 4. Semaphore - ä¿¡å·é‡
    def test_semaphore():
        """æµ‹è¯•ä¿¡å·é‡"""
        # é™åˆ¶åŒæ—¶è®¿é—®èµ„æºçš„çº¿ç¨‹æ•°
        semaphore = threading.Semaphore(2)  # æœ€å¤š2ä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®

        def access_resource(worker_id: int):
            print(f"   å·¥ä½œè€… {worker_id} è¯·æ±‚èµ„æº...")

            with semaphore:
                print(f"   å·¥ä½œè€… {worker_id} è·å¾—èµ„æºï¼Œå¼€å§‹å·¥ä½œ")
                time.sleep(random.uniform(0.5, 1.5))  # æ¨¡æ‹Ÿå·¥ä½œæ—¶é—´
                print(f"   å·¥ä½œè€… {worker_id} å®Œæˆå·¥ä½œï¼Œé‡Šæ”¾èµ„æº")

        print(f"\n4. Semaphoreä¿¡å·é‡æµ‹è¯• (æœ€å¤š2ä¸ªå¹¶å‘):")

        threads = []
        for i in range(5):
            thread = threading.Thread(target=access_resource, args=(i,))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    test_semaphore()

    # 5. Event - äº‹ä»¶å¯¹è±¡
    def test_event():
        """æµ‹è¯•äº‹ä»¶å¯¹è±¡"""
        event = threading.Event()

        def waiter(name: str):
            print(f"   {name} ç­‰å¾…äº‹ä»¶...")
            event.wait()  # ç­‰å¾…äº‹ä»¶è¢«è®¾ç½®
            print(f"   {name} æ”¶åˆ°äº‹ä»¶é€šçŸ¥ï¼")

        def setter():
            time.sleep(2)  # ç­‰å¾…2ç§’
            print(f"   è®¾ç½®äº‹ä»¶...")
            event.set()  # è®¾ç½®äº‹ä»¶ï¼Œå”¤é†’æ‰€æœ‰ç­‰å¾…çš„çº¿ç¨‹

        print(f"\n5. Eventäº‹ä»¶å¯¹è±¡æµ‹è¯•:")

        # å¯åŠ¨ç­‰å¾…çº¿ç¨‹
        waiter_threads = []
        for i in range(3):
            thread = threading.Thread(target=waiter, args=(f"ç­‰å¾…è€…{i}",))
            waiter_threads.append(thread)
            thread.start()

        # å¯åŠ¨è®¾ç½®çº¿ç¨‹
        setter_thread = threading.Thread(target=setter)
        setter_thread.start()

        # ç­‰å¾…å®Œæˆ
        setter_thread.join()
        for thread in waiter_threads:
            thread.join()

    test_event()

    # 6. Barrier - å±éšœ
    def test_barrier():
        """æµ‹è¯•å±éšœåŒæ­¥"""
        num_threads = 3
        barrier = threading.Barrier(num_threads)

        def worker(worker_id: int):
            # ç¬¬ä¸€é˜¶æ®µå·¥ä½œ
            work_time = random.uniform(0.5, 2.0)
            print(f"   å·¥ä½œè€… {worker_id} å¼€å§‹ç¬¬ä¸€é˜¶æ®µå·¥ä½œ ({work_time:.1f}ç§’)...")
            time.sleep(work_time)
            print(f"   å·¥ä½œè€… {worker_id} å®Œæˆç¬¬ä¸€é˜¶æ®µï¼Œç­‰å¾…å…¶ä»–å·¥ä½œè€…...")

            try:
                barrier.wait()  # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹åˆ°è¾¾å±éšœ
            except threading.BrokenBarrierError:
                print(f"   å·¥ä½œè€… {worker_id}: å±éšœè¢«ç ´åï¼")
                return

            # ç¬¬äºŒé˜¶æ®µå·¥ä½œ
            print(f"   å·¥ä½œè€… {worker_id} å¼€å§‹ç¬¬äºŒé˜¶æ®µå·¥ä½œ...")
            time.sleep(0.5)
            print(f"   å·¥ä½œè€… {worker_id} å®Œæˆæ‰€æœ‰å·¥ä½œ")

        print(f"\n6. Barrierå±éšœæµ‹è¯• ({num_threads}ä¸ªå·¥ä½œè€…):")

        threads = []
        for i in range(num_threads):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    test_barrier()

# è¿è¡Œçº¿ç¨‹åŒæ­¥åˆ†æ
if __name__ == "__main__":
    threading_synchronization_analysis()
```

## 3. å¤šè¿›ç¨‹ç¼–ç¨‹æ·±åº¦åˆ†æ

### 3.1 è¿›ç¨‹é—´é€šä¿¡æœºåˆ¶

```python
# å¤šè¿›ç¨‹ç¼–ç¨‹æ·±åº¦åˆ†æ
import multiprocessing as mp
import time
import os
import signal
import mmap
import pickle
from typing import List, Dict, Any, Optional
import concurrent.futures
import queue

def multiprocessing_analysis():
    """å¤šè¿›ç¨‹ç¼–ç¨‹æ·±åº¦åˆ†æ"""

    print("=== å¤šè¿›ç¨‹ç¼–ç¨‹æ·±åº¦åˆ†æ ===")

    # 1. åŸºç¡€è¿›ç¨‹åˆ›å»ºå’Œç®¡ç†
    def test_basic_process():
        """æµ‹è¯•åŸºç¡€è¿›ç¨‹åŠŸèƒ½"""

        def worker_function(name: str, work_time: float):
            """å·¥ä½œè¿›ç¨‹å‡½æ•°"""
            pid = os.getpid()
            print(f"   è¿›ç¨‹ {name} (PID: {pid}) å¼€å§‹å·¥ä½œï¼Œé¢„è®¡ {work_time} ç§’")
            time.sleep(work_time)
            print(f"   è¿›ç¨‹ {name} (PID: {pid}) å·¥ä½œå®Œæˆ")
            return f"ç»“æœæ¥è‡ªè¿›ç¨‹ {name}"

        print("1. åŸºç¡€è¿›ç¨‹åˆ›å»º:")

        # åˆ›å»ºå’Œå¯åŠ¨è¿›ç¨‹
        processes = []
        for i in range(3):
            process = mp.Process(
                target=worker_function,
                args=(f"Worker-{i}", random.uniform(1.0, 3.0))
            )
            processes.append(process)
            process.start()
            print(f"   å¯åŠ¨è¿›ç¨‹ Worker-{i}, PID: {process.pid}")

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        for process in processes:
            process.join()
            print(f"   è¿›ç¨‹ {process.pid} é€€å‡ºï¼Œé€€å‡ºç : {process.exitcode}")

    test_basic_process()

    # 2. è¿›ç¨‹æ± 
    def test_process_pool():
        """æµ‹è¯•è¿›ç¨‹æ± """

        def cpu_task(n: int) -> int:
            """CPUå¯†é›†å‹ä»»åŠ¡"""
            result = 0
            for i in range(n):
                result += i * i
            return result

        print(f"\n2. è¿›ç¨‹æ± æµ‹è¯•:")

        tasks = [100000, 200000, 150000, 300000]

        # ä½¿ç”¨è¿›ç¨‹æ± 
        start_time = time.time()
        with mp.Pool(processes=4) as pool:
            results = pool.map(cpu_task, tasks)
        pool_time = time.time() - start_time

        # ä¸²è¡Œæ‰§è¡Œå¯¹æ¯”
        start_time = time.time()
        serial_results = [cpu_task(n) for n in tasks]
        serial_time = time.time() - start_time

        print(f"   è¿›ç¨‹æ± æ‰§è¡Œ: {pool_time:.3f}ç§’")
        print(f"   ä¸²è¡Œæ‰§è¡Œ: {serial_time:.3f}ç§’")
        print(f"   åŠ é€Ÿæ¯”: {serial_time/pool_time:.2f}x")
        print(f"   ç»“æœä¸€è‡´: {results == serial_results}")

    test_process_pool()

    # 3. è¿›ç¨‹é—´é€šä¿¡ - Queue
    def test_process_queue():
        """æµ‹è¯•è¿›ç¨‹é˜Ÿåˆ—é€šä¿¡"""

        def producer(q: mp.Queue, name: str, count: int):
            """ç”Ÿäº§è€…è¿›ç¨‹"""
            for i in range(count):
                item = f"{name}-item-{i}"
                q.put(item)
                print(f"   ç”Ÿäº§è€… {name} ç”Ÿäº§: {item}")
                time.sleep(0.2)

            q.put(None)  # ç»“æŸæ ‡å¿—
            print(f"   ç”Ÿäº§è€… {name} å®Œæˆ")

        def consumer(q: mp.Queue, name: str):
            """æ¶ˆè´¹è€…è¿›ç¨‹"""
            consumed = 0
            while True:
                try:
                    item = q.get(timeout=5)
                    if item is None:
                        break

                    print(f"   æ¶ˆè´¹è€… {name} æ¶ˆè´¹: {item}")
                    consumed += 1
                    time.sleep(0.1)

                except queue.Empty:
                    print(f"   æ¶ˆè´¹è€… {name} è¶…æ—¶é€€å‡º")
                    break

            print(f"   æ¶ˆè´¹è€… {name} æ€»å…±æ¶ˆè´¹ {consumed} ä¸ªé¡¹ç›®")

        print(f"\n3. è¿›ç¨‹é˜Ÿåˆ—é€šä¿¡:")

        # åˆ›å»ºé˜Ÿåˆ—
        q = mp.Queue(maxsize=10)

        # åˆ›å»ºç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…è¿›ç¨‹
        producer_proc = mp.Process(target=producer, args=(q, "P1", 5))
        consumer_proc = mp.Process(target=consumer, args=(q, "C1"))

        # å¯åŠ¨è¿›ç¨‹
        producer_proc.start()
        consumer_proc.start()

        # ç­‰å¾…å®Œæˆ
        producer_proc.join()
        consumer_proc.join()

    test_process_queue()

    # 4. å…±äº«å†…å­˜
    def test_shared_memory():
        """æµ‹è¯•å…±äº«å†…å­˜"""

        def worker_with_shared_memory(shared_array, lock, worker_id: int):
            """ä½¿ç”¨å…±äº«å†…å­˜çš„å·¥ä½œè¿›ç¨‹"""
            with lock:
                print(f"   å·¥ä½œè€… {worker_id} å¼€å§‹ä¿®æ”¹å…±äº«æ•°ç»„")
                for i in range(len(shared_array)):
                    shared_array[i] += worker_id
                time.sleep(0.1)  # æ¨¡æ‹Ÿå·¥ä½œæ—¶é—´
                print(f"   å·¥ä½œè€… {worker_id} å®Œæˆä¿®æ”¹")

        print(f"\n4. å…±äº«å†…å­˜æµ‹è¯•:")

        # åˆ›å»ºå…±äº«æ•°ç»„
        shared_array = mp.Array('i', [0, 0, 0, 0, 0])  # 5ä¸ªæ•´æ•°çš„å…±äº«æ•°ç»„
        lock = mp.Lock()

        print(f"   åˆå§‹æ•°ç»„: {list(shared_array[:])}")

        # åˆ›å»ºå·¥ä½œè¿›ç¨‹
        processes = []
        for i in range(3):
            process = mp.Process(
                target=worker_with_shared_memory,
                args=(shared_array, lock, i+1)
            )
            processes.append(process)
            process.start()

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        for process in processes:
            process.join()

        print(f"   æœ€ç»ˆæ•°ç»„: {list(shared_array[:])}")

    test_shared_memory()

    # 5. ç®¡é“é€šä¿¡
    def test_pipe_communication():
        """æµ‹è¯•ç®¡é“é€šä¿¡"""

        def sender(conn, messages: List[str]):
            """å‘é€ç«¯è¿›ç¨‹"""
            for msg in messages:
                print(f"   å‘é€: {msg}")
                conn.send(msg)
                time.sleep(0.5)

            conn.send("END")
            conn.close()

        def receiver(conn):
            """æ¥æ”¶ç«¯è¿›ç¨‹"""
            received = []
            while True:
                try:
                    msg = conn.recv()
                    if msg == "END":
                        break

                    print(f"   æ¥æ”¶: {msg}")
                    received.append(msg)

                except EOFError:
                    break

            conn.close()
            print(f"   æ€»å…±æ¥æ”¶ {len(received)} æ¡æ¶ˆæ¯")

        print(f"\n5. ç®¡é“é€šä¿¡æµ‹è¯•:")

        # åˆ›å»ºç®¡é“
        parent_conn, child_conn = mp.Pipe()

        # åˆ›å»ºè¿›ç¨‹
        sender_proc = mp.Process(
            target=sender,
            args=(child_conn, ["Hello", "World", "From", "Pipe"])
        )
        receiver_proc = mp.Process(target=receiver, args=(parent_conn,))

        # å¯åŠ¨è¿›ç¨‹
        sender_proc.start()
        receiver_proc.start()

        # ç­‰å¾…å®Œæˆ
        sender_proc.join()
        receiver_proc.join()

    test_pipe_communication()

    # 6. è¿›ç¨‹åŒæ­¥ - Manager
    def test_manager():
        """æµ‹è¯•Managerå¯¹è±¡"""

        def worker_with_manager(shared_dict, shared_list, lock, worker_id: int):
            """ä½¿ç”¨Managerçš„å·¥ä½œè¿›ç¨‹"""
            with lock:
                # ä¿®æ”¹å…±äº«å­—å…¸
                shared_dict[f'worker_{worker_id}'] = f'result_{worker_id}'

                # ä¿®æ”¹å…±äº«åˆ—è¡¨
                shared_list.append(f'item_{worker_id}')

                print(f"   å·¥ä½œè€… {worker_id} æ›´æ–°äº†å…±äº«æ•°æ®")
                time.sleep(0.1)

        print(f"\n6. Managerå¯¹è±¡æµ‹è¯•:")

        # åˆ›å»ºManager
        with mp.Manager() as manager:
            shared_dict = manager.dict()
            shared_list = manager.list()
            lock = manager.Lock()

            print(f"   åˆå§‹å­—å…¸: {dict(shared_dict)}")
            print(f"   åˆå§‹åˆ—è¡¨: {list(shared_list)}")

            # åˆ›å»ºå·¥ä½œè¿›ç¨‹
            processes = []
            for i in range(4):
                process = mp.Process(
                    target=worker_with_manager,
                    args=(shared_dict, shared_list, lock, i)
                )
                processes.append(process)
                process.start()

            # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
            for process in processes:
                process.join()

            print(f"   æœ€ç»ˆå­—å…¸: {dict(shared_dict)}")
            print(f"   æœ€ç»ˆåˆ—è¡¨: {list(shared_list)}")

    test_manager()

# è¿è¡Œå¤šè¿›ç¨‹åˆ†æ
if __name__ == "__main__":
    import random
    multiprocessing_analysis()
```

## 4. å¼‚æ­¥ç¼–ç¨‹æ€§èƒ½åˆ†æ

### 4.1 asyncioæ€§èƒ½ç‰¹å¾

```python
# å¼‚æ­¥ç¼–ç¨‹æ€§èƒ½åˆ†æ
import asyncio
import aiohttp
import time
import concurrent.futures
from typing import List, Dict, Any
import requests
import threading

async def asyncio_performance_analysis():
    """å¼‚æ­¥ç¼–ç¨‹æ€§èƒ½åˆ†æ"""

    print("=== å¼‚æ­¥ç¼–ç¨‹æ€§èƒ½åˆ†æ ===")

    # 1. I/Oå¯†é›†å‹ä»»åŠ¡çš„æ€§èƒ½å¯¹æ¯”
    async def test_io_performance():
        """æµ‹è¯•I/Oå¯†é›†å‹ä»»åŠ¡æ€§èƒ½"""

        # æ¨¡æ‹ŸI/Oæ“ä½œ
        async def async_io_task(task_id: int, duration: float):
            await asyncio.sleep(duration)
            return f"å¼‚æ­¥ä»»åŠ¡ {task_id} å®Œæˆ"

        def sync_io_task(task_id: int, duration: float):
            time.sleep(duration)
            return f"åŒæ­¥ä»»åŠ¡ {task_id} å®Œæˆ"

        num_tasks = 10
        task_duration = 0.1

        print("1. I/Oå¯†é›†å‹ä»»åŠ¡æ€§èƒ½å¯¹æ¯”:")

        # å¼‚æ­¥æ‰§è¡Œ
        start = time.time()
        tasks = [async_io_task(i, task_duration) for i in range(num_tasks)]
        async_results = await asyncio.gather(*tasks)
        async_time = time.time() - start

        # åŒæ­¥ä¸²è¡Œæ‰§è¡Œ
        start = time.time()
        sync_results = [sync_io_task(i, task_duration) for i in range(num_tasks)]
        sync_time = time.time() - start

        # å¤šçº¿ç¨‹æ‰§è¡Œ
        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_tasks) as executor:
            thread_results = list(executor.map(
                lambda x: sync_io_task(x[0], x[1]),
                [(i, task_duration) for i in range(num_tasks)]
            ))
        thread_time = time.time() - start

        print(f"   å¼‚æ­¥æ‰§è¡Œ: {async_time:.3f}ç§’")
        print(f"   åŒæ­¥ä¸²è¡Œ: {sync_time:.3f}ç§’ (å¼‚æ­¥æ•ˆç‡: {sync_time/async_time:.1f}x)")
        print(f"   å¤šçº¿ç¨‹: {thread_time:.3f}ç§’ (å¼‚æ­¥æ•ˆç‡: {thread_time/async_time:.1f}x)")

    await test_io_performance()

    # 2. å¹¶å‘è¿æ¥æ•°æµ‹è¯•
    async def test_concurrent_connections():
        """æµ‹è¯•å¹¶å‘è¿æ¥æ•°"""

        async def make_request(session, url: str, request_id: int):
            """å‘èµ·HTTPè¯·æ±‚"""
            try:
                async with session.get(url) as response:
                    content = await response.text()
                    return f"è¯·æ±‚ {request_id}: {response.status}"
            except Exception as e:
                return f"è¯·æ±‚ {request_id}: é”™è¯¯ - {e}"

        print(f"\n2. å¹¶å‘HTTPè¯·æ±‚æµ‹è¯•:")

        # ä½¿ç”¨httpbin.orgä½œä¸ºæµ‹è¯•æœåŠ¡
        test_url = "https://httpbin.org/delay/0.1"  # å»¶è¿Ÿ0.1ç§’çš„æµ‹è¯•ç«¯ç‚¹
        num_requests = 20

        try:
            timeout = aiohttp.ClientTimeout(total=10)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                start = time.time()

                # å¹¶å‘å‘èµ·è¯·æ±‚
                tasks = [
                    make_request(session, test_url, i)
                    for i in range(num_requests)
                ]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                async_time = time.time() - start

                print(f"   {num_requests} ä¸ªå¹¶å‘è¯·æ±‚å®Œæˆæ—¶é—´: {async_time:.3f}ç§’")

                # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„è¯·æ±‚
                success_count = sum(1 for r in results if isinstance(r, str) and "200" in r)
                print(f"   æˆåŠŸè¯·æ±‚: {success_count}/{num_requests}")

        except Exception as e:
            print(f"   HTTPæµ‹è¯•å¤±è´¥: {e}")

    await test_concurrent_connections()

    # 3. å¼‚æ­¥ç”Ÿæˆå™¨æ€§èƒ½
    async def test_async_generator():
        """æµ‹è¯•å¼‚æ­¥ç”Ÿæˆå™¨æ€§èƒ½"""

        async def async_data_generator(count: int):
            """å¼‚æ­¥æ•°æ®ç”Ÿæˆå™¨"""
            for i in range(count):
                await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿå¼‚æ­¥æ•°æ®è·å–
                yield f"data-{i}"

        def sync_data_generator(count: int):
            """åŒæ­¥æ•°æ®ç”Ÿæˆå™¨"""
            for i in range(count):
                time.sleep(0.01)  # æ¨¡æ‹ŸåŒæ­¥æ•°æ®è·å–
                yield f"data-{i}"

        print(f"\n3. å¼‚æ­¥ç”Ÿæˆå™¨æ€§èƒ½æµ‹è¯•:")

        count = 50

        # å¼‚æ­¥ç”Ÿæˆå™¨
        start = time.time()
        async_data = []
        async for item in async_data_generator(count):
            async_data.append(item)
        async_gen_time = time.time() - start

        # åŒæ­¥ç”Ÿæˆå™¨
        start = time.time()
        sync_data = list(sync_data_generator(count))
        sync_gen_time = time.time() - start

        print(f"   å¼‚æ­¥ç”Ÿæˆå™¨: {async_gen_time:.3f}ç§’")
        print(f"   åŒæ­¥ç”Ÿæˆå™¨: {sync_gen_time:.3f}ç§’")
        print(f"   æ•°æ®ä¸€è‡´æ€§: {len(async_data) == len(sync_data)}")

    await test_async_generator()

    # 4. äº‹ä»¶å¾ªç¯æ€§èƒ½åˆ†æ
    async def test_event_loop_performance():
        """æµ‹è¯•äº‹ä»¶å¾ªç¯æ€§èƒ½"""

        async def micro_task():
            """å¾®ä»»åŠ¡"""
            await asyncio.sleep(0)
            return "micro"

        async def small_task():
            """å°ä»»åŠ¡"""
            await asyncio.sleep(0.001)
            return "small"

        async def medium_task():
            """ä¸­ç­‰ä»»åŠ¡"""
            await asyncio.sleep(0.01)
            return "medium"

        print(f"\n4. äº‹ä»¶å¾ªç¯æ€§èƒ½åˆ†æ:")

        # æµ‹è¯•å¤§é‡å¾®ä»»åŠ¡
        num_micro_tasks = 1000
        start = time.time()
        micro_results = await asyncio.gather(*[micro_task() for _ in range(num_micro_tasks)])
        micro_time = time.time() - start

        # æµ‹è¯•ä¸­ç­‰æ•°é‡å°ä»»åŠ¡
        num_small_tasks = 100
        start = time.time()
        small_results = await asyncio.gather(*[small_task() for _ in range(num_small_tasks)])
        small_time = time.time() - start

        # æµ‹è¯•å°‘é‡ä¸­ç­‰ä»»åŠ¡
        num_medium_tasks = 20
        start = time.time()
        medium_results = await asyncio.gather(*[medium_task() for _ in range(num_medium_tasks)])
        medium_time = time.time() - start

        print(f"   {num_micro_tasks} ä¸ªå¾®ä»»åŠ¡: {micro_time:.3f}ç§’ (å¹³å‡: {micro_time/num_micro_tasks*1000:.3f}ms)")
        print(f"   {num_small_tasks} ä¸ªå°ä»»åŠ¡: {small_time:.3f}ç§’ (å¹³å‡: {small_time/num_small_tasks*1000:.3f}ms)")
        print(f"   {num_medium_tasks} ä¸ªä¸­ç­‰ä»»åŠ¡: {medium_time:.3f}ç§’ (å¹³å‡: {medium_time/num_medium_tasks*1000:.3f}ms)")

    await test_event_loop_performance()

    # 5. CPUå¯†é›†å‹ä»»åŠ¡åœ¨å¼‚æ­¥ç¯å¢ƒä¸­çš„è¡¨ç°
    async def test_cpu_intensive_in_async():
        """æµ‹è¯•CPUå¯†é›†å‹ä»»åŠ¡åœ¨å¼‚æ­¥ç¯å¢ƒä¸­çš„è¡¨ç°"""

        def cpu_task(n: int) -> int:
            """CPUå¯†é›†å‹ä»»åŠ¡"""
            result = 0
            for i in range(n):
                result += i * i
            return result

        async def async_cpu_wrapper(n: int) -> int:
            """å¼‚æ­¥åŒ…è£…çš„CPUä»»åŠ¡"""
            loop = asyncio.get_event_loop()
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒCPUå¯†é›†å‹ä»»åŠ¡
            return await loop.run_in_executor(None, cpu_task, n)

        print(f"\n5. CPUå¯†é›†å‹ä»»åŠ¡åœ¨å¼‚æ­¥ç¯å¢ƒæµ‹è¯•:")

        tasks = [100000, 200000, 150000]

        # ç›´æ¥åœ¨äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œï¼ˆä¼šé˜»å¡ï¼‰
        start = time.time()
        direct_results = []
        for n in tasks:
            result = cpu_task(n)
            direct_results.append(result)
        direct_time = time.time() - start

        # åœ¨çº¿ç¨‹æ± ä¸­å¼‚æ­¥æ‰§è¡Œ
        start = time.time()
        async_results = await asyncio.gather(*[async_cpu_wrapper(n) for n in tasks])
        async_time = time.time() - start

        print(f"   ç›´æ¥æ‰§è¡Œ: {direct_time:.3f}ç§’")
        print(f"   çº¿ç¨‹æ± å¼‚æ­¥: {async_time:.3f}ç§’")
        print(f"   ç»“æœä¸€è‡´: {direct_results == async_results}")

    await test_cpu_intensive_in_async()

# è¿è¡Œå¼‚æ­¥æ€§èƒ½åˆ†æ
async def main():
    await asyncio_performance_analysis()

if __name__ == "__main__":
    asyncio.run(main())
```

## 5. æ€§èƒ½åˆ†æå·¥å…·æ·±åº¦åº”ç”¨

### 5.1 cProfileå’Œline_profiler

```python
# æ€§èƒ½åˆ†æå·¥å…·æ·±åº¦åº”ç”¨
import cProfile
import pstats
import io
import time
import sys
import tracemalloc
from typing import List, Dict, Any, Callable
import functools
import threading
import multiprocessing

def performance_profiling_tools():
    """æ€§èƒ½åˆ†æå·¥å…·åº”ç”¨"""

    print("=== æ€§èƒ½åˆ†æå·¥å…·åº”ç”¨ ===")

    # 1. cProfileåŸºç¡€ä½¿ç”¨
    def example_function_to_profile():
        """éœ€è¦åˆ†æçš„ç¤ºä¾‹å‡½æ•°"""

        def fibonacci(n: int) -> int:
            if n <= 1:
                return n
            return fibonacci(n-1) + fibonacci(n-2)

        def factorial(n: int) -> int:
            if n <= 1:
                return 1
            return n * factorial(n-1)

        def bubble_sort(arr: List[int]) -> List[int]:
            n = len(arr)
            for i in range(n):
                for j in range(0, n-i-1):
                    if arr[j] > arr[j+1]:
                        arr[j], arr[j+1] = arr[j+1], arr[j]
            return arr

        # æ‰§è¡Œä¸€äº›è®¡ç®—
        fib_results = [fibonacci(i) for i in range(20, 25)]
        fact_results = [factorial(i) for i in range(5, 10)]

        # æ’åºæ“ä½œ
        import random
        for _ in range(10):
            data = [random.randint(1, 100) for _ in range(50)]
            sorted_data = bubble_sort(data.copy())

        return fib_results, fact_results

    def test_cprofile():
        """æµ‹è¯•cProfile"""
        print("1. cProfileæ€§èƒ½åˆ†æ:")

        # åˆ›å»ºæ€§èƒ½åˆ†æå™¨
        profiler = cProfile.Profile()

        # å¼€å§‹åˆ†æ
        profiler.enable()

        # æ‰§è¡Œéœ€è¦åˆ†æçš„ä»£ç 
        result = example_function_to_profile()

        # åœæ­¢åˆ†æ
        profiler.disable()

        # è·å–åˆ†æç»“æœ
        s = io.StringIO()
        stats = pstats.Stats(profiler, stream=s)
        stats.sort_stats('cumulative')
        stats.print_stats(10)  # æ˜¾ç¤ºå‰10ä¸ªæœ€è€—æ—¶çš„å‡½æ•°

        profile_output = s.getvalue()
        print("   æ€§èƒ½åˆ†æç»“æœ:")
        print("   " + "\n   ".join(profile_output.split('\n')[:15]))

        # åˆ†æçƒ­ç‚¹å‡½æ•°
        stats.sort_stats('tottime')
        hot_functions = []
        for func_info in list(stats.stats.items())[:5]:
            func_name = func_info[0]
            func_stats = func_info[1]
            hot_functions.append({
                'function': f"{func_name[0]}:{func_name[1]}({func_name[2]})",
                'total_time': func_stats[2],
                'calls': func_stats[0]
            })

        print(f"\n   çƒ­ç‚¹å‡½æ•°Top5:")
        for i, func in enumerate(hot_functions, 1):
            print(f"   {i}. {func['function']}")
            print(f"      æ€»æ—¶é—´: {func['total_time']:.4f}ç§’, è°ƒç”¨æ¬¡æ•°: {func['calls']}")

    test_cprofile()

    # 2. å†…å­˜åˆ†æ - tracemalloc
    def test_memory_profiling():
        """æµ‹è¯•å†…å­˜åˆ†æ"""
        print(f"\n2. å†…å­˜ä½¿ç”¨åˆ†æ:")

        # å¯åŠ¨å†…å­˜è¿½è¸ª
        tracemalloc.start()

        # è·å–åˆå§‹å†…å­˜å¿«ç…§
        snapshot1 = tracemalloc.take_snapshot()

        # æ‰§è¡Œä¸€äº›å†…å­˜å¯†é›†å‹æ“ä½œ
        def memory_intensive_operations():
            # åˆ›å»ºå¤§é‡åˆ—è¡¨
            big_lists = []
            for i in range(100):
                big_list = [j * i for j in range(1000)]
                big_lists.append(big_list)

            # åˆ›å»ºå¤§é‡å­—å…¸
            big_dicts = []
            for i in range(50):
                big_dict = {f"key_{j}": f"value_{j}_{i}" for j in range(500)}
                big_dicts.append(big_dict)

            return big_lists, big_dicts

        # æ‰§è¡Œå†…å­˜æ“ä½œ
        result = memory_intensive_operations()

        # è·å–æ“ä½œåçš„å†…å­˜å¿«ç…§
        snapshot2 = tracemalloc.take_snapshot()

        # æ¯”è¾ƒå†…å­˜å¿«ç…§
        top_stats = snapshot2.compare_to(snapshot1, 'lineno')

        print("   å†…å­˜å¢é•¿Top10:")
        for index, stat in enumerate(top_stats[:10], 1):
            print(f"   {index}. {stat.traceback.format()[-1].strip()}")
            print(f"      å¢é•¿: {stat.size_diff/1024:.1f} KB ({stat.count_diff} ä¸ªå¯¹è±¡)")

        # è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
        current, peak = tracemalloc.get_traced_memory()
        print(f"\n   å½“å‰å†…å­˜ä½¿ç”¨: {current/1024/1024:.1f} MB")
        print(f"   å³°å€¼å†…å­˜ä½¿ç”¨: {peak/1024/1024:.1f} MB")

        # åœæ­¢å†…å­˜è¿½è¸ª
        tracemalloc.stop()

    test_memory_profiling()

    # 3. è‡ªå®šä¹‰æ€§èƒ½è£…é¥°å™¨
    def performance_decorator(func: Callable) -> Callable:
        """æ€§èƒ½åˆ†æè£…é¥°å™¨"""

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # è®°å½•å¼€å§‹æ—¶é—´å’Œå†…å­˜
            start_time = time.perf_counter()
            tracemalloc.start()
            start_snapshot = tracemalloc.take_snapshot()

            try:
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)

                # è®°å½•ç»“æŸæ—¶é—´å’Œå†…å­˜
                end_time = time.perf_counter()
                end_snapshot = tracemalloc.take_snapshot()

                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                execution_time = end_time - start_time
                current_memory, peak_memory = tracemalloc.get_traced_memory()

                # åˆ†æå†…å­˜å˜åŒ–
                memory_diff = end_snapshot.compare_to(start_snapshot, 'lineno')
                total_memory_growth = sum(stat.size_diff for stat in memory_diff)

                print(f"\n   å‡½æ•° {func.__name__} æ€§èƒ½æŠ¥å‘Š:")
                print(f"   æ‰§è¡Œæ—¶é—´: {execution_time:.4f} ç§’")
                print(f"   å†…å­˜ä½¿ç”¨: {current_memory/1024:.1f} KB (å³°å€¼: {peak_memory/1024:.1f} KB)")
                print(f"   å†…å­˜å¢é•¿: {total_memory_growth/1024:.1f} KB")

                return result

            finally:
                tracemalloc.stop()

        return wrapper

    # ä½¿ç”¨æ€§èƒ½è£…é¥°å™¨
    @performance_decorator
    def test_function():
        """æµ‹è¯•å‡½æ•°"""
        # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—å’Œå†…å­˜æ“ä½œ
        data = []
        for i in range(10000):
            data.append(i ** 2)

        # æ¨¡æ‹Ÿä¸€äº›å­—ç¬¦ä¸²æ“ä½œ
        text_data = []
        for i in range(1000):
            text = f"This is string number {i} with some additional text"
            text_data.append(text.upper().replace("NUMBER", "NUM"))

        return len(data), len(text_data)

    print(f"\n3. è‡ªå®šä¹‰æ€§èƒ½è£…é¥°å™¨æµ‹è¯•:")
    result = test_function()
    print(f"   å‡½æ•°è¿”å›ç»“æœ: {result}")

    # 4. å¤šçº¿ç¨‹æ€§èƒ½åˆ†æ
    def test_threading_performance():
        """æµ‹è¯•å¤šçº¿ç¨‹æ€§èƒ½"""
        print(f"\n4. å¤šçº¿ç¨‹æ€§èƒ½åˆ†æ:")

        def cpu_bound_task(n: int) -> int:
            """CPUå¯†é›†å‹ä»»åŠ¡"""
            result = 0
            for i in range(n):
                result += i * i
            return result

        def io_bound_task(duration: float) -> str:
            """I/Oå¯†é›†å‹ä»»åŠ¡"""
            time.sleep(duration)
            return f"Task completed in {duration}s"

        # CPUå¯†é›†å‹ä»»åŠ¡æµ‹è¯•
        cpu_tasks = [100000] * 4

        # å•çº¿ç¨‹æ‰§è¡Œ
        start = time.time()
        cpu_results_single = [cpu_bound_task(n) for n in cpu_tasks]
        cpu_single_time = time.time() - start

        # å¤šçº¿ç¨‹æ‰§è¡Œ
        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            cpu_results_multi = list(executor.map(cpu_bound_task, cpu_tasks))
        cpu_multi_time = time.time() - start

        print(f"   CPUå¯†é›†å‹ä»»åŠ¡:")
        print(f"   å•çº¿ç¨‹: {cpu_single_time:.3f}ç§’")
        print(f"   å¤šçº¿ç¨‹: {cpu_multi_time:.3f}ç§’ (æ•ˆç‡: {cpu_single_time/cpu_multi_time:.2f}x)")

        # I/Oå¯†é›†å‹ä»»åŠ¡æµ‹è¯•
        io_tasks = [0.1] * 8

        # ä¸²è¡Œæ‰§è¡Œ
        start = time.time()
        io_results_serial = [io_bound_task(d) for d in io_tasks]
        io_serial_time = time.time() - start

        # å¤šçº¿ç¨‹æ‰§è¡Œ
        start = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            io_results_multi = list(executor.map(io_bound_task, io_tasks))
        io_multi_time = time.time() - start

        print(f"   I/Oå¯†é›†å‹ä»»åŠ¡:")
        print(f"   ä¸²è¡Œæ‰§è¡Œ: {io_serial_time:.3f}ç§’")
        print(f"   å¤šçº¿ç¨‹: {io_multi_time:.3f}ç§’ (æ•ˆç‡: {io_serial_time/io_multi_time:.2f}x)")

    test_threading_performance()

    # 5. æ€§èƒ½ç›‘æ§ç±»
    class PerformanceMonitor:
        """æ€§èƒ½ç›‘æ§ç±»"""

        def __init__(self, name: str = "Performance Monitor"):
            self.name = name
            self.metrics = []
            self.start_time = None
            self.start_memory = None

        def start_monitoring(self):
            """å¼€å§‹ç›‘æ§"""
            self.start_time = time.perf_counter()
            tracemalloc.start()
            self.start_memory = tracemalloc.take_snapshot()
            print(f"   {self.name} å¼€å§‹ç›‘æ§...")

        def record_checkpoint(self, label: str):
            """è®°å½•æ£€æŸ¥ç‚¹"""
            if self.start_time is None:
                return

            current_time = time.perf_counter()
            elapsed = current_time - self.start_time
            current_memory = tracemalloc.take_snapshot()

            memory_diff = current_memory.compare_to(self.start_memory, 'lineno')
            memory_growth = sum(stat.size_diff for stat in memory_diff)

            self.metrics.append({
                'label': label,
                'elapsed_time': elapsed,
                'memory_growth': memory_growth
            })

            print(f"   æ£€æŸ¥ç‚¹ '{label}': {elapsed:.3f}ç§’, å†…å­˜: {memory_growth/1024:+.1f}KB")

        def stop_monitoring(self):
            """åœæ­¢ç›‘æ§"""
            if self.start_time is None:
                return

            total_time = time.perf_counter() - self.start_time
            current_memory, peak_memory = tracemalloc.get_traced_memory()
            tracemalloc.stop()

            print(f"   {self.name} ç›‘æ§å®Œæˆ:")
            print(f"   æ€»æ—¶é—´: {total_time:.3f}ç§’")
            print(f"   å†…å­˜ä½¿ç”¨: {current_memory/1024:.1f}KB (å³°å€¼: {peak_memory/1024:.1f}KB)")

            return {
                'total_time': total_time,
                'current_memory': current_memory,
                'peak_memory': peak_memory,
                'checkpoints': self.metrics
            }

    # ä½¿ç”¨æ€§èƒ½ç›‘æ§ç±»
    print(f"\n5. æ€§èƒ½ç›‘æ§ç±»æµ‹è¯•:")

    monitor = PerformanceMonitor("å¤æ‚æ“ä½œç›‘æ§")
    monitor.start_monitoring()

    # æ¨¡æ‹Ÿå¤æ‚æ“ä½œ
    data = []
    monitor.record_checkpoint("å¼€å§‹æ•°æ®ç”Ÿæˆ")

    for i in range(5000):
        data.append({'id': i, 'value': i**2, 'text': f"item_{i}"})

    monitor.record_checkpoint("æ•°æ®ç”Ÿæˆå®Œæˆ")

    # æ•°æ®å¤„ç†
    processed_data = []
    for item in data:
        if item['value'] % 2 == 0:
            processed_data.append({
                'id': item['id'],
                'processed_value': item['value'] * 2,
                'text': item['text'].upper()
            })

    monitor.record_checkpoint("æ•°æ®å¤„ç†å®Œæˆ")

    # æ•°æ®æ±‡æ€»
    summary = {
        'total_items': len(data),
        'processed_items': len(processed_data),
        'sum_values': sum(item['processed_value'] for item in processed_data)
    }

    monitor.record_checkpoint("æ•°æ®æ±‡æ€»å®Œæˆ")

    final_report = monitor.stop_monitoring()
    print(f"   æœ€ç»ˆç»“æœ: {summary}")

# è¿è¡Œæ€§èƒ½åˆ†æå·¥å…·æµ‹è¯•
if __name__ == "__main__":
    import concurrent.futures
    import random
    performance_profiling_tools()
```

## 6. å¹¶è¡Œå¤„ç†æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant Main as ä¸»ç¨‹åº
    participant GIL as GILç®¡ç†
    participant Thread as çº¿ç¨‹æ± 
    participant Process as è¿›ç¨‹æ± 
    participant Async as å¼‚æ­¥äº‹ä»¶å¾ªç¯

    Main->>GIL: åˆ›å»ºå¤šçº¿ç¨‹ä»»åŠ¡
    GIL->>Thread: åˆ†é…çº¿ç¨‹
    Thread->>GIL: è¯·æ±‚GIL
    GIL->>Thread: è·å¾—GIL (ä¸²è¡Œæ‰§è¡Œ)
    Thread->>GIL: é‡Šæ”¾GIL
    Thread->>Main: è¿”å›ç»“æœ

    Main->>Process: åˆ›å»ºå¤šè¿›ç¨‹ä»»åŠ¡
    Process->>Process: åˆ›å»ºç‹¬ç«‹è¿›ç¨‹
    Process->>Process: å¹¶è¡Œæ‰§è¡Œ (ç»•è¿‡GIL)
    Process->>Main: è¿›ç¨‹é—´é€šä¿¡è¿”å›ç»“æœ

    Main->>Async: åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
    Async->>Async: äº‹ä»¶å¾ªç¯è°ƒåº¦
    Async->>Async: åç¨‹å¹¶å‘æ‰§è¡Œ
    Async->>Main: å¼‚æ­¥è¿”å›ç»“æœ
```

## 7. æ€»ç»“

Pythonçš„å¹¶è¡Œå¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–ä½“ç°äº†è¯­è¨€çš„çµæ´»æ€§å’Œå®ç”¨æ€§ï¼š

### 7.1 å¹¶è¡Œæ¨¡å‹ç‰¹ç‚¹

1. **å¤šçº¿ç¨‹**: é€‚åˆI/Oå¯†é›†å‹ä»»åŠ¡ï¼Œå—GILé™åˆ¶
2. **å¤šè¿›ç¨‹**: é€‚åˆCPUå¯†é›†å‹ä»»åŠ¡ï¼ŒçœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ
3. **å¼‚æ­¥ç¼–ç¨‹**: é€‚åˆå¤§é‡å¹¶å‘I/Oæ“ä½œï¼Œå•çº¿ç¨‹é«˜æ•ˆ
4. **æ··åˆæ¨¡å¼**: ç»“åˆå¤šç§æ–¹å¼å¤„ç†å¤æ‚åœºæ™¯

### 7.2 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

1. **é€‰æ‹©åˆé€‚çš„å¹¶è¡Œæ¨¡å‹**: æ ¹æ®ä»»åŠ¡ç‰¹æ€§é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
2. **GILæ„è¯†**: ç†è§£GILçš„å½±å“å¹¶é‡‡å–ç›¸åº”ç­–ç•¥
3. **èµ„æºç®¡ç†**: åˆç†æ§åˆ¶çº¿ç¨‹/è¿›ç¨‹æ•°é‡
4. **æ€§èƒ½ç›‘æ§**: ä½¿ç”¨ä¸“ä¸šå·¥å…·è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ

### 7.3 æœ€ä½³å®è·µ

1. **ä»»åŠ¡åˆ†ç±»**: åŒºåˆ†CPUå¯†é›†å‹å’ŒI/Oå¯†é›†å‹ä»»åŠ¡
2. **åˆç†è®¾è®¡**: é¿å…è¿‡åº¦å¹¶è¡ŒåŒ–å¸¦æ¥çš„å¼€é”€
3. **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œèµ„æºæ¸…ç†
4. **æ€§èƒ½æµ‹è¯•**: æŒç»­çš„æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–

Pythonçš„å¹¶è¡Œå¤„ç†èƒ½åŠ›ä¸ºç°ä»£åº”ç”¨ç¨‹åºæä¾›äº†å¼ºå¤§çš„æ€§èƒ½æå‡æ‰‹æ®µï¼Œåˆç†è¿ç”¨è¿™äº›æŠ€æœ¯å¯ä»¥æ˜¾è‘—æ”¹å–„ç¨‹åºçš„å“åº”æ€§å’Œååé‡ã€‚
