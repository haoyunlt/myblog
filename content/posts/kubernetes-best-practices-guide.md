# Kubernetes å®æˆ˜ç»éªŒä¸æœ€ä½³å®è·µæŒ‡å—

## ğŸ“š æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£æ±‡æ€»äº† Kubernetes ç”Ÿäº§ç¯å¢ƒçš„å®æˆ˜ç»éªŒå’Œæœ€ä½³å®è·µï¼Œæ¶µç›–é›†ç¾¤æ­å»ºã€åº”ç”¨éƒ¨ç½²ã€è¿ç»´ç›‘æ§ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨åŠ å›ºç­‰å„ä¸ªæ–¹é¢ã€‚é€šè¿‡å…·ä½“çš„æ¡ˆä¾‹å’Œé…ç½®ç¤ºä¾‹ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é«˜æ•ˆã€å®‰å…¨åœ°ä½¿ç”¨ Kubernetesã€‚

## ğŸ—ï¸ é›†ç¾¤æ¶æ„æœ€ä½³å®è·µ

### 1.1 é«˜å¯ç”¨é›†ç¾¤æ¶æ„

```mermaid
graph TB
    subgraph "è´Ÿè½½å‡è¡¡å±‚ (Load Balancer Layer)"
        LB[Load Balancer<br/>è´Ÿè½½å‡è¡¡å™¨]
        VIP[Virtual IP<br/>è™šæ‹Ÿ IP]
    end
    
    subgraph "æ§åˆ¶å¹³é¢ (Control Plane)"
        subgraph "Master Node 1"
            API1[kube-apiserver]
            ETCD1[etcd]
            SCHED1[kube-scheduler]
            CM1[kube-controller-manager]
        end
        
        subgraph "Master Node 2"
            API2[kube-apiserver]
            ETCD2[etcd]
            SCHED2[kube-scheduler]
            CM2[kube-controller-manager]
        end
        
        subgraph "Master Node 3"
            API3[kube-apiserver]
            ETCD3[etcd]
            SCHED3[kube-scheduler]
            CM3[kube-controller-manager]
        end
    end
    
    subgraph "å·¥ä½œèŠ‚ç‚¹ (Worker Nodes)"
        subgraph "Worker Node 1"
            KUBELET1[kubelet]
            PROXY1[kube-proxy]
            RUNTIME1[Container Runtime]
        end
        
        subgraph "Worker Node 2"
            KUBELET2[kubelet]
            PROXY2[kube-proxy]
            RUNTIME2[Container Runtime]
        end
        
        subgraph "Worker Node N"
            KUBELETN[kubelet]
            PROXYN[kube-proxy]
            RUNTIMEN[Container Runtime]
        end
    end
    
    subgraph "å­˜å‚¨å±‚ (Storage Layer)"
        STORAGE[åˆ†å¸ƒå¼å­˜å‚¨<br/>Ceph/GlusterFS/NFS]
    end
    
    subgraph "ç½‘ç»œå±‚ (Network Layer)"
        CNI[CNI Plugin<br/>Calico/Flannel/Cilium]
    end
    
    %% è¿æ¥å…³ç³»
    LB --> VIP
    VIP --> API1
    VIP --> API2
    VIP --> API3
    
    ETCD1 <--> ETCD2
    ETCD2 <--> ETCD3
    ETCD3 <--> ETCD1
    
    API1 --> KUBELET1
    API2 --> KUBELET2
    API3 --> KUBELETN
    
    KUBELET1 --> STORAGE
    KUBELET2 --> STORAGE
    KUBELETN --> STORAGE
    
    PROXY1 --> CNI
    PROXY2 --> CNI
    PROXYN --> CNI
    
    %% æ ·å¼å®šä¹‰
    classDef lb fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef master fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef worker fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef storage fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef network fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class LB,VIP lb
    class API1,API2,API3,ETCD1,ETCD2,ETCD3,SCHED1,SCHED2,SCHED3,CM1,CM2,CM3 master
    class KUBELET1,KUBELET2,KUBELETN,PROXY1,PROXY2,PROXYN,RUNTIME1,RUNTIME2,RUNTIMEN worker
    class STORAGE storage
    class CNI network
```

### 1.2 é›†ç¾¤è§„åˆ’æœ€ä½³å®è·µ

#### 1.2.1 èŠ‚ç‚¹è§„åˆ’

```yaml
# ç”Ÿäº§ç¯å¢ƒèŠ‚ç‚¹è§„åˆ’å»ºè®®
cluster_planning:
  # æ§åˆ¶å¹³é¢èŠ‚ç‚¹
  master_nodes:
    count: 3  # å¥‡æ•°ä¸ªï¼Œæ¨è 3 æˆ– 5 ä¸ª
    specs:
      cpu: "4 cores"
      memory: "8GB"
      disk: "100GB SSD"
    # ä¸“ç”¨æ§åˆ¶å¹³é¢ï¼Œä¸è°ƒåº¦ä¸šåŠ¡ Pod
    taints:
      - key: "node-role.kubernetes.io/control-plane"
        effect: "NoSchedule"
  
  # å·¥ä½œèŠ‚ç‚¹
  worker_nodes:
    count: ">=3"  # æ ¹æ®ä¸šåŠ¡éœ€æ±‚æ‰©å±•
    specs:
      cpu: "8+ cores"
      memory: "16+ GB"
      disk: "200+ GB SSD"
    # æŒ‰ä¸šåŠ¡ç±»å‹åˆ†ç»„
    node_groups:
      - name: "compute-intensive"
        labels:
          workload-type: "compute"
        specs:
          cpu: "16+ cores"
          memory: "32+ GB"
      - name: "memory-intensive"
        labels:
          workload-type: "memory"
        specs:
          cpu: "8+ cores"
          memory: "64+ GB"
      - name: "storage-intensive"
        labels:
          workload-type: "storage"
        specs:
          cpu: "8+ cores"
          memory: "16+ GB"
          disk: "1TB+ SSD"

# etcd é›†ç¾¤é…ç½®
etcd_cluster:
  # ä¸“ç”¨ etcd èŠ‚ç‚¹ï¼ˆå¤§è§„æ¨¡é›†ç¾¤æ¨èï¼‰
  dedicated_nodes: true
  count: 3
  specs:
    cpu: "4 cores"
    memory: "8GB"
    disk: "100GB SSD (IOPS > 3000)"
  # æ•°æ®ç›®å½•é…ç½®
  data_dir: "/var/lib/etcd"
  # å¤‡ä»½ç­–ç•¥
  backup:
    enabled: true
    schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨ 2 ç‚¹
    retention: "30d"
```

#### 1.2.2 ç½‘ç»œè§„åˆ’

```yaml
# ç½‘ç»œ CIDR è§„åˆ’
network_planning:
  # é›†ç¾¤ CIDRï¼ˆPod ç½‘ç»œï¼‰
  cluster_cidr: "10.244.0.0/16"  # æ”¯æŒ 65536 ä¸ª Pod
  
  # æœåŠ¡ CIDR
  service_cidr: "10.96.0.0/12"   # æ”¯æŒ 4096 ä¸ªæœåŠ¡
  
  # èŠ‚ç‚¹ç½‘ç»œ
  node_cidr: "192.168.1.0/24"    # ç‰©ç†èŠ‚ç‚¹ç½‘ç»œ
  
  # CNI é€‰æ‹©å»ºè®®
  cni_recommendations:
    small_cluster: "Flannel"      # < 50 èŠ‚ç‚¹
    medium_cluster: "Calico"      # 50-200 èŠ‚ç‚¹
    large_cluster: "Cilium"       # > 200 èŠ‚ç‚¹
    
  # ç½‘ç»œç­–ç•¥
  network_policies:
    enabled: true
    default_deny: true  # é»˜è®¤æ‹’ç»æ‰€æœ‰æµé‡
    
# å­˜å‚¨è§„åˆ’
storage_planning:
  # å­˜å‚¨ç±»é…ç½®
  storage_classes:
    - name: "fast-ssd"
      provisioner: "kubernetes.io/aws-ebs"
      parameters:
        type: "gp3"
        iops: "3000"
      reclaim_policy: "Retain"
      
    - name: "standard"
      provisioner: "kubernetes.io/aws-ebs"
      parameters:
        type: "gp2"
      reclaim_policy: "Delete"
      
    - name: "backup"
      provisioner: "kubernetes.io/aws-ebs"
      parameters:
        type: "sc1"
      reclaim_policy: "Retain"
```

## ğŸš€ åº”ç”¨éƒ¨ç½²æœ€ä½³å®è·µ

### 2.1 Deployment é…ç½®æœ€ä½³å®è·µ

```yaml
# ç”Ÿäº§çº§ Deployment é…ç½®ç¤ºä¾‹
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: production
  labels:
    app: web-app
    version: v1.2.3
    environment: production
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubernetes.io/change-cause: "Initial deployment v1.2.3"
spec:
  # å‰¯æœ¬æ•°é…ç½®
  replicas: 3
  
  # é€‰æ‹©å™¨å¿…é¡»åŒ¹é…æ¨¡æ¿æ ‡ç­¾
  selector:
    matchLabels:
      app: web-app
      version: v1.2.3
  
  # éƒ¨ç½²ç­–ç•¥
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%  # æœ€å¤š 25% çš„ Pod ä¸å¯ç”¨
      maxSurge: 25%        # æœ€å¤šè¶…å‡ºæœŸæœ›å‰¯æœ¬æ•° 25%
  
  # æœ€å°å°±ç»ªæ—¶é—´
  minReadySeconds: 30
  
  # è¿›åº¦æˆªæ­¢æ—¶é—´
  progressDeadlineSeconds: 600
  
  # ä¿ç•™çš„å†å²ç‰ˆæœ¬æ•°
  revisionHistoryLimit: 10
  
  template:
    metadata:
      labels:
        app: web-app
        version: v1.2.3
        environment: production
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      # æœåŠ¡è´¦æˆ·
      serviceAccountName: web-app-sa
      
      # å®‰å…¨ä¸Šä¸‹æ–‡
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      
      # å®¹å™¨é…ç½®
      containers:
      - name: web-app
        image: myregistry/web-app:v1.2.3
        
        # é•œåƒæ‹‰å–ç­–ç•¥
        imagePullPolicy: Always
        
        # ç«¯å£é…ç½®
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        
        # ç¯å¢ƒå˜é‡
        env:
        - name: ENV
          value: "production"
        - name: LOG_LEVEL
          value: "info"
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        
        # ç¯å¢ƒå˜é‡ä» ConfigMap
        envFrom:
        - configMapRef:
            name: app-config
        
        # èµ„æºé™åˆ¶å’Œè¯·æ±‚
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        
        # å­˜æ´»æ¢é’ˆ
        livenessProbe:
          httpGet:
            path: /health
            port: http
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
        
        # å°±ç»ªæ¢é’ˆ
        readinessProbe:
          httpGet:
            path: /ready
            port: http
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
          successThreshold: 1
        
        # å¯åŠ¨æ¢é’ˆ
        startupProbe:
          httpGet:
            path: /health
            port: http
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30
          successThreshold: 1
        
        # ç”Ÿå‘½å‘¨æœŸé’©å­
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - "sleep 15"  # ä¼˜é›…å…³é—­
        
        # å®‰å…¨ä¸Šä¸‹æ–‡
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
        
        # å­˜å‚¨å·æŒ‚è½½
        volumeMounts:
        - name: config-volume
          mountPath: /etc/config
          readOnly: true
        - name: secret-volume
          mountPath: /etc/secrets
          readOnly: true
        - name: tmp-volume
          mountPath: /tmp
        - name: cache-volume
          mountPath: /app/cache
      
      # é•œåƒæ‹‰å–å¯†é’¥
      imagePullSecrets:
      - name: registry-secret
      
      # å­˜å‚¨å·
      volumes:
      - name: config-volume
        configMap:
          name: app-config
      - name: secret-volume
        secret:
          secretName: app-secret
      - name: tmp-volume
        emptyDir: {}
      - name: cache-volume
        emptyDir:
          sizeLimit: 1Gi
      
      # è°ƒåº¦é…ç½®
      nodeSelector:
        workload-type: "web"
      
      # äº²å’Œæ€§é…ç½®
      affinity:
        # Pod åäº²å’Œæ€§ï¼ˆé¿å…åŒä¸€èŠ‚ç‚¹éƒ¨ç½²å¤šä¸ªå‰¯æœ¬ï¼‰
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web-app
              topologyKey: kubernetes.io/hostname
        
        # èŠ‚ç‚¹äº²å’Œæ€§
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/arch
                operator: In
                values:
                - amd64
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            preference:
              matchExpressions:
              - key: node-type
                operator: In
                values:
                - compute-optimized
      
      # å®¹å¿åº¦
      tolerations:
      - key: "workload-type"
        operator: "Equal"
        value: "web"
        effect: "NoSchedule"
      
      # æ‹“æ‰‘åˆ†å¸ƒçº¦æŸ
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: web-app
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app: web-app
      
      # ç»ˆæ­¢ä¼˜é›…æœŸ
      terminationGracePeriodSeconds: 30
      
      # DNS ç­–ç•¥
      dnsPolicy: ClusterFirst
      
      # é‡å¯ç­–ç•¥
      restartPolicy: Always
      
      # ä¼˜å…ˆçº§ç±»
      priorityClassName: high-priority

---
# Pod ä¸­æ–­é¢„ç®—
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: web-app-pdb
  namespace: production
spec:
  minAvailable: 2  # è‡³å°‘ä¿æŒ 2 ä¸ª Pod å¯ç”¨
  selector:
    matchLabels:
      app: web-app

---
# æ°´å¹³ Pod è‡ªåŠ¨æ‰©ç¼©å®¹
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-app-hpa
  namespace: production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

### 2.2 Service é…ç½®æœ€ä½³å®è·µ

```yaml
# ç”Ÿäº§çº§ Service é…ç½®
apiVersion: v1
kind: Service
metadata:
  name: web-app-service
  namespace: production
  labels:
    app: web-app
    service-type: web
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "tcp"
spec:
  type: LoadBalancer
  
  # é€‰æ‹©å™¨
  selector:
    app: web-app
  
  # ç«¯å£é…ç½®
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP
  - name: https
    port: 443
    targetPort: https
    protocol: TCP
  
  # ä¼šè¯äº²å’Œæ€§
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800  # 3 å°æ—¶
  
  # å¤–éƒ¨æµé‡ç­–ç•¥
  externalTrafficPolicy: Local  # ä¿ç•™æº IP
  
  # å¥åº·æ£€æŸ¥èŠ‚ç‚¹ç«¯å£
  healthCheckNodePort: 32000
  
  # è´Ÿè½½å‡è¡¡å™¨æºèŒƒå›´
  loadBalancerSourceRanges:
  - 10.0.0.0/8
  - 172.16.0.0/12
  - 192.168.0.0/16

---
# Headless Serviceï¼ˆç”¨äº StatefulSetï¼‰
apiVersion: v1
kind: Service
metadata:
  name: database-headless
  namespace: production
  labels:
    app: database
spec:
  clusterIP: None  # Headless Service
  selector:
    app: database
  ports:
  - name: mysql
    port: 3306
    targetPort: 3306
    protocol: TCP

---
# å†…éƒ¨æœåŠ¡
apiVersion: v1
kind: Service
metadata:
  name: internal-api
  namespace: production
  labels:
    app: internal-api
spec:
  type: ClusterIP
  selector:
    app: internal-api
  ports:
  - name: api
    port: 8080
    targetPort: 8080
    protocol: TCP
  
  # å†…éƒ¨æµé‡ç­–ç•¥
  internalTrafficPolicy: Local
```

### 2.3 ConfigMap å’Œ Secret æœ€ä½³å®è·µ

```yaml
# ConfigMap é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: production
  labels:
    app: web-app
    config-type: application
data:
  # åº”ç”¨é…ç½®
  app.properties: |
    server.port=8080
    server.servlet.context-path=/api
    
    # æ•°æ®åº“é…ç½®
    spring.datasource.url=jdbc:mysql://database-service:3306/appdb
    spring.datasource.username=appuser
    spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
    
    # è¿æ¥æ± é…ç½®
    spring.datasource.hikari.maximum-pool-size=20
    spring.datasource.hikari.minimum-idle=5
    spring.datasource.hikari.connection-timeout=30000
    
    # ç¼“å­˜é…ç½®
    spring.cache.type=redis
    spring.redis.host=redis-service
    spring.redis.port=6379
    spring.redis.timeout=2000ms
    
    # æ—¥å¿—é…ç½®
    logging.level.com.example=INFO
    logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n
  
  # Nginx é…ç½®
  nginx.conf: |
    upstream backend {
        server web-app-service:8080;
    }
    
    server {
        listen 80;
        server_name example.com;
        
        location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        location /health {
            access_log off;
            return 200 "healthy\n";
        }
    }

---
# Secret é…ç½®
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
  namespace: production
  labels:
    app: web-app
    secret-type: application
type: Opaque
data:
  # æ•°æ®åº“å¯†ç ï¼ˆBase64 ç¼–ç ï¼‰
  db-password: cGFzc3dvcmQxMjM=
  
  # API å¯†é’¥
  api-key: YWJjZGVmZ2hpams=
  
  # JWT å¯†é’¥
  jwt-secret: bXlqd3RzZWNyZXRrZXk=

---
# TLS Secret
apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
  namespace: production
  labels:
    app: web-app
    secret-type: tls
type: kubernetes.io/tls
data:
  tls.crt: |
    LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0t...
  tls.key: |
    LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0t...

---
# é•œåƒæ‹‰å– Secret
apiVersion: v1
kind: Secret
metadata:
  name: registry-secret
  namespace: production
  labels:
    secret-type: registry
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: |
    eyJhdXRocyI6eyJteXJlZ2lzdHJ5LmNvbSI6eyJ1c2VybmFtZSI6InVzZXIiLCJwYXNzd29yZCI6InBhc3MiLCJhdXRoIjoiZFhObGNqcHdZWE56In19fQ==
```

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

### 3.1 RBAC æƒé™æ§åˆ¶

```yaml
# æœåŠ¡è´¦æˆ·
apiVersion: v1
kind: ServiceAccount
metadata:
  name: web-app-sa
  namespace: production
  labels:
    app: web-app
automountServiceAccountToken: false  # ç¦ç”¨è‡ªåŠ¨æŒ‚è½½

---
# è§’è‰²å®šä¹‰
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: production
  name: web-app-role
rules:
# å…è®¸è¯»å– ConfigMap å’Œ Secret
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list"]
# å…è®¸åˆ›å»ºäº‹ä»¶
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create"]

---
# è§’è‰²ç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: web-app-rolebinding
  namespace: production
subjects:
- kind: ServiceAccount
  name: web-app-sa
  namespace: production
roleRef:
  kind: Role
  name: web-app-role
  apiGroup: rbac.authorization.k8s.io

---
# é›†ç¾¤è§’è‰²ï¼ˆè·¨å‘½åç©ºé—´æƒé™ï¼‰
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: monitoring-reader
rules:
- apiGroups: [""]
  resources: ["nodes", "nodes/metrics", "services", "endpoints", "pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions", "apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch"]

---
# é›†ç¾¤è§’è‰²ç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: monitoring-binding
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
roleRef:
  kind: ClusterRole
  name: monitoring-reader
  apiGroup: rbac.authorization.k8s.io
```

### 3.2 ç½‘ç»œç­–ç•¥

```yaml
# é»˜è®¤æ‹’ç»æ‰€æœ‰æµé‡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# å…è®¸ Web åº”ç”¨æ¥æ”¶æµé‡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: web-app-ingress
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: web-app
  policyTypes:
  - Ingress
  ingress:
  # å…è®¸æ¥è‡ªè´Ÿè½½å‡è¡¡å™¨çš„æµé‡
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  # å…è®¸æ¥è‡ªåŒå‘½åç©ºé—´çš„æµé‡
  - from:
    - podSelector:
        matchLabels:
          role: frontend
    ports:
    - protocol: TCP
      port: 8080

---
# å…è®¸ Web åº”ç”¨è®¿é—®æ•°æ®åº“
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: web-app-egress
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: web-app
  policyTypes:
  - Egress
  egress:
  # å…è®¸è®¿é—®æ•°æ®åº“
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 3306
  # å…è®¸è®¿é—® Redis
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  # å…è®¸ DNS è§£æ
  - to: []
    ports:
    - protocol: UDP
      port: 53
  # å…è®¸ HTTPS å‡ºç«™æµé‡
  - to: []
    ports:
    - protocol: TCP
      port: 443

---
# æ•°æ®åº“ç½‘ç»œç­–ç•¥
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-policy
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: database
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # åªå…è®¸æ¥è‡ª Web åº”ç”¨çš„è¿æ¥
  - from:
    - podSelector:
        matchLabels:
          app: web-app
    ports:
    - protocol: TCP
      port: 3306
  egress:
  # å…è®¸ DNS è§£æ
  - to: []
    ports:
    - protocol: UDP
      port: 53
```

### 3.3 Pod Security Standards

```yaml
# Pod å®‰å…¨ç­–ç•¥
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    # Pod Security Standards
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

---
# å®‰å…¨ä¸Šä¸‹æ–‡çº¦æŸï¼ˆOpenShiftï¼‰
apiVersion: security.openshift.io/v1
kind: SecurityContextConstraints
metadata:
  name: restricted-scc
allowHostDirVolumePlugin: false
allowHostIPC: false
allowHostNetwork: false
allowHostPID: false
allowHostPorts: false
allowPrivilegedContainer: false
allowedCapabilities: []
defaultAddCapabilities: []
requiredDropCapabilities:
- ALL
allowedFlexVolumes: []
fsGroup:
  type: MustRunAs
  ranges:
  - min: 1000
    max: 65535
readOnlyRootFilesystem: true
runAsUser:
  type: MustRunAsNonRoot
seLinuxContext:
  type: MustRunAs
supplementalGroups:
  type: MustRunAs
  ranges:
  - min: 1000
    max: 65535
volumes:
- configMap
- downwardAPI
- emptyDir
- persistentVolumeClaim
- projected
- secret
```

## ğŸ“Š ç›‘æ§å’Œå¯è§‚æµ‹æ€§æœ€ä½³å®è·µ

### 4.1 Prometheus ç›‘æ§é…ç½®

```yaml
# Prometheus é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'production'
        region: 'us-west-2'
    
    rule_files:
    - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093
    
    scrape_configs:
    # Kubernetes API Server
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
    
    # Kubernetes Nodes
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics
    
    # Kubernetes Pods
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name
    
    # åº”ç”¨ç¨‹åºæŒ‡æ ‡
    - job_name: 'web-app'
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_label_app]
        action: keep
        regex: web-app
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        action: keep
        regex: metrics

---
# Prometheus å‘Šè­¦è§„åˆ™
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
data:
  kubernetes.yml: |
    groups:
    - name: kubernetes.rules
      rules:
      # èŠ‚ç‚¹ CPU ä½¿ç”¨ç‡
      - alert: NodeCPUUsage
        expr: (100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "èŠ‚ç‚¹ CPU ä½¿ç”¨ç‡è¿‡é«˜"
          description: "èŠ‚ç‚¹ {{ $labels.instance }} CPU ä½¿ç”¨ç‡ä¸º {{ $value }}%"
      
      # èŠ‚ç‚¹å†…å­˜ä½¿ç”¨ç‡
      - alert: NodeMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "èŠ‚ç‚¹å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "èŠ‚ç‚¹ {{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡ä¸º {{ $value }}%"
      
      # èŠ‚ç‚¹ç£ç›˜ä½¿ç”¨ç‡
      - alert: NodeDiskUsage
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "èŠ‚ç‚¹ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "èŠ‚ç‚¹ {{ $labels.instance }} ç£ç›˜ {{ $labels.mountpoint }} ä½¿ç”¨ç‡ä¸º {{ $value }}%"
      
      # Pod CPU ä½¿ç”¨ç‡
      - alert: PodCPUUsage
        expr: sum by (namespace, pod) (rate(container_cpu_usage_seconds_total{container!="POD",container!=""}[5m])) / sum by (namespace, pod) (container_spec_cpu_quota{container!="POD",container!=""}/container_spec_cpu_period{container!="POD",container!=""}) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod CPU ä½¿ç”¨ç‡è¿‡é«˜"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} CPU ä½¿ç”¨ç‡ä¸º {{ $value }}%"
      
      # Pod å†…å­˜ä½¿ç”¨ç‡
      - alert: PodMemoryUsage
        expr: sum by (namespace, pod) (container_memory_working_set_bytes{container!="POD",container!=""}) / sum by (namespace, pod) (container_spec_memory_limit_bytes{container!="POD",container!=""}) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Pod å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} å†…å­˜ä½¿ç”¨ç‡ä¸º {{ $value }}%"
      
      # Pod é‡å¯æ¬¡æ•°
      - alert: PodRestartCount
        expr: increase(kube_pod_container_status_restarts_total[1h]) > 5
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Pod é‡å¯æ¬¡æ•°è¿‡å¤š"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} åœ¨è¿‡å» 1 å°æ—¶å†…é‡å¯äº† {{ $value }} æ¬¡"
      
      # Deployment å‰¯æœ¬æ•°ä¸è¶³
      - alert: DeploymentReplicasMismatch
        expr: kube_deployment_spec_replicas != kube_deployment_status_available_replicas
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Deployment å‰¯æœ¬æ•°ä¸åŒ¹é…"
          description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} æœŸæœ›å‰¯æœ¬æ•° {{ $labels.spec_replicas }}ï¼Œå®é™…å¯ç”¨å‰¯æœ¬æ•° {{ $labels.available_replicas }}"

  application.yml: |
    groups:
    - name: application.rules
      rules:
      # HTTP é”™è¯¯ç‡
      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{status=~"5.."}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service) * 100 > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "HTTP é”™è¯¯ç‡è¿‡é«˜"
          description: "æœåŠ¡ {{ $labels.service }} HTTP 5xx é”™è¯¯ç‡ä¸º {{ $value }}%"
      
      # HTTP å“åº”æ—¶é—´
      - alert: HighLatency
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "HTTP å“åº”æ—¶é—´è¿‡é•¿"
          description: "æœåŠ¡ {{ $labels.service }} 95% å“åº”æ—¶é—´ä¸º {{ $value }}s"
      
      # æ•°æ®åº“è¿æ¥æ•°
      - alert: DatabaseConnectionHigh
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜"
          description: "æ•°æ®åº“è¿æ¥ä½¿ç”¨ç‡ä¸º {{ $value }}%"
```

### 4.2 æ—¥å¿—æ”¶é›†é…ç½®

```yaml
# Fluent Bit é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: logging
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020
    
    [INPUT]
        Name              tail
        Path              /var/log/containers/*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On
    
    [INPUT]
        Name              systemd
        Tag               host.*
        Systemd_Filter    _SYSTEMD_UNIT=kubelet.service
        Systemd_Filter    _SYSTEMD_UNIT=docker.service
    
    [FILTER]
        Name                kubernetes
        Match               kube.*
        Kube_URL            https://kubernetes.default.svc:443
        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token
        Kube_Tag_Prefix     kube.var.log.containers.
        Merge_Log           On
        Merge_Log_Key       log_processed
        K8S-Logging.Parser  On
        K8S-Logging.Exclude Off
        Annotations         Off
        Labels              On
    
    [FILTER]
        Name                nest
        Match               kube.*
        Operation           lift
        Nested_under        kubernetes
        Add_prefix          kubernetes_
    
    [FILTER]
        Name                modify
        Match               kube.*
        Remove              kubernetes_pod_id
        Remove              kubernetes_docker_id
        Remove              kubernetes_container_hash
    
    [OUTPUT]
        Name                elasticsearch
        Match               kube.*
        Host                elasticsearch.logging.svc.cluster.local
        Port                9200
        Index               kubernetes
        Type                _doc
        Logstash_Format     On
        Logstash_Prefix     kubernetes
        Logstash_DateFormat %Y.%m.%d
        Time_Key            @timestamp
        Time_Key_Format     %Y-%m-%dT%H:%M:%S.%L%z
        Retry_Limit         False
    
    [OUTPUT]
        Name                elasticsearch
        Match               host.*
        Host                elasticsearch.logging.svc.cluster.local
        Port                9200
        Index               system
        Type                _doc
        Logstash_Format     On
        Logstash_Prefix     system
        Logstash_DateFormat %Y.%m.%d
        Time_Key            @timestamp
        Time_Key_Format     %Y-%m-%dT%H:%M:%S.%L%z
        Retry_Limit         False

  parsers.conf: |
    [PARSER]
        Name        docker
        Format      json
        Time_Key    time
        Time_Format %Y-%m-%dT%H:%M:%S.%L%z
        Time_Keep   On
    
    [PARSER]
        Name        nginx
        Format      regex
        Regex       ^(?<remote>[^ ]*) (?<host>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
        Time_Key    time
        Time_Format %d/%b/%Y:%H:%M:%S %z
    
    [PARSER]
        Name        apache
        Format      regex
        Regex       ^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
        Time_Key    time
        Time_Format %d/%b/%Y:%H:%M:%S %z
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

### 5.1 é›†ç¾¤æ€§èƒ½è°ƒä¼˜

```yaml
# etcd æ€§èƒ½ä¼˜åŒ–é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: etcd-config
  namespace: kube-system
data:
  etcd.conf.yml: |
    # æ•°æ®ç›®å½•
    data-dir: /var/lib/etcd
    
    # ç½‘ç»œé…ç½®
    listen-client-urls: https://0.0.0.0:2379
    advertise-client-urls: https://etcd-1:2379,https://etcd-2:2379,https://etcd-3:2379
    listen-peer-urls: https://0.0.0.0:2380
    initial-advertise-peer-urls: https://etcd-1:2380
    
    # é›†ç¾¤é…ç½®
    initial-cluster: etcd-1=https://etcd-1:2380,etcd-2=https://etcd-2:2380,etcd-3=https://etcd-3:2380
    initial-cluster-state: new
    initial-cluster-token: etcd-cluster
    
    # æ€§èƒ½è°ƒä¼˜
    heartbeat-interval: 100
    election-timeout: 1000
    max-snapshots: 5
    max-wals: 5
    snapshot-count: 100000
    
    # å‹ç¼©é…ç½®
    auto-compaction-retention: "1h"
    auto-compaction-mode: periodic
    
    # é…é¢è®¾ç½®
    quota-backend-bytes: 8589934592  # 8GB
    
    # æ—¥å¿—é…ç½®
    log-level: info
    logger: zap
    log-outputs: [stderr]
    
    # å®‰å…¨é…ç½®
    client-transport-security:
      cert-file: /etc/etcd/pki/etcd.crt
      key-file: /etc/etcd/pki/etcd.key
      client-cert-auth: true
      trusted-ca-file: /etc/etcd/pki/ca.crt
    peer-transport-security:
      cert-file: /etc/etcd/pki/etcd.crt
      key-file: /etc/etcd/pki/etcd.key
      peer-client-cert-auth: true
      trusted-ca-file: /etc/etcd/pki/ca.crt

---
# kube-apiserver æ€§èƒ½ä¼˜åŒ–
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - name: kube-apiserver
    image: k8s.gcr.io/kube-apiserver:v1.29.0
    command:
    - kube-apiserver
    # åŸºç¡€é…ç½®
    - --advertise-address=192.168.1.10
    - --bind-address=0.0.0.0
    - --secure-port=6443
    
    # etcd é…ç½®
    - --etcd-servers=https://etcd-1:2379,https://etcd-2:2379,https://etcd-3:2379
    - --etcd-cafile=/etc/etcd/pki/ca.crt
    - --etcd-certfile=/etc/etcd/pki/etcd.crt
    - --etcd-keyfile=/etc/etcd/pki/etcd.key
    
    # æ€§èƒ½è°ƒä¼˜
    - --max-requests-inflight=3000
    - --max-mutating-requests-inflight=1000
    - --request-timeout=60s
    - --min-request-timeout=1800
    
    # å®¡è®¡é…ç½®
    - --audit-log-maxage=30
    - --audit-log-maxbackup=10
    - --audit-log-maxsize=100
    - --audit-log-path=/var/log/audit.log
    - --audit-policy-file=/etc/kubernetes/audit-policy.yaml
    
    # è®¤è¯æˆæƒ
    - --authorization-mode=Node,RBAC
    - --enable-admission-plugins=NodeRestriction,ResourceQuota,PodSecurityPolicy
    - --disable-admission-plugins=StorageObjectInUseProtection
    
    # æœåŠ¡è´¦æˆ·
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    
    # ç½‘ç»œé…ç½®
    - --service-cluster-ip-range=10.96.0.0/12
    - --service-node-port-range=30000-32767
    
    # åŠŸèƒ½é—¨æ§
    - --feature-gates=RemoveSelfLink=false
    
    # æ—¥å¿—é…ç½®
    - --v=2
    - --logtostderr=true
    
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 2
        memory: 2Gi

---
# kube-controller-manager æ€§èƒ½ä¼˜åŒ–
apiVersion: v1
kind: Pod
metadata:
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - name: kube-controller-manager
    image: k8s.gcr.io/kube-controller-manager:v1.29.0
    command:
    - kube-controller-manager
    # åŸºç¡€é…ç½®
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    
    # æ€§èƒ½è°ƒä¼˜
    - --concurrent-deployment-syncs=10
    - --concurrent-replicaset-syncs=10
    - --concurrent-service-syncs=5
    - --concurrent-endpoint-syncs=10
    - --concurrent-namespace-syncs=10
    - --concurrent-gc-syncs=30
    
    # æ§åˆ¶å™¨é…ç½®
    - --node-monitor-period=5s
    - --node-monitor-grace-period=40s
    - --pod-eviction-timeout=5m0s
    - --terminated-pod-gc-threshold=12500
    
    # é›†ç¾¤é…ç½®
    - --cluster-cidr=10.244.0.0/16
    - --service-cluster-ip-range=10.96.0.0/12
    - --cluster-name=kubernetes
    
    # è¯ä¹¦é…ç½®
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    
    # åŠŸèƒ½é—¨æ§
    - --feature-gates=RemoveSelfLink=false
    
    # æ—¥å¿—é…ç½®
    - --v=2
    - --logtostderr=true
    
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1Gi

---
# kube-scheduler æ€§èƒ½ä¼˜åŒ–
apiVersion: v1
kind: Pod
metadata:
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - name: kube-scheduler
    image: k8s.gcr.io/kube-scheduler:v1.29.0
    command:
    - kube-scheduler
    # åŸºç¡€é…ç½®
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --config=/etc/kubernetes/scheduler-config.yaml
    
    # æ—¥å¿—é…ç½®
    - --v=2
    - --logtostderr=true
    
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi

---
# è°ƒåº¦å™¨é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: scheduler-config
  namespace: kube-system
data:
  config.yaml: |
    apiVersion: kubescheduler.config.k8s.io/v1beta3
    kind: KubeSchedulerConfiguration
    profiles:
    - schedulerName: default-scheduler
      plugins:
        score:
          enabled:
          - name: NodeResourcesFit
          - name: NodeAffinity
          - name: PodTopologySpread
          - name: InterPodAffinity
          disabled:
          - name: NodeResourcesLeastAllocated
      pluginConfig:
      - name: NodeResourcesFit
        args:
          scoringStrategy:
            type: LeastAllocated
            resources:
            - name: cpu
              weight: 1
            - name: memory
              weight: 1
      - name: PodTopologySpread
        args:
          defaultConstraints:
          - maxSkew: 1
            topologyKey: kubernetes.io/hostname
            whenUnsatisfiable: ScheduleAnyway
          - maxSkew: 1
            topologyKey: topology.kubernetes.io/zone
            whenUnsatisfiable: ScheduleAnyway
    
    # æ€§èƒ½è°ƒä¼˜
    percentageOfNodesToScore: 50
    podInitialBackoffSeconds: 1
    podMaxBackoffSeconds: 10
```

### 5.2 åº”ç”¨æ€§èƒ½ä¼˜åŒ–

```yaml
# å‚ç›´ Pod è‡ªåŠ¨æ‰©ç¼©å®¹
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: web-app-vpa
  namespace: production
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  updatePolicy:
    updateMode: "Auto"  # Auto, Recreation, Initial, Off
  resourcePolicy:
    containerPolicies:
    - containerName: web-app
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 2Gi
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits

---
# é›†ç¾¤è‡ªåŠ¨æ‰©ç¼©å®¹
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-autoscaler-status
  namespace: kube-system
data:
  nodes.max: "100"
  nodes.min: "3"
  scale-down-delay-after-add: "10m"
  scale-down-unneeded-time: "10m"
  scale-down-utilization-threshold: "0.5"
  skip-nodes-with-local-storage: "false"
  skip-nodes-with-system-pods: "false"

---
# ä¼˜å…ˆçº§ç±»é…ç½®
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000
globalDefault: false
description: "é«˜ä¼˜å…ˆçº§ç±»ï¼Œç”¨äºå…³é”®ä¸šåŠ¡åº”ç”¨"

---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority
value: 100
globalDefault: false
description: "ä½ä¼˜å…ˆçº§ç±»ï¼Œç”¨äºæ‰¹å¤„ç†ä»»åŠ¡"

---
# èµ„æºé…é¢
apiVersion: v1
kind: ResourceQuota
metadata:
  name: production-quota
  namespace: production
spec:
  hard:
    # è®¡ç®—èµ„æº
    requests.cpu: "100"
    requests.memory: 200Gi
    limits.cpu: "200"
    limits.memory: 400Gi
    
    # å­˜å‚¨èµ„æº
    requests.storage: 1Ti
    persistentvolumeclaims: "50"
    
    # å¯¹è±¡æ•°é‡
    pods: "100"
    services: "20"
    secrets: "50"
    configmaps: "50"
    replicationcontrollers: "20"
    deployments.apps: "20"
    replicasets.apps: "20"
    statefulsets.apps: "10"
    jobs.batch: "20"
    cronjobs.batch: "10"

---
# é™åˆ¶èŒƒå›´
apiVersion: v1
kind: LimitRange
metadata:
  name: production-limits
  namespace: production
spec:
  limits:
  # Pod é™åˆ¶
  - type: Pod
    max:
      cpu: "4"
      memory: 8Gi
    min:
      cpu: 50m
      memory: 64Mi
  
  # å®¹å™¨é™åˆ¶
  - type: Container
    default:
      cpu: 200m
      memory: 256Mi
    defaultRequest:
      cpu: 100m
      memory: 128Mi
    max:
      cpu: "2"
      memory: 4Gi
    min:
      cpu: 50m
      memory: 64Mi
  
  # PVC é™åˆ¶
  - type: PersistentVolumeClaim
    max:
      storage: 100Gi
    min:
      storage: 1Gi
```

## ğŸ“š æ€»ç»“

### æ ¸å¿ƒæœ€ä½³å®è·µæ€»ç»“

1. **é«˜å¯ç”¨æ¶æ„**ï¼šå¤šä¸»èŠ‚ç‚¹ã€etcd é›†ç¾¤ã€è´Ÿè½½å‡è¡¡
2. **å®‰å…¨åŠ å›º**ï¼šRBACã€ç½‘ç»œç­–ç•¥ã€Pod å®‰å…¨æ ‡å‡†
3. **èµ„æºç®¡ç†**ï¼šèµ„æºé…é¢ã€é™åˆ¶èŒƒå›´ã€ä¼˜å…ˆçº§ç±»
4. **ç›‘æ§è§‚æµ‹**ï¼šPrometheus ç›‘æ§ã€æ—¥å¿—æ”¶é›†ã€å‘Šè­¦è§„åˆ™
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šè‡ªåŠ¨æ‰©ç¼©å®¹ã€èµ„æºè°ƒä¼˜ã€è°ƒåº¦ä¼˜åŒ–

### è¿ç»´å»ºè®®

1. **æ¸è¿›å¼éƒ¨ç½²**ï¼šä½¿ç”¨æ»šåŠ¨æ›´æ–°å’Œé‡‘ä¸é›€éƒ¨ç½²
2. **å¤‡ä»½æ¢å¤**ï¼šå®šæœŸå¤‡ä»½ etcd å’ŒæŒä¹…åŒ–æ•°æ®
3. **å®¹é‡è§„åˆ’**ï¼šåŸºäºç›‘æ§æ•°æ®è¿›è¡Œå®¹é‡è§„åˆ’
4. **æ•…éšœæ¼”ç»ƒ**ï¼šå®šæœŸè¿›è¡Œæ•…éšœæ¼”ç»ƒå’Œæ¢å¤æµ‹è¯•
5. **æ–‡æ¡£ç»´æŠ¤**ï¼šä¿æŒè¿ç»´æ–‡æ¡£å’Œé…ç½®çš„åŠæ—¶æ›´æ–°

é€šè¿‡éµå¾ªè¿™äº›æœ€ä½³å®è·µï¼Œå¯ä»¥æ„å»ºç¨³å®šã€å®‰å…¨ã€é«˜æ€§èƒ½çš„ Kubernetes ç”Ÿäº§ç¯å¢ƒã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´09æœˆ27æ—¥  
**é€‚ç”¨ç‰ˆæœ¬**: Kubernetes 1.29+
