---
title: "VoiceHelper æœ€ä½³å®è·µä¸ä½¿ç”¨æ¡ˆä¾‹"
date: 2025-09-28T00:47:16+08:00
draft: false
tags: ['æºç åˆ†æ', 'æŠ€æœ¯æ–‡æ¡£', 'æœ€ä½³å®è·µ']
categories: ['AIåº”ç”¨']
description: "VoiceHelper æœ€ä½³å®è·µä¸ä½¿ç”¨æ¡ˆä¾‹çš„æ·±å…¥æŠ€æœ¯åˆ†ææ–‡æ¡£"
keywords: ['æºç åˆ†æ', 'æŠ€æœ¯æ–‡æ¡£', 'æœ€ä½³å®è·µ']
author: "æŠ€æœ¯åˆ†æå¸ˆ"
weight: 1
---

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æ•´ç†äº†VoiceHelperç³»ç»Ÿå¼€å‘å’Œä½¿ç”¨è¿‡ç¨‹ä¸­çš„æœ€ä½³å®è·µã€è®¾è®¡æ¨¡å¼ã€æ€§èƒ½ä¼˜åŒ–æŠ€å·§å’Œå®é™…åº”ç”¨æ¡ˆä¾‹ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€ŸæŒæ¡ç³»ç»Ÿç²¾é«“ï¼Œé¿å…å¸¸è§é™·é˜±ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡æœ€ä½³å®è·µ

### 1. å¾®æœåŠ¡æ¶æ„æ¨¡å¼

#### æœåŠ¡æ‹†åˆ†åŸåˆ™

```mermaid
graph TB
    subgraph "æœåŠ¡æ‹†åˆ†ç­–ç•¥"
        A[ä¸šåŠ¡è¾¹ç•Œæ¸…æ™°]
        B[æ•°æ®ç‹¬ç«‹æ€§]
        C[æŠ€æœ¯æ ˆåŒ¹é…]
        D[å›¢é˜Ÿç»„ç»‡ç»“æ„]
        
        A --> A1[å•ä¸€èŒè´£]
        A --> A2[é«˜å†…èšä½è€¦åˆ]
        
        B --> B1[ç‹¬ç«‹æ•°æ®åº“]
        B --> B2[æœ€å°æ•°æ®å…±äº«]
        
        C --> C1[Goç½‘å…³å±‚<br/>é«˜å¹¶å‘å¤„ç†]
        C --> C2[Pythonç®—æ³•å±‚<br/>AIæ¨¡å‹é›†æˆ]
        
        D --> D1[å›¢é˜Ÿè‡ªæ²»]
        D --> D2[ç‹¬ç«‹éƒ¨ç½²]
    end
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
```

#### æœåŠ¡é€šä¿¡æ¨¡å¼å®è·µ

```go
// 1. åŒæ­¥é€šä¿¡ - é€‚ç”¨äºå…³é”®è·¯å¾„å’Œä½å»¶è¿Ÿéœ€æ±‚
type AlgoServiceClient struct {
    baseURL    string
    httpClient *http.Client
    circuitBreaker *CircuitBreaker
}

func (c *AlgoServiceClient) QueryWithTimeout(
    ctx context.Context,
    request *QueryRequest,
) (*QueryResponse, error) {
    // è®¾ç½®è¶…æ—¶ä¸Šä¸‹æ–‡
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()
    
    // ç†”æ–­å™¨ä¿æŠ¤
    return c.circuitBreaker.Execute(func() (*QueryResponse, error) {
        return c.sendRequest(ctx, request)
    })
}

// 2. å¼‚æ­¥é€šä¿¡ - é€‚ç”¨äºè€—æ—¶ä»»åŠ¡å’Œè§£è€¦åœºæ™¯
type EventBus struct {
    subscribers map[string][]EventHandler
    mu         sync.RWMutex
}

func (eb *EventBus) PublishAsync(event Event) {
    go func() {
        eb.mu.RLock()
        handlers := eb.subscribers[event.Type]
        eb.mu.RUnlock()
        
        for _, handler := range handlers {
            go func(h EventHandler) {
                if err := h.Handle(event); err != nil {
                    log.Error("Event handling failed",
                        zap.Error(err),
                        zap.String("event_type", event.Type))
                }
            }(handler)
        }
    }()
}

// 3. æµå¼é€šä¿¡ - é€‚ç”¨äºå®æ—¶æ•°æ®ä¼ è¾“
func (h *VoiceHandler) StreamProcessing(stream VoiceStream) error {
    for {
        select {
        case audioChunk := <-stream.AudioChannel:
            // å¤„ç†éŸ³é¢‘å—
            if err := h.processAudioChunk(audioChunk); err != nil {
                return fmt.Errorf("audio processing failed: %w", err)
            }
            
        case <-stream.Context.Done():
            return stream.Context.Err()
            
        case <-time.After(30 * time.Second):
            return errors.New("stream timeout")
        }
    }
}
```

### 2. æ•°æ®ä¸€è‡´æ€§è®¾è®¡

#### åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†

```python
# Sagaæ¨¡å¼å®ç° - å¤„ç†è·¨æœåŠ¡äº‹åŠ¡
class DocumentIngestSaga:
    """æ–‡æ¡£å…¥åº“çš„åˆ†å¸ƒå¼äº‹åŠ¡åè°ƒå™¨"""
    
    def __init__(self):
        self.steps = [
            ('parse_documents', self.parse_documents, self.compensate_parse),
            ('generate_embeddings', self.generate_embeddings, self.compensate_embeddings),
            ('update_index', self.update_index, self.compensate_index),
            ('store_metadata', self.store_metadata, self.compensate_metadata)
        ]
    
    async def execute(self, request: IngestRequest) -> IngestResult:
        """æ‰§è¡ŒSagaäº‹åŠ¡"""
        executed_steps = []
        
        try:
            for step_name, action, compensate in self.steps:
                logger.info(f"Executing step: {step_name}")
                result = await action(request)
                executed_steps.append((step_name, compensate, result))
                
            return IngestResult(success=True, task_id=request.task_id)
            
        except Exception as e:
            logger.error(f"Saga execution failed: {e}")
            await self.compensate_all(executed_steps)
            raise
    
    async def compensate_all(self, executed_steps: List):
        """è¡¥å¿å·²æ‰§è¡Œçš„æ­¥éª¤"""
        for step_name, compensate_func, result in reversed(executed_steps):
            try:
                await compensate_func(result)
                logger.info(f"Compensated step: {step_name}")
            except Exception as e:
                logger.error(f"Compensation failed for {step_name}: {e}")
    
    async def parse_documents(self, request: IngestRequest):
        """è§£ææ–‡æ¡£æ­¥éª¤"""
        parsed_docs = []
        for file in request.files:
            doc = await self.document_parser.parse(file)
            parsed_docs.append(doc)
        return parsed_docs
    
    async def compensate_parse(self, parsed_docs: List):
        """æ¸…ç†å·²è§£æçš„æ–‡æ¡£"""
        for doc in parsed_docs:
            if hasattr(doc, 'temp_file_path'):
                os.remove(doc.temp_file_path)

# äº‹ä»¶æº¯æºæ¨¡å¼ - ä¿è¯æ•°æ®ä¸€è‡´æ€§å’Œå¯è¿½æº¯æ€§
class ConversationEventStore:
    """å¯¹è¯äº‹ä»¶å­˜å‚¨"""
    
    async def append_event(self, event: ConversationEvent):
        """è¿½åŠ äº‹ä»¶åˆ°äº‹ä»¶æµ"""
        await self.db.execute("""
            INSERT INTO conversation_events
            (conversation_id, event_type, event_data, timestamp, version)
            VALUES ($1, $2, $3, $4, $5)
        """, event.conversation_id, event.type,
            json.dumps(event.data), event.timestamp, event.version)
    
    async def replay_events(self, conversation_id: str) -> Conversation:
        """é‡æ”¾äº‹ä»¶é‡æ„å¯¹è¯çŠ¶æ€"""
        events = await self.db.fetch("""
            SELECT * FROM conversation_events
            WHERE conversation_id = $1
            ORDER BY version ASC
        """, conversation_id)
        
        conversation = Conversation(id=conversation_id)
        
        for event_row in events:
            event = ConversationEvent.from_row(event_row)
            conversation = self.apply_event(conversation, event)
        
        return conversation
```

### 3. ç¼“å­˜ç­–ç•¥è®¾è®¡

#### å¤šå±‚ç¼“å­˜æ¶æ„

```typescript
/**

 * å¤šå±‚ç¼“å­˜ç­–ç•¥å®ç°
 * L1: å†…å­˜ç¼“å­˜ (æœ€å¿«ï¼Œå®¹é‡å°)
 * L2: Redisç¼“å­˜ (å¿«é€Ÿï¼Œå®¹é‡ä¸­ç­‰)
 * L3: æ•°æ®åº“ (æ…¢é€Ÿï¼Œå®¹é‡å¤§)

 */
class MultiLevelCacheManager {
  private l1Cache = new Map<string, CacheEntry>();
  private l2Cache: Redis;
  private l3Database: Database;
  
  constructor() {
    // L1ç¼“å­˜æ¸…ç†å®šæ—¶å™¨
    setInterval(() => this.cleanupL1Cache(), 60000);
  }
  
  async get<T>(key: string): Promise<T | null> {
    // L1ç¼“å­˜æŸ¥æ‰¾
    const l1Entry = this.l1Cache.get(key);
    if (l1Entry && !this.isExpired(l1Entry)) {
      this.updateL1Stats('hit');
      return l1Entry.data as T;
    }
    
    // L2ç¼“å­˜æŸ¥æ‰¾
    try {
      const l2Data = await this.l2Cache.get(key);
      if (l2Data) {
        const parsed = JSON.parse(l2Data);
        // å›å¡«L1ç¼“å­˜
        this.setL1(key, parsed, 300000); // 5åˆ†é’Ÿ
        this.updateL2Stats('hit');
        return parsed as T;
      }
    } catch (error) {
      console.warn('L2 cache error:', error);
    }
    
    // L3æ•°æ®åº“æŸ¥è¯¢
    const dbData = await this.queryDatabase<T>(key);
    if (dbData) {
      // å›å¡«å¤šçº§ç¼“å­˜
      await this.setL2(key, dbData, 3600000); // 1å°æ—¶
      this.setL1(key, dbData, 300000); // 5åˆ†é’Ÿ
      this.updateL3Stats('hit');
      return dbData;
    }
    
    return null;
  }
  
  async set<T>(key: string, data: T, options?: CacheOptions): Promise<void> {
    const { l1Ttl = 300000, l2Ttl = 3600000, writeThrough = true } = options || {};
    
    // åŒæ—¶æ›´æ–°å¤šçº§ç¼“å­˜
    this.setL1(key, data, l1Ttl);
    await this.setL2(key, data, l2Ttl);
    
    // å¯é€‰çš„å†™ç©¿é€
    if (writeThrough) {
      await this.updateDatabase(key, data);
    }
  }
  
  private setL1<T>(key: string, data: T, ttl: number): void {
    this.l1Cache.set(key, {
      data,
      expiresAt: Date.now() + ttl,
      accessCount: 1,
      lastAccess: Date.now()
    });
  }
  
  private async setL2<T>(key: string, data: T, ttl: number): Promise<void> {
    await this.l2Cache.setex(key, Math.floor(ttl / 1000), JSON.stringify(data));
  }
  
  // æ™ºèƒ½ç¼“å­˜é¢„çƒ­
  async warmupCache(patterns: string[]): Promise<void> {
    const warmupTasks = patterns.map(async (pattern) => {
      const keys = await this.l2Cache.keys(pattern);
      
      for (const key of keys.slice(0, 100)) { // é™åˆ¶é¢„çƒ­æ•°é‡
        const data = await this.l2Cache.get(key);
        if (data) {
          this.setL1(key, JSON.parse(data), 600000); // 10åˆ†é’Ÿ
        }
      }
    });
    
    await Promise.all(warmupTasks);
    console.log(`Cache warmed up for ${patterns.length} patterns`);
  }
  
  // ç¼“å­˜å¤±æ•ˆç­–ç•¥
  async invalidatePattern(pattern: string): Promise<void> {
    // æ¸…ç†L1ç¼“å­˜
    for (const key of this.l1Cache.keys()) {
      if (this.matchPattern(key, pattern)) {
        this.l1Cache.delete(key);
      }
    }
    
    // æ¸…ç†L2ç¼“å­˜
    const keys = await this.l2Cache.keys(pattern);
    if (keys.length > 0) {
      await this.l2Cache.del(...keys);
    }
    
    console.log(`Invalidated cache pattern: ${pattern}`);
  }
}

// ç¼“å­˜ä½¿ç”¨ç¤ºä¾‹
class ConversationService {
  constructor(private cache: MultiLevelCacheManager) {}
  
  async getConversation(id: string): Promise<Conversation | null> {
    const cacheKey = `conversation:${id}`;
    
    // å…ˆä»ç¼“å­˜è·å–
    let conversation = await this.cache.get<Conversation>(cacheKey);
    
    if (!conversation) {
      // ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®åº“æŸ¥è¯¢
      conversation = await this.db.findConversationById(id);
      
      if (conversation) {
        // å­˜å…¥ç¼“å­˜
        await this.cache.set(cacheKey, conversation, {
          l1Ttl: 300000,  // L1ç¼“å­˜5åˆ†é’Ÿ
          l2Ttl: 3600000, // L2ç¼“å­˜1å°æ—¶
          writeThrough: false // æ•°æ®å·²åœ¨æ•°æ®åº“ä¸­
        });
      }
    }
    
    return conversation;
  }
  
  async updateConversation(id: string, updates: Partial<Conversation>): Promise<void> {
    // æ›´æ–°æ•°æ®åº“
    await this.db.updateConversation(id, updates);
    
    // å¤±æ•ˆç›¸å…³ç¼“å­˜
    await this.cache.invalidatePattern(`conversation:${id}*`);
    await this.cache.invalidatePattern(`user:${updates.userId}:conversations*`);
  }
}
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–å®æˆ˜æ¡ˆä¾‹

### 1. æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

#### N+1æŸ¥è¯¢é—®é¢˜è§£å†³

```python
# é—®é¢˜ï¼šN+1æŸ¥è¯¢å¯¼è‡´æ€§èƒ½ç“¶é¢ˆ
# åŸå§‹ä»£ç ï¼ˆæœ‰é—®é¢˜ï¼‰
async def get_conversations_with_messages_bad(user_id: str):
    conversations = await db.fetch(
        "SELECT * FROM conversations WHERE user_id = $1", user_id
    )
    
    for conversation in conversations:
        # N+1é—®é¢˜ï¼šä¸ºæ¯ä¸ªå¯¹è¯å•ç‹¬æŸ¥è¯¢æ¶ˆæ¯
        messages = await db.fetch(
            "SELECT * FROM messages WHERE conversation_id = $1",
            conversation.id
        )
        conversation.messages = messages
    
    return conversations

# è§£å†³æ–¹æ¡ˆ1ï¼šæ‰¹é‡æŸ¥è¯¢
async def get_conversations_with_messages_optimized(user_id: str):
    conversations = await db.fetch(
        "SELECT * FROM conversations WHERE user_id = $1", user_id
    )
    
    if not conversations:
        return []
    
    # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰ç›¸å…³æ¶ˆæ¯
    conversation_ids = [c.id for c in conversations]
    messages = await db.fetch("""
        SELECT conversation_id, message_id, role, content, created_at
        FROM messages
        WHERE conversation_id = ANY($1)
        ORDER BY conversation_id, created_at
    """, conversation_ids)
    
    # æŒ‰conversation_idåˆ†ç»„
    messages_by_conv = {}
    for message in messages:
        conv_id = message['conversation_id']
        if conv_id not in messages_by_conv:
            messages_by_conv[conv_id] = []
        messages_by_conv[conv_id].append(message)
    
    # ç»„è£…ç»“æœ
    for conversation in conversations:
        conversation.messages = messages_by_conv.get(conversation.id, [])
    
    return conversations

# è§£å†³æ–¹æ¡ˆ2ï¼šä½¿ç”¨DataLoaderæ¨¡å¼
class MessageDataLoader:
    def __init__(self, db):
        self.db = db
        self.batch_load_fn = self._batch_load_messages
        self._batch_cache = {}
        self._batch_queue = []
        
    async def load(self, conversation_id: str) -> List[Message]:
        """åŠ è½½å•ä¸ªå¯¹è¯çš„æ¶ˆæ¯"""
        if conversation_id in self._batch_cache:
            return self._batch_cache[conversation_id]
        
        self._batch_queue.append(conversation_id)
        
        # æ‰¹é‡æ‰§è¡Œ
        if len(self._batch_queue) >= 10:  # æ‰¹é‡å¤§å°
            await self._execute_batch()
        
        return self._batch_cache.get(conversation_id, [])
    
    async def _batch_load_messages(self, conversation_ids: List[str]):
        """æ‰¹é‡åŠ è½½æ¶ˆæ¯"""
        messages = await self.db.fetch("""
            SELECT conversation_id, message_id, role, content, created_at
            FROM messages
            WHERE conversation_id = ANY($1)
            ORDER BY conversation_id, created_at
        """, conversation_ids)
        
        # åˆ†ç»„å¹¶ç¼“å­˜ç»“æœ
        for conv_id in conversation_ids:
            self._batch_cache[conv_id] = []
        
        for message in messages:
            conv_id = message['conversation_id']
            self._batch_cache[conv_id].append(message)

# è§£å†³æ–¹æ¡ˆ3ï¼šä½¿ç”¨JOINæŸ¥è¯¢ï¼ˆé€‚åˆå°æ•°æ®é‡ï¼‰
async def get_conversations_with_recent_message(user_id: str):
    return await db.fetch("""
        SELECT
            c.conversation_id,
            c.title,
            c.created_at as conversation_created_at,
            m.message_id,
            m.content as last_message,
            m.created_at as message_created_at
        FROM conversations c
        LEFT JOIN LATERAL (
            SELECT message_id, content, created_at
            FROM messages
            WHERE conversation_id = c.conversation_id
            ORDER BY created_at DESC
            LIMIT 1
        ) m ON true
        WHERE c.user_id = $1
        ORDER BY COALESCE(m.created_at, c.created_at) DESC
    """, user_id)
```

#### ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

```sql
-- 1. å¤åˆç´¢å¼•è®¾è®¡
-- å¯¹è¯æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_conversations_user_status_updated
ON conversations (user_id, status, updated_at DESC)
WHERE status IN ('active', 'archived');

-- æ¶ˆæ¯æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_messages_conversation_created
ON messages (conversation_id, created_at DESC)
INCLUDE (role, content);

-- 2. éƒ¨åˆ†ç´¢å¼•ä¼˜åŒ–
-- åªä¸ºæ´»è·ƒå¯¹è¯åˆ›å»ºç´¢å¼•
CREATE INDEX CONCURRENTLY idx_active_conversations
ON conversations (user_id, updated_at DESC)
WHERE status = 'active';

-- åªä¸ºç”¨æˆ·æ¶ˆæ¯åˆ›å»ºå…¨æ–‡ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_user_messages_fts
ON messages USING gin(to_tsvector('simple', content))
WHERE role = 'user';

-- 3. è¡¨è¾¾å¼ç´¢å¼•
-- æŒ‰æ—¥æœŸåˆ†åŒºæŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_messages_date_partition
ON messages ((created_at::date), conversation_id);

-- JSONå­—æ®µç´¢å¼•
CREATE INDEX CONCURRENTLY idx_conversation_metadata_tags
ON conversations USING gin((metadata->'tags'))
WHERE metadata ? 'tags';

-- 4. æŸ¥è¯¢æ€§èƒ½åˆ†æ
-- ä½¿ç”¨EXPLAIN ANALYZEåˆ†ææŸ¥è¯¢è®¡åˆ’
EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON)
SELECT c.*, m.content as last_message
FROM conversations c
LEFT JOIN LATERAL (
    SELECT content
    FROM messages
    WHERE conversation_id = c.conversation_id
    ORDER BY created_at DESC
    LIMIT 1
) m ON true
WHERE c.user_id = $1
ORDER BY c.updated_at DESC
LIMIT 20;
```

### 2. å†…å­˜ä½¿ç”¨ä¼˜åŒ–

#### å¤§æ•°æ®é›†å¤„ç†

```python
# é—®é¢˜ï¼šå¤§é‡æ•°æ®å¯¼è‡´å†…å­˜æº¢å‡º
# åŸå§‹ä»£ç ï¼ˆæœ‰é—®é¢˜ï¼‰
async def process_large_dataset_bad():
    # ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜
    all_documents = await db.fetch("SELECT * FROM documents")  # å¯èƒ½æœ‰å‡ ä¸‡æ¡è®°å½•
    
    processed_results = []
    for doc in all_documents:
        result = await process_document(doc)  # å†…å­˜å ç”¨æŒç»­å¢é•¿
        processed_results.append(result)
    
    return processed_results

# è§£å†³æ–¹æ¡ˆ1ï¼šæµå¼å¤„ç†
async def process_large_dataset_streaming():
    """ä½¿ç”¨å¼‚æ­¥ç”Ÿæˆå™¨æµå¼å¤„ç†å¤§æ•°æ®é›†"""
    
    async def document_stream():
        """æ–‡æ¡£æµç”Ÿæˆå™¨"""
        offset = 0
        batch_size = 1000
        
        while True:
            batch = await db.fetch(
                "SELECT * FROM documents ORDER BY id LIMIT $1 OFFSET $2",
                batch_size, offset
            )
            
            if not batch:
                break
                
            for doc in batch:
                yield doc
            
            offset += batch_size
    
    # æµå¼å¤„ç†
    processed_count = 0
    async for document in document_stream():
        result = await process_document(document)
        
        # æ‰¹é‡å†™å…¥ç»“æœ
        if processed_count % 100 == 0:
            await flush_results()
        
        processed_count += 1
        
        # å†…å­˜ç®¡ç†ï¼šå®šæœŸè§¦å‘åƒåœ¾å›æ”¶
        if processed_count % 1000 == 0:
            import gc
            gc.collect()
            logger.info(f"Processed {processed_count} documents")

# è§£å†³æ–¹æ¡ˆ2ï¼šå†…å­˜æ± ç®¡ç†
class DocumentProcessor:
    def __init__(self, pool_size: int = 1000):
        self.pool_size = pool_size
        self.processing_pool = []
        self.memory_threshold = 500 * 1024 * 1024  # 500MB
    
    async def process_batch(self, documents: List[Document]) -> List[ProcessResult]:
        results = []
        
        for i, doc in enumerate(documents):
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            if self._get_memory_usage() > self.memory_threshold:
                await self._force_gc()
            
            result = await self._process_single_document(doc)
            results.append(result)
            
            # æ‰¹é‡å¤„ç†å®Œæˆ
            if (i + 1) % self.pool_size == 0:
                await self._flush_intermediate_results(results)
                results.clear()  # é‡Šæ”¾å†…å­˜
        
        return results
    
    def _get_memory_usage(self) -> int:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡"""
        import psutil
        process = psutil.Process()
        return process.memory_info().rss
    
    async def _force_gc(self):
        """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        import gc
        gc.collect()
        await asyncio.sleep(0.1)  # è®©å‡ºCPUæ—¶é—´

# è§£å†³æ–¹æ¡ˆ3ï¼šå¯¹è±¡æ± æ¨¡å¼
class ObjectPool:
    """å¯¹è±¡æ± æ¨¡å¼å‡å°‘å†…å­˜åˆ†é…"""
    
    def __init__(self, factory, max_size: int = 100):
        self.factory = factory
        self.pool = []
        self.max_size = max_size
        self.in_use = set()
    
    def acquire(self):
        """è·å–å¯¹è±¡"""
        if self.pool:
            obj = self.pool.pop()
        else:
            obj = self.factory()
        
        self.in_use.add(id(obj))
        return obj
    
    def release(self, obj):
        """é‡Šæ”¾å¯¹è±¡"""
        obj_id = id(obj)
        if obj_id in self.in_use:
            self.in_use.remove(obj_id)
            
            # é‡ç½®å¯¹è±¡çŠ¶æ€
            if hasattr(obj, 'reset'):
                obj.reset()
            
            # æ·»åŠ å›æ± ä¸­
            if len(self.pool) < self.max_size:
                self.pool.append(obj)

# ä½¿ç”¨å¯¹è±¡æ± ä¼˜åŒ–æ–‡æ¡£å¤„ç†
class DocumentParserPool:
    def __init__(self):
        self.parser_pool = ObjectPool(
            factory=lambda: DocumentParser(),
            max_size=20
        )
    
    async def parse_document(self, file_content: bytes) -> Document:
        parser = self.parser_pool.acquire()
        try:
            result = await parser.parse(file_content)
            return result
        finally:
            self.parser_pool.release(parser)
```

### 3. å¹¶å‘å¤„ç†ä¼˜åŒ–

#### å¼‚æ­¥å¹¶å‘æ¨¡å¼

```python
# é«˜å¹¶å‘å¼‚æ­¥å¤„ç†æ¨¡å¼
import asyncio
from asyncio import Semaphore
from typing import AsyncGenerator, List, Callable

class ConcurrencyManager:
    """å¹¶å‘ç®¡ç†å™¨ - æ§åˆ¶å¹¶å‘æ•°é‡å’Œèµ„æºä½¿ç”¨"""
    
    def __init__(
        self,
        max_concurrent: int = 10,
        rate_limit: float = 100,  # æ¯ç§’è¯·æ±‚æ•°
        timeout: float = 30.0
    ):
        self.semaphore = Semaphore(max_concurrent)
        self.rate_limiter = RateLimiter(rate_limit)
        self.timeout = timeout
    
    async def process_concurrent(
        self,
        items: List[any],
        processor: Callable,
        batch_size: int = 50
    ) -> AsyncGenerator[any, None]:
        """å¹¶å‘å¤„ç†é¡¹ç›®åˆ—è¡¨"""
        
        # åˆ†æ‰¹å¤„ç†é¿å…åˆ›å»ºè¿‡å¤šåç¨‹
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            
            # å¹¶å‘å¤„ç†å½“å‰æ‰¹æ¬¡
            tasks = [
                self._process_single_item(item, processor)
                for item in batch
            ]
            
            # ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
            results = await asyncio.gather(
                *tasks,
                return_exceptions=True
            )
            
            # ç”Ÿæˆç»“æœ
            for result in results:
                if not isinstance(result, Exception):
                    yield result
                else:
                    logger.error(f"Processing failed: {result}")
    
    async def _process_single_item(self, item: any, processor: Callable):
        """å¤„ç†å•ä¸ªé¡¹ç›®"""
        async with self.semaphore:  # é™åˆ¶å¹¶å‘æ•°
            await self.rate_limiter.acquire()  # é™åˆ¶é€Ÿç‡
            
            try:
                return await asyncio.wait_for(
                    processor(item),
                    timeout=self.timeout
                )
            except asyncio.TimeoutError:
                raise Exception(f"Processing timeout for item: {item}")

class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    
    def __init__(self, rate: float):
        self.rate = rate
        self.tokens = rate
        self.last_update = asyncio.get_event_loop().time()
        self.lock = asyncio.Lock()
    
    async def acquire(self):
        """è·å–ä»¤ç‰Œ"""
        async with self.lock:
            now = asyncio.get_event_loop().time()
            
            # æ·»åŠ ä»¤ç‰Œ
            elapsed = now - self.last_update
            self.tokens = min(self.rate, self.tokens + elapsed * self.rate)
            self.last_update = now
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨ä»¤ç‰Œ
            if self.tokens < 1:
                sleep_time = (1 - self.tokens) / self.rate
                await asyncio.sleep(sleep_time)
                self.tokens = 0
            else:
                self.tokens -= 1

# å®é™…åº”ç”¨æ¡ˆä¾‹ï¼šæ‰¹é‡æ–‡æ¡£å¤„ç†
class BatchDocumentProcessor:
    def __init__(self):
        self.concurrency_manager = ConcurrencyManager(
            max_concurrent=5,    # æœ€å¤š5ä¸ªå¹¶å‘
            rate_limit=10,       # æ¯ç§’10ä¸ªè¯·æ±‚
            timeout=60.0         # 60ç§’è¶…æ—¶
        )
        self.embedding_service = EmbeddingService()
    
    async def process_documents(
        self,
        documents: List[Document]
    ) -> List[ProcessedDocument]:
        """æ‰¹é‡å¤„ç†æ–‡æ¡£"""
        
        results = []
        
        async for result in self.concurrency_manager.process_concurrent(
            items=documents,
            processor=self._process_single_document,
            batch_size=20
        ):
            results.append(result)
            
            # è¿›åº¦æŠ¥å‘Š
            if len(results) % 100 == 0:
                logger.info(f"Processed {len(results)}/{len(documents)} documents")
        
        return results
    
    async def _process_single_document(self, doc: Document) -> ProcessedDocument:
        """å¤„ç†å•ä¸ªæ–‡æ¡£"""
        try:
            # 1. æ–‡æœ¬æå–
            text = await self._extract_text(doc)
            
            # 2. æ–‡æœ¬åˆ†å—
            chunks = await self._chunk_text(text)
            
            # 3. ç”ŸæˆåµŒå…¥å‘é‡
            embeddings = await self.embedding_service.generate_embeddings(chunks)
            
            # 4. æ„å»ºç»“æœ
            return ProcessedDocument(
                document_id=doc.id,
                chunks=chunks,
                embeddings=embeddings,
                processed_at=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Document processing failed: {doc.id}, error: {e}")
            raise
    
    async def _extract_text(self, doc: Document) -> str:
        """æå–æ–‡æ¡£æ–‡æœ¬"""
        if doc.type == 'pdf':
            return await self._extract_pdf_text(doc.content)
        elif doc.type == 'docx':
            return await self._extract_docx_text(doc.content)
        else:
            return doc.content
    
    async def _chunk_text(self, text: str) -> List[str]:
        """æ–‡æœ¬åˆ†å—"""
        # ä½¿ç”¨å¼‚æ­¥å®ç°é¿å…é˜»å¡
        return await asyncio.get_event_loop().run_in_executor(
            None,  # ä½¿ç”¨é»˜è®¤çº¿ç¨‹æ± 
            self._sync_chunk_text,
            text
        )
    
    def _sync_chunk_text(self, text: str) -> List[str]:
        """åŒæ­¥æ–‡æœ¬åˆ†å—å®ç°"""
        chunk_size = 1000
        overlap = 200
        
        chunks = []
        for i in range(0, len(text), chunk_size - overlap):
            chunk = text[i:i + chunk_size]
            if chunk.strip():
                chunks.append(chunk)
        
        return chunks

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    processor = BatchDocumentProcessor()
    
    # æ¨¡æ‹Ÿå¤§é‡æ–‡æ¡£
    documents = [
        Document(id=f"doc_{i}", content=f"Document content {i}", type="txt")
        for i in range(1000)
    ]
    
    # æ‰¹é‡å¤„ç†
    start_time = time.time()
    processed_docs = await processor.process_documents(documents)
    duration = time.time() - start_time
    
    logger.info(f"Processed {len(processed_docs)} documents in {duration:.2f}s")

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ›¡ï¸ å®‰å…¨æœ€ä½³å®è·µ

### 1. è¾“å…¥éªŒè¯ä¸æ¸…ç†

```python
# è¾“å…¥éªŒè¯å’Œæ¸…ç†æ¡†æ¶
import re
import html
import bleach
from typing import Any, Dict, List
from pydantic import BaseModel, validator
from enum import Enum

class SecurityLevel(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    PARANOID = "paranoid"

class InputSanitizer:
    """è¾“å…¥æ¸…ç†å™¨"""
    
    # HTMLæ ‡ç­¾ç™½åå•
    ALLOWED_HTML_TAGS = [
        'p', 'br', 'strong', 'em', 'u', 'ol', 'ul', 'li',
        'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
        'blockquote', 'code', 'pre'
    ]
    
    # HTMLå±æ€§ç™½åå•
    ALLOWED_HTML_ATTRIBUTES = {
        'a': ['href', 'title'],
        'img': ['src', 'alt', 'title', 'width', 'height'],
        'code': ['class'],
        'pre': ['class']
    }
    
    @classmethod
    def sanitize_html(cls, content: str, level: SecurityLevel = SecurityLevel.MEDIUM) -> str:
        """æ¸…ç†HTMLå†…å®¹"""
        if level == SecurityLevel.PARANOID:
            # å®Œå…¨ç§»é™¤HTMLæ ‡ç­¾
            return bleach.clean(content, tags=[], strip=True)
        
        elif level == SecurityLevel.HIGH:
            # åªå…è®¸æœ€åŸºæœ¬çš„æ ‡ç­¾
            basic_tags = ['p', 'br', 'strong', 'em']
            return bleach.clean(content, tags=basic_tags, strip=True)
        
        elif level == SecurityLevel.MEDIUM:
            # å…è®¸å¸¸ç”¨çš„å®‰å…¨æ ‡ç­¾
            return bleach.clean(
                content,
                tags=cls.ALLOWED_HTML_TAGS,
                attributes=cls.ALLOWED_HTML_ATTRIBUTES,
                strip=True
            )
        
        else:  # LOW level
            # åŸºæœ¬æ¸…ç†ï¼Œä¿ç•™å¤§éƒ¨åˆ†æ ‡ç­¾
            return bleach.clean(content, strip=True)
    
    @classmethod
    def sanitize_sql_input(cls, value: str) -> str:
        """é˜²SQLæ³¨å…¥æ¸…ç†"""
        if not isinstance(value, str):
            return str(value)
        
        # ç§»é™¤æ½œåœ¨çš„SQLæ³¨å…¥å­—ç¬¦
        dangerous_patterns = [
            r"[';\"\\]",  # å¼•å·å’Œåæ–œæ 
            r"--",        # SQLæ³¨é‡Š
            r"/\*.*?\*/", # SQLå—æ³¨é‡Š
            r"\b(union|select|insert|delete|update|drop|create|alter)\b",  # SQLå…³é”®å­—
            r"[<>]",      # æ¯”è¾ƒæ“ä½œç¬¦
        ]
        
        cleaned = value
        for pattern in dangerous_patterns:
            cleaned = re.sub(pattern, "", cleaned, flags=re.IGNORECASE)
        
        return cleaned.strip()
    
    @classmethod
    def sanitize_xss_input(cls, value: str) -> str:
        """é˜²XSSæ”»å‡»æ¸…ç†"""
        if not isinstance(value, str):
            return str(value)
        
        # HTMLå®ä½“ç¼–ç 
        cleaned = html.escape(value)
        
        # ç§»é™¤JavaScriptåè®®
        cleaned = re.sub(r'javascript:', '', cleaned, flags=re.IGNORECASE)
        
        # ç§»é™¤äº‹ä»¶å¤„ç†å™¨
        cleaned = re.sub(r'on\w+\s*=', '', cleaned, flags=re.IGNORECASE)
        
        return cleaned

# åŸºäºPydanticçš„æ•°æ®éªŒè¯æ¨¡å‹
class SecureMessageInput(BaseModel):
    """å®‰å…¨çš„æ¶ˆæ¯è¾“å…¥æ¨¡å‹"""
    
    content: str
    conversation_id: str
    message_type: str = "text"
    
    @validator('content')
    def validate_content(cls, v):
        if not v or not v.strip():
            raise ValueError("æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # é•¿åº¦é™åˆ¶
        if len(v) > 10000:
            raise ValueError("æ¶ˆæ¯å†…å®¹è¿‡é•¿")
        
        # XSSé˜²æŠ¤
        cleaned_content = InputSanitizer.sanitize_xss_input(v)
        
        # å†…å®¹å®‰å…¨æ£€æŸ¥
        if cls._contains_malicious_content(cleaned_content):
            raise ValueError("æ¶ˆæ¯åŒ…å«ä¸å½“å†…å®¹")
        
        return cleaned_content
    
    @validator('conversation_id')
    def validate_conversation_id(cls, v):
        # UUIDæ ¼å¼éªŒè¯
        uuid_pattern = r'^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$'
        if not re.match(uuid_pattern, v, re.IGNORECASE):
            raise ValueError("å¯¹è¯IDæ ¼å¼æ— æ•ˆ")
        
        return v
    
    @staticmethod
    def _contains_malicious_content(content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æ¶æ„å†…å®¹"""
        malicious_patterns = [
            r'<script[^>]*>.*?</script>',  # Scriptæ ‡ç­¾
            r'javascript:',               # JavaScriptåè®®
            r'vbscript:',                # VBScriptåè®®
            r'data:text/html',           # Data URL
            r'<iframe[^>]*>',            # Iframeæ ‡ç­¾
            r'<object[^>]*>',            # Objectæ ‡ç­¾
            r'<embed[^>]*>',             # Embedæ ‡ç­¾
        ]
        
        for pattern in malicious_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return True
        
        return False

# APIå®‰å…¨è£…é¥°å™¨
from functools import wraps

def secure_endpoint(
    rate_limit: int = 100,  # æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶
    require_auth: bool = True,
    input_validation: Any = None,
    security_level: SecurityLevel = SecurityLevel.MEDIUM
):
    """å®‰å…¨ç«¯ç‚¹è£…é¥°å™¨"""
    
    def decorator(func):
        @wraps(func)
        async def wrapper(request, *args, **kwargs):
            # 1. é€Ÿç‡é™åˆ¶æ£€æŸ¥
            client_ip = request.client.host
            if not await check_rate_limit(client_ip, rate_limit):
                raise HTTPException(429, "è¯·æ±‚é¢‘ç‡è¶…å‡ºé™åˆ¶")
            
            # 2. è®¤è¯æ£€æŸ¥
            if require_auth:
                user = await authenticate_request(request)
                if not user:
                    raise HTTPException(401, "è®¤è¯å¤±è´¥")
                kwargs['current_user'] = user
            
            # 3. è¾“å…¥éªŒè¯
            if input_validation:
                try:
                    validated_data = input_validation(**request.json())
                    kwargs['validated_data'] = validated_data
                except ValidationError as e:
                    raise HTTPException(400, f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
            
            # 4. å®‰å…¨å¤´è®¾ç½®
            response = await func(request, *args, **kwargs)
            
            # æ·»åŠ å®‰å…¨å“åº”å¤´
            if hasattr(response, 'headers'):
                response.headers.update({
                    'X-Content-Type-Options': 'nosniff',
                    'X-Frame-Options': 'DENY',
                    'X-XSS-Protection': '1; mode=block',
                    'Strict-Transport-Security': 'max-age=31536000; includeSubDomains',
                    'Content-Security-Policy': "default-src 'self'"
                })
            
            return response
        
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@secure_endpoint(
    rate_limit=50,
    require_auth=True,
    input_validation=SecureMessageInput,
    security_level=SecurityLevel.HIGH
)
async def send_message(request, current_user, validated_data):
    """å‘é€æ¶ˆæ¯çš„å®‰å…¨ç«¯ç‚¹"""
    
    # æƒé™æ£€æŸ¥
    if not can_send_message(current_user, validated_data.conversation_id):
        raise HTTPException(403, "æ— æƒé™è®¿é—®è¯¥å¯¹è¯")
    
    # å†…å®¹è¿‡æ»¤
    filtered_content = await content_filter.filter(validated_data.content)
    
    # ä¿å­˜æ¶ˆæ¯
    message = await create_message(
        user_id=current_user.id,
        conversation_id=validated_data.conversation_id,
        content=filtered_content,
        type=validated_data.message_type
    )
    
    return {"message": "æ¶ˆæ¯å‘é€æˆåŠŸ", "message_id": message.id}
```

### 2. æ•°æ®åŠ å¯†ä¸è„±æ•

```python
# æ•°æ®åŠ å¯†å’Œè„±æ•å·¥å…·
import hashlib
import hmac
import secrets
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from cryptography.hazmat.primitives.asymmetric import rsa, padding
import base64
import re

class DataEncryption:
    """æ•°æ®åŠ å¯†å·¥å…·ç±»"""
    
    def __init__(self, master_key: str):
        self.master_key = master_key.encode()
        self._fernet_cache = {}
    
    def _get_fernet(self, salt: bytes = None) -> Fernet:
        """è·å–FernetåŠ å¯†å®ä¾‹"""
        if salt is None:
            salt = b'default_salt_1234567890123456'  # 32å­—èŠ‚ç›å€¼
        
        cache_key = base64.b64encode(salt).decode()
        
        if cache_key not in self._fernet_cache:
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32,
                salt=salt,
                iterations=100000,
            )
            key = base64.urlsafe_b64encode(kdf.derive(self.master_key))
            self._fernet_cache[cache_key] = Fernet(key)
        
        return self._fernet_cache[cache_key]
    
    def encrypt_sensitive_data(self, data: str, user_salt: str = None) -> str:
        """åŠ å¯†æ•æ„Ÿæ•°æ®"""
        if not data:
            return ""
        
        # ä½¿ç”¨ç”¨æˆ·ç›¸å…³çš„ç›å€¼
        salt = user_salt.encode() if user_salt else secrets.token_bytes(16)
        fernet = self._get_fernet(salt)
        
        encrypted = fernet.encrypt(data.encode())
        
        # è¿”å› salt + encrypted_data çš„base64ç¼–ç 
        return base64.b64encode(salt + encrypted).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """è§£å¯†æ•æ„Ÿæ•°æ®"""
        if not encrypted_data:
            return ""
        
        try:
            # è§£ç base64
            data = base64.b64decode(encrypted_data.encode())
            
            # åˆ†ç¦»ç›å€¼å’ŒåŠ å¯†æ•°æ®
            salt = data[:16]  # å‰16å­—èŠ‚ä¸ºç›å€¼
            encrypted = data[16:]
            
            fernet = self._get_fernet(salt)
            decrypted = fernet.decrypt(encrypted)
            
            return decrypted.decode()
        
        except Exception as e:
            logger.error(f"Decryption failed: {e}")
            return ""

class DataMasking:
    """æ•°æ®è„±æ•å·¥å…·ç±»"""
    
    @staticmethod
    def mask_email(email: str) -> str:
        """é‚®ç®±è„±æ•"""
        if not email or '@' not in email:
            return email
        
        local, domain = email.split('@', 1)
        
        if len(local) <= 2:
            masked_local = '*' * len(local)
        else:
            masked_local = local[0] + '*' * (len(local) - 2) + local[-1]
        
        return f"{masked_local}@{domain}"
    
    @staticmethod
    def mask_phone(phone: str) -> str:
        """æ‰‹æœºå·è„±æ•"""
        if not phone:
            return phone
        
        # ç§»é™¤éæ•°å­—å­—ç¬¦
        digits = re.sub(r'\D', '', phone)
        
        if len(digits) >= 11:
            return digits[:3] + '*' * (len(digits) - 7) + digits[-4:]
        elif len(digits) >= 7:
            return digits[:3] + '*' * (len(digits) - 6) + digits[-3:]
        else:
            return '*' * len(digits)
    
    @staticmethod
    def mask_id_card(id_card: str) -> str:
        """èº«ä»½è¯å·è„±æ•"""
        if not id_card:
            return id_card
        
        if len(id_card) == 18:
            return id_card[:6] + '*' * 8 + id_card[-4:]
        elif len(id_card) == 15:
            return id_card[:6] + '*' * 6 + id_card[-3:]
        else:
            return '*' * len(id_card)
    
    @staticmethod
    def mask_content(content: str, preserve_length: int = 50) -> str:
        """å†…å®¹è„±æ•"""
        if not content:
            return content
        
        if len(content) <= preserve_length:
            return content
        
        return content[:preserve_length] + f"... (å…±{len(content)}å­—ç¬¦)"
    
    @classmethod
    def mask_user_data(cls, user_data: dict) -> dict:
        """ç”¨æˆ·æ•°æ®è„±æ•"""
        masked_data = user_data.copy()
        
        # å®šä¹‰è„±æ•è§„åˆ™
        masking_rules = {
            'email': cls.mask_email,
            'phone': cls.mask_phone,
            'mobile': cls.mask_phone,
            'id_card': cls.mask_id_card,
            'identity_card': cls.mask_id_card,
            'content': lambda x: cls.mask_content(x, 100),
            'message': lambda x: cls.mask_content(x, 200),
        }
        
        for field, masking_func in masking_rules.items():
            if field in masked_data and masked_data[field]:
                masked_data[field] = masking_func(masked_data[field])
        
        return masked_data

# æ•æ„Ÿæ•°æ®æ¨¡å‹
class SensitiveDataModel(BaseModel):
    """æ•æ„Ÿæ•°æ®æ¨¡å‹"""
    
    def __init__(self, **data):
        # è‡ªåŠ¨åŠ å¯†æ•æ„Ÿå­—æ®µ
        encryption = DataEncryption(os.getenv('ENCRYPTION_KEY', 'default_key'))
        
        sensitive_fields = getattr(self, 'SENSITIVE_FIELDS', [])
        
        for field in sensitive_fields:
            if field in data and data[field]:
                data[field] = encryption.encrypt_sensitive_data(
                    str(data[field]),
                    user_salt=data.get('user_id', '')
                )
        
        super().__init__(**data)
    
    def decrypt_sensitive_fields(self):
        """è§£å¯†æ•æ„Ÿå­—æ®µ"""
        encryption = DataEncryption(os.getenv('ENCRYPTION_KEY', 'default_key'))
        
        sensitive_fields = getattr(self, 'SENSITIVE_FIELDS', [])
        
        for field in sensitive_fields:
            if hasattr(self, field) and getattr(self, field):
                decrypted = encryption.decrypt_sensitive_data(getattr(self, field))
                setattr(self, field, decrypted)
    
    def to_masked_dict(self) -> dict:
        """è¿”å›è„±æ•åçš„å­—å…¸"""
        data = self.dict()
        return DataMasking.mask_user_data(data)

# ä½¿ç”¨ç¤ºä¾‹
class UserProfile(SensitiveDataModel):
    SENSITIVE_FIELDS = ['email', 'phone', 'real_name']
    
    user_id: str
    username: str
    email: str
    phone: str
    real_name: str
    created_at: datetime

# ä½¿ç”¨ç¤ºä¾‹
user = UserProfile(
    user_id="123456",
    username="testuser",
    email="user@example.com",
    phone="13800138000",
    real_name="å¼ ä¸‰",
    created_at=datetime.now()
)

# è·å–è„±æ•æ•°æ®ç”¨äºæ—¥å¿—
masked_data = user.to_masked_dict()
logger.info(f"User profile: {masked_data}")

# è§£å¯†æ•æ„Ÿæ•°æ®ç”¨äºä¸šåŠ¡é€»è¾‘
user.decrypt_sensitive_fields()
send_email(user.email, "Welcome!")
```

## ğŸ“± å®é™…åº”ç”¨æ¡ˆä¾‹

### 1. å®¢æœç³»ç»Ÿé›†æˆ

```typescript
/**

 * å®¢æœç³»ç»Ÿé›†æˆæ¡ˆä¾‹
 * æ¼”ç¤ºVoiceHelperå¦‚ä½•é›†æˆåˆ°ç°æœ‰å®¢æœç³»ç»Ÿä¸­

 */

interface CustomerServiceConfig {
  // å·¥ä½œæ—¶é—´é…ç½®
  workingHours: {
    start: string;
    end: string;
    timezone: string;
    workdays: number[];
  };
  
  // è‡ªåŠ¨å›å¤é…ç½®
  autoReply: {
    enabled: boolean;
    greeting: string;
    fallback: string;
    transferMessage: string;
  };
  
  // äººå·¥å®¢æœé…ç½®
  humanAgent: {
    maxWaitTime: number;
    transferKeywords: string[];
    escalationConditions: string[];
  };
}

class CustomerServiceBot {
  private voiceHelper: VoiceHelperClient;
  private knowledgeBase: KnowledgeBaseService;
  private ticketSystem: TicketingService;
  
  constructor(
    private config: CustomerServiceConfig,
    private agentPool: AgentPool
  ) {
    this.voiceHelper = new VoiceHelperClient({
      baseURL: process.env.VOICEHELPER_API_URL,
      apiKey: process.env.VOICEHELPER_API_KEY
    });
  }
  
  async handleCustomerInquiry(inquiry: CustomerInquiry): Promise<ServiceResponse> {
    const conversation = await this.initializeConversation(inquiry);
    
    try {
      // 1. æ„å›¾è¯†åˆ«å’Œåˆ†ç±»
      const intent = await this.classifyInquiry(inquiry.message);
      
      // 2. æ ¹æ®æ„å›¾é€‰æ‹©å¤„ç†ç­–ç•¥
      switch (intent.category) {
        case 'faq':
          return await this.handleFAQ(conversation, inquiry);
        
        case 'technical_support':
          return await this.handleTechnicalSupport(conversation, inquiry);
        
        case 'billing':
          return await this.handleBillingInquiry(conversation, inquiry);
        
        case 'complaint':
          return await this.escalateToHuman(conversation, inquiry);
        
        default:
          return await this.handleGeneralInquiry(conversation, inquiry);
      }
      
    } catch (error) {
      logger.error('Customer service error:', error);
      return await this.handleServiceError(conversation, error);
    }
  }
  
  private async handleFAQ(
    conversation: Conversation,
    inquiry: CustomerInquiry
  ): Promise<ServiceResponse> {
    
    // ä½¿ç”¨VoiceHelperè¿›è¡ŒFAQæ£€ç´¢
    const response = await this.voiceHelper.chat({
      message: inquiry.message,
      conversation_id: conversation.id,
      retrieval_config: {
        mode: 'hybrid',
        top_k: 5,
        collection: 'customer_service_faq'
      }
    });
    
    // è§£ææµå¼å“åº”
    let botResponse = '';
    let references: Reference[] = [];
    
    for await (const chunk of response.stream()) {
      if (chunk.type === 'generation_chunk') {
        botResponse += chunk.data.text;
      } else if (chunk.type === 'retrieval_result') {
        references = chunk.data.results;
      }
    }
    
    // æ·»åŠ äººå·¥å®¢æœé€‰é¡¹
    const hasHumanOption = this.shouldOfferHumanAgent(inquiry, botResponse);
    
    return {
      type: 'bot_response',
      message: botResponse,
      references,
      actions: hasHumanOption ? [{
        type: 'transfer_to_human',
        label: 'è½¬äººå·¥å®¢æœ',
        data: { reason: 'user_request' }
      }] : [],
      satisfaction_survey: true
    };
  }
  
  private async handleTechnicalSupport(
    conversation: Conversation,
    inquiry: CustomerInquiry
  ): Promise<ServiceResponse> {
    
    // æ£€æŸ¥æ˜¯å¦éœ€è¦æ”¶é›†ç³»ç»Ÿä¿¡æ¯
    const needsSystemInfo = await this.requiresSystemInfo(inquiry.message);
    
    if (needsSystemInfo && !inquiry.systemInfo) {
      return {
        type: 'system_info_request',
        message: 'ä¸ºäº†æ›´å¥½åœ°å¸®åŠ©æ‚¨è§£å†³é—®é¢˜ï¼Œè¯·æä¾›ä»¥ä¸‹ç³»ç»Ÿä¿¡æ¯ï¼š',
        form: {
          fields: [
            { name: 'os', label: 'æ“ä½œç³»ç»Ÿ', type: 'select', required: true },
            { name: 'browser', label: 'æµè§ˆå™¨ç‰ˆæœ¬', type: 'text', required: true },
            { name: 'error_message', label: 'é”™è¯¯ä¿¡æ¯', type: 'textarea', required: false }
          ]
        }
      };
    }
    
    // ç»“åˆç³»ç»Ÿä¿¡æ¯è¿›è¡Œæ™ºèƒ½è¯Šæ–­
    const diagnosticPrompt = this.buildDiagnosticPrompt(inquiry);
    
    const response = await this.voiceHelper.chat({
      message: diagnosticPrompt,
      conversation_id: conversation.id,
      retrieval_config: {
        mode: 'graph',
        top_k: 3,
        collection: 'technical_documentation'
      }
    });
    
    let solution = '';
    for await (const chunk of response.stream()) {
      if (chunk.type === 'generation_chunk') {
        solution += chunk.data.text;
      }
    }
    
    // åˆ›å»ºå·¥å•ï¼ˆå¦‚æœé—®é¢˜å¤æ‚ï¼‰
    if (this.isComplexIssue(inquiry, solution)) {
      const ticket = await this.ticketSystem.createTicket({
        customer_id: inquiry.customer_id,
        category: 'technical_support',
        priority: this.calculatePriority(inquiry),
        description: inquiry.message,
        conversation_id: conversation.id,
        initial_analysis: solution
      });
      
      solution += `\n\nå·¥å•å·²åˆ›å»ºï¼š${ticket.id}ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯å›¢é˜Ÿä¼šåœ¨24å°æ—¶å†…è·Ÿè¿›ã€‚`;
    }
    
    return {
      type: 'technical_solution',
      message: solution,
      actions: [
        { type: 'mark_resolved', label: 'é—®é¢˜å·²è§£å†³' },
        { type: 'escalate', label: 'éœ€è¦æ›´å¤šå¸®åŠ©' }
      ]
    };
  }
  
  private async escalateToHuman(
    conversation: Conversation,
    inquiry: CustomerInquiry
  ): Promise<ServiceResponse> {
    
    // æ£€æŸ¥äººå·¥å®¢æœå¯ç”¨æ€§
    const agent = await this.agentPool.findAvailableAgent({
      skills: ['complaint_handling'],
      language: inquiry.language,
      priority: 'high'
    });
    
    if (agent) {
      // ç«‹å³è½¬æ¥
      await this.transferToAgent(conversation, agent, {
        reason: 'complaint',
        priority: 'high',
        context: {
          customer_emotion: 'frustrated',
          issue_category: 'complaint'
        }
      });
      
      return {
        type: 'transfer_initiated',
        message: `æ‚¨çš„é—®é¢˜å·²è½¬æ¥ç»™ä¸“ä¸šå®¢æœ ${agent.name}ï¼Œè¯·ç¨ç­‰...`,
        estimated_wait_time: 0
      };
      
    } else {
      // æ’é˜Ÿç­‰å¾…
      const queuePosition = await this.agentPool.addToQueue(conversation, {
        priority: 'high',
        skills_required: ['complaint_handling']
      });
      
      return {
        type: 'queued_for_agent',
        message: 'å½“å‰æ‰€æœ‰å®¢æœéƒ½å¿™ç¢Œä¸­ï¼Œæ‚¨åœ¨é˜Ÿåˆ—ä¸­çš„ä½ç½®æ˜¯ç¬¬ ${queuePosition} ä½ã€‚',
        estimated_wait_time: queuePosition * 3 * 60, // ä¼°ç®—ç­‰å¾…æ—¶é—´
        actions: [
          { type: 'leave_message', label: 'ç•™è¨€' },
          { type: 'callback_request', label: 'ç”³è¯·å›ç”µ' }
        ]
      };
    }
  }
  
  // æ™ºèƒ½è´¨é‡ç›‘æ§
  async monitorConversationQuality(conversation: Conversation): Promise<QualityReport> {
    const messages = await this.getConversationMessages(conversation.id);
    
    // æƒ…æ„Ÿåˆ†æ
    const sentimentAnalysis = await this.analyzeSentiment(messages);
    
    // è§£å†³ç‡ç»Ÿè®¡
    const resolutionStatus = await this.checkResolutionStatus(conversation);
    
    // å®¢æˆ·æ»¡æ„åº¦é¢„æµ‹
    const satisfactionPrediction = await this.predictSatisfaction(messages);
    
    return {
      conversation_id: conversation.id,
      quality_score: this.calculateQualityScore(sentimentAnalysis, resolutionStatus),
      sentiment_trend: sentimentAnalysis.trend,
      resolution_status: resolutionStatus,
      predicted_satisfaction: satisfactionPrediction,
      recommendations: this.generateImprovementRecommendations(
        sentimentAnalysis,
        resolutionStatus,
        satisfactionPrediction
      )
    };
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const customerServiceBot = new CustomerServiceBot(
  {
    workingHours: {
      start: '09:00',
      end: '18:00',
      timezone: 'Asia/Shanghai',
      workdays: [1, 2, 3, 4, 5]
    },
    autoReply: {
      enabled: true,
      greeting: 'æ‚¨å¥½ï¼æˆ‘æ˜¯AIå®¢æœåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ',
      fallback: 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å®Œå…¨ç†è§£æ‚¨çš„é—®é¢˜ï¼Œæ­£åœ¨ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœ...',
      transferMessage: 'æ­£åœ¨ä¸ºæ‚¨è½¬æ¥äººå·¥å®¢æœï¼Œè¯·ç¨å€™...'
    },
    humanAgent: {
      maxWaitTime: 10 * 60, // 10åˆ†é’Ÿ
      transferKeywords: ['è½¬äººå·¥', 'æŠ•è¯‰', 'é€€æ¬¾'],
      escalationConditions: ['æƒ…ç»ªè´Ÿé¢', 'å¤æ‚é—®é¢˜', 'å¤šæ¬¡æœªè§£å†³']
    }
  },
  new AgentPool()
);

// APIé›†æˆ
app.post('/api/customer-service/chat', async (req, res) => {
  try {
    const inquiry: CustomerInquiry = req.body;
    const response = await customerServiceBot.handleCustomerInquiry(inquiry);
    
    res.json({
      success: true,
      data: response
    });
    
  } catch (error) {
    logger.error('Customer service API error:', error);
    res.status(500).json({
      success: false,
      error: 'Service temporarily unavailable'
    });
  }
});
```

### 2. æ•™è‚²åŸ¹è®­åº”ç”¨

```python
# æ•™è‚²åŸ¹è®­åº”ç”¨æ¡ˆä¾‹
# æ¼”ç¤ºVoiceHelperåœ¨åœ¨çº¿æ•™è‚²åœºæ™¯ä¸­çš„åº”ç”¨

class EducationAssistant:
    """æ•™è‚²åŠ©æ‰‹ç³»ç»Ÿ"""
    
    def __init__(self, course_id: str, voicehelper_client):
        self.course_id = course_id
        self.voicehelper = voicehelper_client
        self.knowledge_base = CourseKnowledgeBase(course_id)
        self.learning_tracker = LearningProgressTracker()
        self.assessment_engine = AssessmentEngine()
    
    async def handle_student_question(
        self,
        student_id: str,
        question: str,
        context: dict = None
    ) -> EducationResponse:
        """å¤„ç†å­¦ç”Ÿæé—®"""
        
        # 1. åˆ†æé—®é¢˜ç±»å‹
        question_type = await self.classify_question(question)
        
        # 2. è·å–å­¦ç”Ÿå­¦ä¹ è¿›åº¦
        progress = await self.learning_tracker.get_progress(student_id, self.course_id)
        
        # 3. æ„å»ºä¸ªæ€§åŒ–æŸ¥è¯¢ä¸Šä¸‹æ–‡
        enhanced_query = self.build_educational_context(
            question=question,
            student_progress=progress,
            question_type=question_type,
            context=context
        )
        
        # 4. è°ƒç”¨VoiceHelperè¿›è¡Œæ™ºèƒ½é—®ç­”
        response = await self.voicehelper.chat({
            'message': enhanced_query,
            'conversation_id': f"edu_{student_id}_{self.course_id}",
            'retrieval_config': {
                'mode': 'hybrid',
                'top_k': 5,
                'collection': f'course_{self.course_id}'
            },
            'context': {
                'user_type': 'student',
                'course_level': progress.current_level,
                'learning_style': progress.preferred_style
            }
        })
        
        # 5. è§£æå“åº”å¹¶å¢å¼ºæ•™è‚²åŠŸèƒ½
        educational_response = await self.enhance_educational_response(
            response, question_type, student_id
        )
        
        # 6. è®°å½•å­¦ä¹ äº’åŠ¨
        await self.learning_tracker.record_interaction(
            student_id=student_id,
            question=question,
            response=educational_response,
            question_type=question_type
        )
        
        return educational_response
    
    async def classify_question(self, question: str) -> QuestionType:
        """åˆ†ç±»å­¦ç”Ÿé—®é¢˜"""
        
        # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé—®é¢˜åˆ†ç±»
        classification_prompt = f"""
        åˆ†æä»¥ä¸‹å­¦ç”Ÿé—®é¢˜çš„ç±»å‹ï¼š
        
        é—®é¢˜: {question}
        
        è¯·ä»ä»¥ä¸‹ç±»å‹ä¸­é€‰æ‹©æœ€åˆé€‚çš„ï¼š

        1. concept_explanation - æ¦‚å¿µè§£é‡Š
        2. problem_solving - è§£é¢˜æ±‚åŠ©
        3. example_request - è¦æ±‚ç¤ºä¾‹
        4. clarification - æ¾„æ¸…ç–‘é—®
        5. application - åº”ç”¨åœºæ™¯
        6. assessment - è‡ªæˆ‘è¯„ä¼°
        
        åªè¿”å›ç±»å‹ä»£ç ã€‚
        """
        
        # è°ƒç”¨åˆ†ç±»æœåŠ¡
        result = await self.voicehelper.classify(classification_prompt)
        
        return QuestionType(result.strip())
    
    def build_educational_context(
        self,
        question: str,
        student_progress: StudentProgress,
        question_type: QuestionType,
        context: dict = None
    ) -> str:
        """æ„å»ºæ•™è‚²ä¸Šä¸‹æ–‡å¢å¼ºæŸ¥è¯¢"""
        
        context_parts = [
            f"å­¦ç”Ÿé—®é¢˜: {question}",
            f"å½“å‰å­¦ä¹ é˜¶æ®µ: {student_progress.current_level}",
            f"å·²å­¦ä¹ ç« èŠ‚: {', '.join(student_progress.completed_chapters)}",
            f"å­¦ä¹ åå¥½: {student_progress.preferred_style}",
            f"é—®é¢˜ç±»å‹: {question_type.value}"
        ]
        
        # æ ¹æ®é—®é¢˜ç±»å‹æ·»åŠ ç‰¹å®šæŒ‡å¯¼
        if question_type == QuestionType.CONCEPT_EXPLANATION:
            context_parts.append(
                "è¯·æä¾›æ¸…æ™°çš„æ¦‚å¿µè§£é‡Šï¼ŒåŒ…å«å®šä¹‰ã€ç‰¹å¾ã€å®ä¾‹ï¼Œé€‚åˆå½“å‰å­¦ä¹ æ°´å¹³ã€‚"
            )
        elif question_type == QuestionType.PROBLEM_SOLVING:
            context_parts.append(
                "è¯·æä¾›è§£é¢˜æ€è·¯å’Œæ­¥éª¤ï¼Œè€Œéç›´æ¥ç­”æ¡ˆï¼Œå¼•å¯¼å­¦ç”Ÿæ€è€ƒã€‚"
            )
        elif question_type == QuestionType.EXAMPLE_REQUEST:
            context_parts.append(
                "è¯·æä¾›ç›¸å…³çš„å®é™…ä¾‹å­ï¼Œæœ€å¥½ç»“åˆå­¦ç”Ÿçš„ç”Ÿæ´»ç»éªŒã€‚"
            )
        
        # æ·»åŠ ä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®
        if student_progress.weak_areas:
            context_parts.append(
                f"æ³¨æ„å­¦ç”Ÿåœ¨ä»¥ä¸‹æ–¹é¢è¾ƒå¼±ï¼Œéœ€è¦é¢å¤–å…³æ³¨: {', '.join(student_progress.weak_areas)}"
            )
        
        return "\n".join(context_parts)
    
    async def enhance_educational_response(
        self,
        base_response: VoiceHelperResponse,
        question_type: QuestionType,
        student_id: str
    ) -> EducationResponse:
        """å¢å¼ºæ•™è‚²å“åº”åŠŸèƒ½"""
        
        # è§£æåŸºç¡€å“åº”
        answer = ""
        references = []
        
        async for chunk in base_response.stream():
            if chunk.type == 'generation_chunk':
                answer += chunk.data.text
            elif chunk.type == 'retrieval_result':
                references = chunk.data.results
        
        # ç”Ÿæˆç›¸å…³ç»ƒä¹ é¢˜
        related_exercises = []
        if question_type in [QuestionType.CONCEPT_EXPLANATION, QuestionType.PROBLEM_SOLVING]:
            related_exercises = await self.generate_practice_questions(
                topic=self.extract_topic_from_question(base_response.original_question),
                difficulty=await self.get_student_level(student_id)
            )
        
        # æ¨èå­¦ä¹ èµ„æº
        recommended_resources = await self.recommend_learning_resources(
            student_id=student_id,
            current_topic=self.extract_topic_from_question(base_response.original_question),
            question_type=question_type
        )
        
        # ç”Ÿæˆå­¦ä¹ è·¯å¾„å»ºè®®
        learning_path = await self.suggest_learning_path(
            student_id=student_id,
            current_understanding=self.assess_understanding_from_question(
                base_response.original_question
            )
        )
        
        return EducationResponse(
            answer=answer,
            references=references,
            related_exercises=related_exercises,
            recommended_resources=recommended_resources,
            learning_path_suggestions=learning_path,
            interactive_elements=self.create_interactive_elements(question_type),
            assessment_opportunities=await self.suggest_assessment(student_id, question_type)
        )
    
    async def generate_practice_questions(
        self,
        topic: str,
        difficulty: str
    ) -> List[PracticeQuestion]:
        """ç”Ÿæˆç›¸å…³ç»ƒä¹ é¢˜"""
        
        generation_prompt = f"""
        åŸºäºä¸»é¢˜"{topic}"ï¼Œç”Ÿæˆ3ä¸ª{difficulty}éš¾åº¦çš„ç»ƒä¹ é¢˜ã€‚
        
        è¦æ±‚ï¼š
        1. é¢˜ç›®åº”è¯¥å¾ªåºæ¸è¿›
        2. åŒ…å«ä¸åŒé¢˜å‹ï¼ˆé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€ç®€ç­”é¢˜ï¼‰
        3. æ¯é¢˜æä¾›è¯¦ç»†çš„è§£é¢˜æ€è·¯
        4. æ ‡æ˜çŸ¥è¯†ç‚¹å’Œéš¾åº¦çº§åˆ«
        
        è¿”å›JSONæ ¼å¼ã€‚
        """
        
        response = await self.voicehelper.generate(generation_prompt)
        
        try:
            questions_data = json.loads(response)
            return [PracticeQuestion(**q) for q in questions_data.get('questions', [])]
        except (json.JSONDecodeError, ValidationError):
            logger.warning("Failed to generate practice questions")
            return []
    
    async def adaptive_tutoring_session(
        self,
        student_id: str,
        topic: str,
        duration_minutes: int = 30
    ) -> TutoringSession:
        """è‡ªé€‚åº”è¾…å¯¼ä¼šè¯"""
        
        session = TutoringSession(
            student_id=student_id,
            topic=topic,
            start_time=datetime.now(),
            target_duration=duration_minutes
        )
        
        # åˆå§‹è¯„ä¼°
        initial_assessment = await self.assessment_engine.quick_assessment(
            student_id, topic
        )
        
        session.initial_level = initial_assessment.level
        
        # ç”Ÿæˆä¸ªæ€§åŒ–å­¦ä¹ è®¡åˆ’
        learning_plan = await self.create_adaptive_plan(
            topic=topic,
            current_level=initial_assessment.level,
            time_available=duration_minutes,
            learning_style=await self.get_learning_style(student_id)
        )
        
        session.learning_activities = []
        
        # æ‰§è¡Œå­¦ä¹ æ´»åŠ¨
        for activity in learning_plan.activities:
            activity_result = await self.execute_learning_activity(
                student_id=student_id,
                activity=activity,
                session_context=session
            )
            
            session.learning_activities.append(activity_result)
            
            # åŠ¨æ€è°ƒæ•´åç»­æ´»åŠ¨
            if activity_result.performance_score < 0.7:
                # å­¦ä¹ æ•ˆæœä¸å¥½ï¼Œè°ƒæ•´éš¾åº¦
                learning_plan = await self.adjust_learning_plan(
                    learning_plan,
                    performance_feedback=activity_result
                )
            
            # æ£€æŸ¥æ—¶é—´é™åˆ¶
            if session.elapsed_minutes() >= duration_minutes:
                break
        
        # ä¼šè¯æ€»ç»“å’Œå»ºè®®
        session.summary = await self.generate_session_summary(session)
        session.next_steps = await self.recommend_next_steps(student_id, session)
        
        # æ›´æ–°å­¦ä¹ è¿›åº¦
        await self.learning_tracker.update_progress(
            student_id=student_id,
            topic=topic,
            session_results=session
        )
        
        return session
    
    async def execute_learning_activity(
        self,
        student_id: str,
        activity: LearningActivity,
        session_context: TutoringSession
    ) -> ActivityResult:
        """æ‰§è¡Œå­¦ä¹ æ´»åŠ¨"""
        
        result = ActivityResult(
            activity_type=activity.type,
            start_time=datetime.now()
        )
        
        try:
            if activity.type == ActivityType.EXPLANATION:
                result = await self.deliver_explanation(
                    student_id, activity.content, session_context
                )
            
            elif activity.type == ActivityType.PRACTICE:
                result = await self.conduct_practice_session(
                    student_id, activity.questions, session_context
                )
            
            elif activity.type == ActivityType.DISCUSSION:
                result = await self.facilitate_discussion(
                    student_id, activity.discussion_topics, session_context
                )
            
            elif activity.type == ActivityType.ASSESSMENT:
                result = await self.conduct_mini_assessment(
                    student_id, activity.assessment_items, session_context
                )
            
        except Exception as e:
            logger.error(f"Activity execution failed: {e}")
            result.success = False
            result.error_message = str(e)
        
        finally:
            result.end_time = datetime.now()
            result.duration_minutes = (result.end_time - result.start_time).seconds // 60
        
        return result

# ä½¿ç”¨ç¤ºä¾‹ï¼šæ•°å­¦è¾…å¯¼ç³»ç»Ÿ
class MathTutoringSystem(EducationAssistant):
    """æ•°å­¦è¾…å¯¼ç³»ç»Ÿ"""
    
    def __init__(self, grade_level: str):
        super().__init__(f"math_grade_{grade_level}", VoiceHelperClient())
        self.grade_level = grade_level
        self.problem_solver = MathProblemSolver()
    
    async def solve_math_problem(
        self,
        student_id: str,
        problem: str,
        show_steps: bool = True
    ) -> MathSolutionResponse:
        """æ•°å­¦é—®é¢˜æ±‚è§£"""
        
        # åˆ†æé—®é¢˜ç±»å‹
        problem_type = await self.analyze_math_problem(problem)
        
        # è·å–è§£é¢˜æ€è·¯
        solution_prompt = f"""
        æ•°å­¦é—®é¢˜: {problem}
        é—®é¢˜ç±»å‹: {problem_type}
        å­¦ç”Ÿå¹´çº§: {self.grade_level}
        
        è¯·æä¾›:

        1. è§£é¢˜æ€è·¯å’Œæ­¥éª¤ï¼ˆä¸è¦ç›´æ¥ç»™ç­”æ¡ˆï¼‰
        2. ç›¸å…³æ¦‚å¿µè§£é‡Š
        3. ç±»ä¼¼ä¾‹é¢˜
        4. å¸¸è§é”™è¯¯æé†’
        
        è¦å¼•å¯¼å­¦ç”Ÿç‹¬ç«‹æ€è€ƒï¼Œè€Œéç›´æ¥å‘Šè¯‰ç­”æ¡ˆã€‚
        """
        
        response = await self.voicehelper.chat({
            'message': solution_prompt,
            'conversation_id': f"math_{student_id}",
            'retrieval_config': {
                'collection': f'math_textbook_grade_{self.grade_level}'
            }
        })
        
        guidance = ""
        async for chunk in response.stream():
            if chunk.type == 'generation_chunk':
                guidance += chunk.data.text
        
        # ç”Ÿæˆå¯è§†åŒ–è¾…åŠ©
        visual_aids = await self.create_visual_aids(problem, problem_type)
        
        # ç”Ÿæˆç»ƒä¹ é¢˜
        similar_problems = await self.generate_similar_problems(problem, problem_type)
        
        return MathSolutionResponse(
            guidance=guidance,
            visual_aids=visual_aids,
            similar_problems=similar_problems,
            difficulty_level=await self.assess_problem_difficulty(problem),
            estimated_time=await self.estimate_solving_time(problem, student_id)
        )

# éƒ¨ç½²ç¤ºä¾‹
if __name__ == "__main__":
    # å¯åŠ¨æ•™è‚²åŠ©æ‰‹æœåŠ¡
    math_tutor = MathTutoringSystem(grade_level="8")
    
    # å¤„ç†å­¦ç”Ÿæé—®
    async def handle_student_request():
        response = await math_tutor.handle_student_question(
            student_id="student_123",
            question="äºŒæ¬¡æ–¹ç¨‹æ€ä¹ˆè§£ï¼Ÿ",
            context={
                'current_chapter': 'ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹',
                'difficulty_preference': 'medium'
            }
        )
        
        print("æ•™è‚²åŠ©æ‰‹å›å¤:", response.answer)
        print("æ¨èç»ƒä¹ :", response.related_exercises)
        print("å­¦ä¹ å»ºè®®:", response.learning_path_suggestions)
    
    asyncio.run(handle_student_request())
```

è¿™ä»½æœ€ä½³å®è·µæ–‡æ¡£æ¶µç›–äº†æ¶æ„è®¾è®¡ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨æªæ–½å’Œå®é™…åº”ç”¨æ¡ˆä¾‹ï¼Œä¸ºå¼€å‘è€…æä¾›äº†å…¨é¢çš„æŠ€æœ¯æŒ‡å¯¼å’Œå®è·µç»éªŒã€‚é€šè¿‡è¿™äº›æ¡ˆä¾‹ï¼Œå¯ä»¥æ·±å…¥ç†è§£VoiceHelperç³»ç»Ÿçš„è®¾è®¡æ€è·¯å’Œåº”ç”¨åœºæ™¯ã€‚
