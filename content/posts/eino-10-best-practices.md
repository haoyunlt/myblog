# Eino å®æˆ˜ç»éªŒä¸æœ€ä½³å®è·µ

## ğŸ“– æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£æ±‡æ€»äº† Eino æ¡†æ¶åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„å®æˆ˜ç»éªŒã€æ€§èƒ½ä¼˜åŒ–æŠ€å·§ã€æœ€ä½³å®è·µæ¨¡å¼å’Œå¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©å¼€å‘è€…æ„å»ºé«˜æ€§èƒ½ã€å¯é çš„ LLM åº”ç”¨ã€‚

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹æœ€ä½³å®è·µ

### é¡¹ç›®ç»“æ„ç»„ç»‡

```
your-eino-project/
â”œâ”€â”€ cmd/                    # åº”ç”¨å…¥å£
â”‚   â””â”€â”€ server/
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ internal/               # å†…éƒ¨åŒ…
â”‚   â”œâ”€â”€ config/            # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ handlers/          # ä¸šåŠ¡å¤„ç†å™¨
â”‚   â”œâ”€â”€ middleware/        # ä¸­é—´ä»¶
â”‚   â””â”€â”€ models/           # æ•°æ®æ¨¡å‹
â”œâ”€â”€ pkg/                   # å¯å¤ç”¨åŒ…
â”‚   â”œâ”€â”€ chains/           # é¢„å®šä¹‰é“¾
â”‚   â”œâ”€â”€ components/       # è‡ªå®šä¹‰ç»„ä»¶
â”‚   â””â”€â”€ utils/           # å·¥å…·å‡½æ•°
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ deployments/          # éƒ¨ç½²é…ç½®
â”œâ”€â”€ docs/                # æ–‡æ¡£
â”œâ”€â”€ examples/            # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ scripts/             # è„šæœ¬
â”œâ”€â”€ tests/               # æµ‹è¯•
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### ä¾èµ–ç®¡ç†æœ€ä½³å®è·µ

```go
// go.mod ç¤ºä¾‹
module your-company/your-eino-app

go 1.21

require (
    github.com/cloudwego/eino v0.1.0
    github.com/cloudwego/eino-ext v0.1.0
    
    // åŸºç¡€ä¾èµ–
    github.com/gin-gonic/gin v1.9.1
    github.com/spf13/viper v1.16.0
    github.com/sirupsen/logrus v1.9.3
    
    // æ•°æ®åº“
    gorm.io/gorm v1.25.4
    gorm.io/driver/postgres v1.5.2
    
    // ç¼“å­˜
    github.com/redis/go-redis/v9 v9.1.0
    
    // ç›‘æ§
    github.com/prometheus/client_golang v1.16.0
    go.opentelemetry.io/otel v1.16.0
)
```

## ğŸ—ï¸ æ¶æ„è®¾è®¡æœ€ä½³å®è·µ

### 1. åˆ†å±‚æ¶æ„è®¾è®¡

```mermaid
graph TB
    subgraph "è¡¨ç°å±‚ (Presentation Layer)"
        API[REST API]
        WS[WebSocket]
        CLI[CLI Interface]
    end
    
    subgraph "ä¸šåŠ¡å±‚ (Business Layer)"
        SVC[Service Layer]
        CHAIN[Chain Orchestration]
        WORKFLOW[Workflow Management]
    end
    
    subgraph "ç»„ä»¶å±‚ (Component Layer)"
        MODEL[Model Components]
        TOOL[Tool Components]
        RETRIEVER[Retriever Components]
    end
    
    subgraph "åŸºç¡€è®¾æ–½å±‚ (Infrastructure Layer)"
        DB[Database]
        CACHE[Cache]
        MQ[Message Queue]
        STORAGE[File Storage]
    end
    
    API --> SVC
    WS --> SVC
    CLI --> SVC
    
    SVC --> CHAIN
    SVC --> WORKFLOW
    
    CHAIN --> MODEL
    CHAIN --> TOOL
    CHAIN --> RETRIEVER
    
    MODEL --> DB
    TOOL --> CACHE
    RETRIEVER --> STORAGE
    
    style API fill:#e8f5e8
    style SVC fill:#fff3e0
    style MODEL fill:#f3e5f5
    style DB fill:#e3f2fd
```

### 2. æœåŠ¡å±‚è®¾è®¡æ¨¡å¼

```go
// service/chat_service.go
package service

import (
    "context"
    "fmt"
    "time"
    
    "github.com/cloudwego/eino/compose"
    "github.com/cloudwego/eino/schema"
)

// ChatService èŠå¤©æœåŠ¡æ¥å£
type ChatService interface {
    // Chat å¤„ç†å•è½®å¯¹è¯
    Chat(ctx context.Context, req *ChatRequest) (*ChatResponse, error)
    
    // StreamChat å¤„ç†æµå¼å¯¹è¯
    StreamChat(ctx context.Context, req *ChatRequest) (<-chan *ChatChunk, error)
    
    // MultiTurnChat å¤„ç†å¤šè½®å¯¹è¯
    MultiTurnChat(ctx context.Context, req *MultiTurnChatRequest) (*ChatResponse, error)
}

// ChatRequest èŠå¤©è¯·æ±‚
type ChatRequest struct {
    UserID    string            `json:"user_id"`
    SessionID string            `json:"session_id"`
    Message   string            `json:"message"`
    Context   map[string]any    `json:"context,omitempty"`
    Options   *ChatOptions      `json:"options,omitempty"`
}

// ChatResponse èŠå¤©å“åº”
type ChatResponse struct {
    MessageID   string            `json:"message_id"`
    Content     string            `json:"content"`
    TokenUsage  *TokenUsage       `json:"token_usage,omitempty"`
    Metadata    map[string]any    `json:"metadata,omitempty"`
    ProcessTime time.Duration     `json:"process_time"`
}

// chatServiceImpl èŠå¤©æœåŠ¡å®ç°
type chatServiceImpl struct {
    chatChain    compose.Runnable[*ChatInput, *schema.Message]
    ragChain     compose.Runnable[*RAGInput, *schema.Message]
    toolChain    compose.Runnable[*ToolInput, *schema.Message]
    
    sessionRepo  SessionRepository
    messageRepo  MessageRepository
    
    logger       Logger
    metrics      Metrics
}

func NewChatService(
    chatChain compose.Runnable[*ChatInput, *schema.Message],
    ragChain compose.Runnable[*RAGInput, *schema.Message],
    toolChain compose.Runnable[*ToolInput, *schema.Message],
    sessionRepo SessionRepository,
    messageRepo MessageRepository,
    logger Logger,
    metrics Metrics,
) ChatService {
    return &chatServiceImpl{
        chatChain:   chatChain,
        ragChain:    ragChain,
        toolChain:   toolChain,
        sessionRepo: sessionRepo,
        messageRepo: messageRepo,
        logger:      logger,
        metrics:     metrics,
    }
}

func (s *chatServiceImpl) Chat(ctx context.Context, req *ChatRequest) (*ChatResponse, error) {
    startTime := time.Now()
    
    // è®°å½•è¯·æ±‚æŒ‡æ ‡
    s.metrics.IncChatRequests(req.UserID)
    
    // æ„å»ºè¾“å…¥
    input := &ChatInput{
        UserID:    req.UserID,
        SessionID: req.SessionID,
        Message:   req.Message,
        Context:   req.Context,
    }
    
    // é€‰æ‹©åˆé€‚çš„é“¾
    chain, err := s.selectChain(ctx, req)
    if err != nil {
        s.metrics.IncChatErrors("chain_selection_error")
        return nil, fmt.Errorf("failed to select chain: %w", err)
    }
    
    // æ‰§è¡Œé“¾
    result, err := chain.Invoke(ctx, input)
    if err != nil {
        s.metrics.IncChatErrors("chain_execution_error")
        s.logger.Error("Chain execution failed", "error", err, "user_id", req.UserID)
        return nil, fmt.Errorf("failed to execute chain: %w", err)
    }
    
    // ä¿å­˜æ¶ˆæ¯å†å²
    if err := s.saveMessageHistory(ctx, req, result); err != nil {
        s.logger.Warn("Failed to save message history", "error", err)
    }
    
    processTime := time.Since(startTime)
    s.metrics.ObserveChatLatency(processTime)
    
    return &ChatResponse{
        MessageID:   generateMessageID(),
        Content:     result.Content,
        TokenUsage:  extractTokenUsage(result),
        Metadata:    extractMetadata(result),
        ProcessTime: processTime,
    }, nil
}

func (s *chatServiceImpl) selectChain(ctx context.Context, req *ChatRequest) (compose.Runnable[any, *schema.Message], error) {
    // æ ¹æ®è¯·æ±‚ç‰¹å¾é€‰æ‹©åˆé€‚çš„é“¾
    if s.needsRAG(req) {
        return s.ragChain, nil
    }
    
    if s.needsTools(req) {
        return s.toolChain, nil
    }
    
    return s.chatChain, nil
}
```

### 3. é…ç½®ç®¡ç†æœ€ä½³å®è·µ

```go
// config/config.go
package config

import (
    "fmt"
    "time"
    
    "github.com/spf13/viper"
)

// Config åº”ç”¨é…ç½®
type Config struct {
    Server   ServerConfig   `mapstructure:"server"`
    Database DatabaseConfig `mapstructure:"database"`
    Redis    RedisConfig    `mapstructure:"redis"`
    LLM      LLMConfig      `mapstructure:"llm"`
    RAG      RAGConfig      `mapstructure:"rag"`
    Logging  LoggingConfig  `mapstructure:"logging"`
    Metrics  MetricsConfig  `mapstructure:"metrics"`
}

// ServerConfig æœåŠ¡å™¨é…ç½®
type ServerConfig struct {
    Host         string        `mapstructure:"host"`
    Port         int           `mapstructure:"port"`
    ReadTimeout  time.Duration `mapstructure:"read_timeout"`
    WriteTimeout time.Duration `mapstructure:"write_timeout"`
    IdleTimeout  time.Duration `mapstructure:"idle_timeout"`
}

// LLMConfig å¤§è¯­è¨€æ¨¡å‹é…ç½®
type LLMConfig struct {
    Provider    string            `mapstructure:"provider"`
    Model       string            `mapstructure:"model"`
    APIKey      string            `mapstructure:"api_key"`
    BaseURL     string            `mapstructure:"base_url"`
    MaxTokens   int               `mapstructure:"max_tokens"`
    Temperature float64           `mapstructure:"temperature"`
    Timeout     time.Duration     `mapstructure:"timeout"`
    RetryCount  int               `mapstructure:"retry_count"`
    Extra       map[string]any    `mapstructure:"extra"`
}

// RAGConfig RAGé…ç½®
type RAGConfig struct {
    VectorStore VectorStoreConfig `mapstructure:"vector_store"`
    Embedding   EmbeddingConfig   `mapstructure:"embedding"`
    Retrieval   RetrievalConfig   `mapstructure:"retrieval"`
}

// LoadConfig åŠ è½½é…ç½®
func LoadConfig(configPath string) (*Config, error) {
    viper.SetConfigFile(configPath)
    viper.SetConfigType("yaml")
    
    // è®¾ç½®é»˜è®¤å€¼
    setDefaults()
    
    // è¯»å–ç¯å¢ƒå˜é‡
    viper.AutomaticEnv()
    
    // è¯»å–é…ç½®æ–‡ä»¶
    if err := viper.ReadInConfig(); err != nil {
        return nil, fmt.Errorf("failed to read config file: %w", err)
    }
    
    var config Config
    if err := viper.Unmarshal(&config); err != nil {
        return nil, fmt.Errorf("failed to unmarshal config: %w", err)
    }
    
    // éªŒè¯é…ç½®
    if err := validateConfig(&config); err != nil {
        return nil, fmt.Errorf("invalid config: %w", err)
    }
    
    return &config, nil
}

func setDefaults() {
    // æœåŠ¡å™¨é»˜è®¤é…ç½®
    viper.SetDefault("server.host", "0.0.0.0")
    viper.SetDefault("server.port", 8080)
    viper.SetDefault("server.read_timeout", "30s")
    viper.SetDefault("server.write_timeout", "30s")
    viper.SetDefault("server.idle_timeout", "120s")
    
    // LLMé»˜è®¤é…ç½®
    viper.SetDefault("llm.max_tokens", 4096)
    viper.SetDefault("llm.temperature", 0.7)
    viper.SetDefault("llm.timeout", "60s")
    viper.SetDefault("llm.retry_count", 3)
    
    // RAGé»˜è®¤é…ç½®
    viper.SetDefault("rag.retrieval.top_k", 5)
    viper.SetDefault("rag.retrieval.score_threshold", 0.7)
}

func validateConfig(config *Config) error {
    if config.LLM.APIKey == "" {
        return fmt.Errorf("LLM API key is required")
    }
    
    if config.LLM.MaxTokens <= 0 {
        return fmt.Errorf("LLM max tokens must be positive")
    }
    
    if config.RAG.Retrieval.TopK <= 0 {
        return fmt.Errorf("RAG retrieval top_k must be positive")
    }
    
    return nil
}
```

## ğŸ”§ ç»„ä»¶å¼€å‘æœ€ä½³å®è·µ

### 1. è‡ªå®šä¹‰ç»„ä»¶å¼€å‘

```go
// components/custom_retriever.go
package components

import (
    "context"
    "fmt"
    "sort"
    
    "github.com/cloudwego/eino/components/retriever"
    "github.com/cloudwego/eino/schema"
)

// HybridRetriever æ··åˆæ£€ç´¢å™¨ï¼Œç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢
type HybridRetriever struct {
    vectorRetriever   retriever.Retriever
    keywordRetriever  retriever.Retriever
    
    vectorWeight      float64
    keywordWeight     float64
    
    logger           Logger
    metrics          Metrics
}

// HybridRetrieverConfig æ··åˆæ£€ç´¢å™¨é…ç½®
type HybridRetrieverConfig struct {
    VectorRetriever   retriever.Retriever `validate:"required"`
    KeywordRetriever  retriever.Retriever `validate:"required"`
    VectorWeight      float64             `validate:"min=0,max=1"`
    KeywordWeight     float64             `validate:"min=0,max=1"`
    Logger           Logger
    Metrics          Metrics
}

func NewHybridRetriever(ctx context.Context, config *HybridRetrieverConfig) (*HybridRetriever, error) {
    if err := validateConfig(config); err != nil {
        return nil, fmt.Errorf("invalid config: %w", err)
    }
    
    return &HybridRetriever{
        vectorRetriever:  config.VectorRetriever,
        keywordRetriever: config.KeywordRetriever,
        vectorWeight:     config.VectorWeight,
        keywordWeight:    config.KeywordWeight,
        logger:          config.Logger,
        metrics:         config.Metrics,
    }, nil
}

// Retrieve å®ç° retriever.Retriever æ¥å£
func (hr *HybridRetriever) Retrieve(ctx context.Context, query string, opts ...retriever.Option) ([]*schema.Document, error) {
    startTime := time.Now()
    defer func() {
        hr.metrics.ObserveRetrievalLatency(time.Since(startTime))
    }()
    
    // è§£æé€‰é¡¹
    options := retriever.GetOptions(opts...)
    
    // å¹¶è¡Œæ‰§è¡Œä¸¤ç§æ£€ç´¢
    vectorCh := make(chan retrievalResult, 1)
    keywordCh := make(chan retrievalResult, 1)
    
    // å‘é‡æ£€ç´¢
    go func() {
        docs, err := hr.vectorRetriever.Retrieve(ctx, query, opts...)
        vectorCh <- retrievalResult{docs: docs, err: err}
    }()
    
    // å…³é”®è¯æ£€ç´¢
    go func() {
        docs, err := hr.keywordRetriever.Retrieve(ctx, query, opts...)
        keywordCh <- retrievalResult{docs: docs, err: err}
    }()
    
    // æ”¶é›†ç»“æœ
    vectorResult := <-vectorCh
    keywordResult := <-keywordCh
    
    // æ£€æŸ¥é”™è¯¯
    if vectorResult.err != nil {
        hr.logger.Error("Vector retrieval failed", "error", vectorResult.err)
        hr.metrics.IncRetrievalErrors("vector")
    }
    
    if keywordResult.err != nil {
        hr.logger.Error("Keyword retrieval failed", "error", keywordResult.err)
        hr.metrics.IncRetrievalErrors("keyword")
    }
    
    // å¦‚æœä¸¤ä¸ªéƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯
    if vectorResult.err != nil && keywordResult.err != nil {
        return nil, fmt.Errorf("both retrievals failed: vector=%v, keyword=%v", 
            vectorResult.err, keywordResult.err)
    }
    
    // åˆå¹¶å’Œé‡æ’åºç»“æœ
    mergedDocs := hr.mergeAndRerank(vectorResult.docs, keywordResult.docs)
    
    // åº”ç”¨ top_k é™åˆ¶
    if options.TopK > 0 && len(mergedDocs) > options.TopK {
        mergedDocs = mergedDocs[:options.TopK]
    }
    
    hr.metrics.ObserveRetrievalCount(len(mergedDocs))
    
    return mergedDocs, nil
}

type retrievalResult struct {
    docs []*schema.Document
    err  error
}

// mergeAndRerank åˆå¹¶å’Œé‡æ’åºæ–‡æ¡£
func (hr *HybridRetriever) mergeAndRerank(vectorDocs, keywordDocs []*schema.Document) []*schema.Document {
    // åˆ›å»ºæ–‡æ¡£æ˜ å°„ï¼Œé¿å…é‡å¤
    docMap := make(map[string]*schema.Document)
    
    // å¤„ç†å‘é‡æ£€ç´¢ç»“æœ
    for i, doc := range vectorDocs {
        if doc == nil {
            continue
        }
        
        // è®¡ç®—å‘é‡æ£€ç´¢åˆ†æ•°ï¼ˆåŸºäºæ’åï¼‰
        vectorScore := 1.0 - float64(i)/float64(len(vectorDocs))
        
        if existingDoc, exists := docMap[doc.ID]; exists {
            // æ–‡æ¡£å·²å­˜åœ¨ï¼Œæ›´æ–°åˆ†æ•°
            existingScore := existingDoc.Score()
            newScore := existingScore + hr.vectorWeight*vectorScore
            existingDoc.WithScore(newScore)
        } else {
            // æ–°æ–‡æ¡£
            newDoc := *doc
            newDoc.WithScore(hr.vectorWeight * vectorScore)
            docMap[doc.ID] = &newDoc
        }
    }
    
    // å¤„ç†å…³é”®è¯æ£€ç´¢ç»“æœ
    for i, doc := range keywordDocs {
        if doc == nil {
            continue
        }
        
        // è®¡ç®—å…³é”®è¯æ£€ç´¢åˆ†æ•°ï¼ˆåŸºäºæ’åï¼‰
        keywordScore := 1.0 - float64(i)/float64(len(keywordDocs))
        
        if existingDoc, exists := docMap[doc.ID]; exists {
            // æ–‡æ¡£å·²å­˜åœ¨ï¼Œæ›´æ–°åˆ†æ•°
            existingScore := existingDoc.Score()
            newScore := existingScore + hr.keywordWeight*keywordScore
            existingDoc.WithScore(newScore)
        } else {
            // æ–°æ–‡æ¡£
            newDoc := *doc
            newDoc.WithScore(hr.keywordWeight * keywordScore)
            docMap[doc.ID] = &newDoc
        }
    }
    
    // è½¬æ¢ä¸ºåˆ‡ç‰‡å¹¶æŒ‰åˆ†æ•°æ’åº
    result := make([]*schema.Document, 0, len(docMap))
    for _, doc := range docMap {
        result = append(result, doc)
    }
    
    sort.Slice(result, func(i, j int) bool {
        return result[i].Score() > result[j].Score()
    })
    
    return result
}

// GetType è¿”å›ç»„ä»¶ç±»å‹
func (hr *HybridRetriever) GetType() string {
    return "HybridRetriever"
}
```

### 2. Lambda å‡½æ•°æœ€ä½³å®è·µ

```go
// chains/processors.go
package chains

import (
    "context"
    "fmt"
    "strings"
    "time"
    
    "github.com/cloudwego/eino/compose"
    "github.com/cloudwego/eino/schema"
)

// CreateQueryProcessor åˆ›å»ºæŸ¥è¯¢é¢„å¤„ç†å™¨
func CreateQueryProcessor(config *ProcessorConfig) *compose.Lambda {
    return compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
        startTime := time.Now()
        defer func() {
            config.Metrics.ObserveProcessingLatency("query_processor", time.Since(startTime))
        }()
        
        // æŸ¥è¯¢æ¸…ç†
        cleaned := strings.TrimSpace(input)
        if cleaned == "" {
            return "", fmt.Errorf("empty query")
        }
        
        // æŸ¥è¯¢å¢å¼º
        enhanced := enhanceQuery(cleaned, config)
        
        config.Logger.Debug("Query processed", 
            "original", input, 
            "enhanced", enhanced)
        
        return enhanced, nil
    }, compose.WithLambdaType("QueryProcessor"))
}

// CreateResponseFormatter åˆ›å»ºå“åº”æ ¼å¼åŒ–å™¨
func CreateResponseFormatter(config *ProcessorConfig) *compose.Lambda {
    return compose.InvokableLambda(func(ctx context.Context, input *schema.Message) (*schema.Message, error) {
        startTime := time.Now()
        defer func() {
            config.Metrics.ObserveProcessingLatency("response_formatter", time.Since(startTime))
        }()
        
        // æ ¼å¼åŒ–å“åº”å†…å®¹
        formatted := formatResponse(input.Content, config)
        
        // åˆ›å»ºæ–°çš„æ¶ˆæ¯
        result := &schema.Message{
            Role:    input.Role,
            Content: formatted,
            Extra: map[string]any{
                "formatted_at": time.Now(),
                "formatter":    "ResponseFormatter",
            },
        }
        
        // å¤åˆ¶å…¶ä»–å­—æ®µ
        if input.ResponseMeta != nil {
            result.ResponseMeta = input.ResponseMeta
        }
        
        return result, nil
    }, compose.WithLambdaType("ResponseFormatter"))
}

// CreateStreamingProcessor åˆ›å»ºæµå¼å¤„ç†å™¨
func CreateStreamingProcessor(config *ProcessorConfig) *compose.Lambda {
    return compose.StreamableLambda(func(ctx context.Context, input string) (*schema.StreamReader[string], error) {
        // åˆ›å»ºæµå¼è¾“å‡º
        sr, sw := schema.Pipe[string](10)
        
        go func() {
            defer sw.Close()
            
            // æ¨¡æ‹Ÿæµå¼å¤„ç†
            words := strings.Fields(input)
            for i, word := range words {
                select {
                case <-ctx.Done():
                    return
                default:
                }
                
                // å¤„ç†å•è¯
                processed := processWord(word, config)
                
                if sw.Send(processed, nil) {
                    return // æµå·²å…³é—­
                }
                
                // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
                if i < len(words)-1 {
                    time.Sleep(10 * time.Millisecond)
                }
            }
        }()
        
        return sr, nil
    }, compose.WithLambdaType("StreamingProcessor"))
}

// CreateBatchProcessor åˆ›å»ºæ‰¹å¤„ç†å™¨
func CreateBatchProcessor(config *ProcessorConfig) *compose.Lambda {
    return compose.CollectableLambda(func(ctx context.Context, input *schema.StreamReader[string]) (string, error) {
        var items []string
        
        // æ”¶é›†æ‰€æœ‰æµæ•°æ®
        for {
            item, err := input.Recv()
            if err == io.EOF {
                break
            }
            if err != nil {
                return "", fmt.Errorf("failed to receive stream item: %w", err)
            }
            
            items = append(items, item)
        }
        
        // æ‰¹é‡å¤„ç†
        result := processBatch(items, config)
        
        return result, nil
    }, compose.WithLambdaType("BatchProcessor"))
}

// è¾…åŠ©å‡½æ•°
func enhanceQuery(query string, config *ProcessorConfig) string {
    // å®ç°æŸ¥è¯¢å¢å¼ºé€»è¾‘
    enhanced := query
    
    // æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
    if config.AddContext {
        enhanced = fmt.Sprintf("Context: %s\nQuery: %s", config.ContextInfo, enhanced)
    }
    
    // æ·»åŠ æŒ‡ä»¤
    if config.AddInstructions {
        enhanced = fmt.Sprintf("%s\nInstructions: %s", enhanced, config.Instructions)
    }
    
    return enhanced
}

func formatResponse(content string, config *ProcessorConfig) string {
    // å®ç°å“åº”æ ¼å¼åŒ–é€»è¾‘
    formatted := content
    
    // æ·»åŠ æ ¼å¼åŒ–æ ‡è®°
    if config.AddMarkdown {
        formatted = addMarkdownFormatting(formatted)
    }
    
    // æ·»åŠ å…ƒä¿¡æ¯
    if config.AddMetaInfo {
        formatted = fmt.Sprintf("%s\n\n---\n*Generated at: %s*", 
            formatted, time.Now().Format("2006-01-02 15:04:05"))
    }
    
    return formatted
}
```

### 3. é”™è¯¯å¤„ç†æœ€ä½³å®è·µ

```go
// errors/errors.go
package errors

import (
    "fmt"
    "net/http"
)

// å®šä¹‰é”™è¯¯ç±»å‹
type ErrorType string

const (
    ErrorTypeValidation   ErrorType = "validation"
    ErrorTypeNotFound     ErrorType = "not_found"
    ErrorTypeUnauthorized ErrorType = "unauthorized"
    ErrorTypeRateLimit    ErrorType = "rate_limit"
    ErrorTypeInternal     ErrorType = "internal"
    ErrorTypeExternal     ErrorType = "external"
)

// AppError åº”ç”¨é”™è¯¯
type AppError struct {
    Type       ErrorType         `json:"type"`
    Code       string            `json:"code"`
    Message    string            `json:"message"`
    Details    string            `json:"details,omitempty"`
    Metadata   map[string]any    `json:"metadata,omitempty"`
    Cause      error             `json:"-"`
    HTTPStatus int               `json:"-"`
}

func (e *AppError) Error() string {
    if e.Cause != nil {
        return fmt.Sprintf("%s: %s (caused by: %v)", e.Code, e.Message, e.Cause)
    }
    return fmt.Sprintf("%s: %s", e.Code, e.Message)
}

func (e *AppError) Unwrap() error {
    return e.Cause
}

// é”™è¯¯æ„é€ å‡½æ•°
func NewValidationError(code, message string) *AppError {
    return &AppError{
        Type:       ErrorTypeValidation,
        Code:       code,
        Message:    message,
        HTTPStatus: http.StatusBadRequest,
    }
}

func NewNotFoundError(code, message string) *AppError {
    return &AppError{
        Type:       ErrorTypeNotFound,
        Code:       code,
        Message:    message,
        HTTPStatus: http.StatusNotFound,
    }
}

func NewInternalError(code, message string, cause error) *AppError {
    return &AppError{
        Type:       ErrorTypeInternal,
        Code:       code,
        Message:    message,
        Cause:      cause,
        HTTPStatus: http.StatusInternalServerError,
    }
}

func NewExternalError(code, message string, cause error) *AppError {
    return &AppError{
        Type:       ErrorTypeExternal,
        Code:       code,
        Message:    message,
        Cause:      cause,
        HTTPStatus: http.StatusBadGateway,
    }
}

// é”™è¯¯å¤„ç†ä¸­é—´ä»¶
func ErrorHandlerMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        c.Next()
        
        if len(c.Errors) > 0 {
            err := c.Errors.Last().Err
            
            var appErr *AppError
            if errors.As(err, &appErr) {
                c.JSON(appErr.HTTPStatus, gin.H{
                    "error": appErr,
                })
            } else {
                // æœªçŸ¥é”™è¯¯
                c.JSON(http.StatusInternalServerError, gin.H{
                    "error": NewInternalError("UNKNOWN_ERROR", "An unexpected error occurred", err),
                })
            }
        }
    }
}
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

### 1. å†…å­˜ç®¡ç†ä¼˜åŒ–

```go
// optimization/memory.go
package optimization

import (
    "context"
    "sync"
    "time"
    
    "github.com/cloudwego/eino/schema"
)

// ObjectPool å¯¹è±¡æ± 
type ObjectPool[T any] struct {
    pool sync.Pool
    new  func() T
}

func NewObjectPool[T any](newFunc func() T) *ObjectPool[T] {
    return &ObjectPool[T]{
        pool: sync.Pool{
            New: func() any {
                return newFunc()
            },
        },
        new: newFunc,
    }
}

func (p *ObjectPool[T]) Get() T {
    return p.pool.Get().(T)
}

func (p *ObjectPool[T]) Put(obj T) {
    p.pool.Put(obj)
}

// é¢„å®šä¹‰å¯¹è±¡æ± 
var (
    MessagePool = NewObjectPool(func() *schema.Message {
        return &schema.Message{}
    })
    
    DocumentPool = NewObjectPool(func() *schema.Document {
        return &schema.Document{
            MetaData: make(map[string]any),
        }
    })
    
    StringBuilderPool = NewObjectPool(func() *strings.Builder {
        return &strings.Builder{}
    })
)

// ä½¿ç”¨ç¤ºä¾‹
func ProcessMessages(messages []*schema.Message) []*schema.Message {
    result := make([]*schema.Message, 0, len(messages))
    
    for _, msg := range messages {
        // ä»æ± ä¸­è·å–å¯¹è±¡
        processed := MessagePool.Get()
        defer MessagePool.Put(processed) // ä½¿ç”¨å®Œæ¯•åå½’è¿˜
        
        // é‡ç½®å¯¹è±¡çŠ¶æ€
        *processed = schema.Message{
            Role:    msg.Role,
            Content: processContent(msg.Content),
        }
        
        result = append(result, processed)
    }
    
    return result
}

// StreamBuffer æµç¼“å†²åŒºç®¡ç†
type StreamBuffer[T any] struct {
    buffer   []T
    capacity int
    mu       sync.RWMutex
}

func NewStreamBuffer[T any](capacity int) *StreamBuffer[T] {
    return &StreamBuffer[T]{
        buffer:   make([]T, 0, capacity),
        capacity: capacity,
    }
}

func (sb *StreamBuffer[T]) Add(item T) bool {
    sb.mu.Lock()
    defer sb.mu.Unlock()
    
    if len(sb.buffer) >= sb.capacity {
        return false // ç¼“å†²åŒºå·²æ»¡
    }
    
    sb.buffer = append(sb.buffer, item)
    return true
}

func (sb *StreamBuffer[T]) Flush() []T {
    sb.mu.Lock()
    defer sb.mu.Unlock()
    
    if len(sb.buffer) == 0 {
        return nil
    }
    
    result := make([]T, len(sb.buffer))
    copy(result, sb.buffer)
    sb.buffer = sb.buffer[:0] // æ¸…ç©ºä½†ä¿ç•™å®¹é‡
    
    return result
}
```

### 2. å¹¶å‘æ§åˆ¶ä¼˜åŒ–

```go
// optimization/concurrency.go
package optimization

import (
    "context"
    "sync"
    "time"
)

// WorkerPool å·¥ä½œæ± 
type WorkerPool[T any, R any] struct {
    workers    int
    jobCh      chan Job[T, R]
    resultCh   chan Result[R]
    wg         sync.WaitGroup
    ctx        context.Context
    cancel     context.CancelFunc
}

type Job[T any, R any] struct {
    ID   string
    Data T
    Fn   func(context.Context, T) (R, error)
}

type Result[R any] struct {
    ID     string
    Data   R
    Error  error
}

func NewWorkerPool[T any, R any](ctx context.Context, workers int) *WorkerPool[T, R] {
    ctx, cancel := context.WithCancel(ctx)
    
    pool := &WorkerPool[T, R]{
        workers:  workers,
        jobCh:    make(chan Job[T, R], workers*2),
        resultCh: make(chan Result[R], workers*2),
        ctx:      ctx,
        cancel:   cancel,
    }
    
    // å¯åŠ¨å·¥ä½œåç¨‹
    for i := 0; i < workers; i++ {
        pool.wg.Add(1)
        go pool.worker()
    }
    
    return pool
}

func (wp *WorkerPool[T, R]) worker() {
    defer wp.wg.Done()
    
    for {
        select {
        case <-wp.ctx.Done():
            return
        case job := <-wp.jobCh:
            result := Result[R]{ID: job.ID}
            result.Data, result.Error = job.Fn(wp.ctx, job.Data)
            
            select {
            case wp.resultCh <- result:
            case <-wp.ctx.Done():
                return
            }
        }
    }
}

func (wp *WorkerPool[T, R]) Submit(job Job[T, R]) bool {
    select {
    case wp.jobCh <- job:
        return true
    case <-wp.ctx.Done():
        return false
    default:
        return false // é˜Ÿåˆ—å·²æ»¡
    }
}

func (wp *WorkerPool[T, R]) Results() <-chan Result[R] {
    return wp.resultCh
}

func (wp *WorkerPool[T, R]) Close() {
    wp.cancel()
    close(wp.jobCh)
    wp.wg.Wait()
    close(wp.resultCh)
}

// RateLimiter é€Ÿç‡é™åˆ¶å™¨
type RateLimiter struct {
    tokens chan struct{}
    ticker *time.Ticker
    done   chan struct{}
}

func NewRateLimiter(rate int, burst int) *RateLimiter {
    rl := &RateLimiter{
        tokens: make(chan struct{}, burst),
        ticker: time.NewTicker(time.Second / time.Duration(rate)),
        done:   make(chan struct{}),
    }
    
    // åˆå§‹å¡«å……ä»¤ç‰Œ
    for i := 0; i < burst; i++ {
        rl.tokens <- struct{}{}
    }
    
    // å®šæœŸæ·»åŠ ä»¤ç‰Œ
    go func() {
        for {
            select {
            case <-rl.ticker.C:
                select {
                case rl.tokens <- struct{}{}:
                default:
                    // ä»¤ç‰Œæ¡¶å·²æ»¡
                }
            case <-rl.done:
                return
            }
        }
    }()
    
    return rl
}

func (rl *RateLimiter) Wait(ctx context.Context) error {
    select {
    case <-rl.tokens:
        return nil
    case <-ctx.Done():
        return ctx.Err()
    }
}

func (rl *RateLimiter) Close() {
    rl.ticker.Stop()
    close(rl.done)
}
```

### 3. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–

```go
// optimization/cache.go
package optimization

import (
    "context"
    "crypto/md5"
    "encoding/hex"
    "encoding/json"
    "fmt"
    "sync"
    "time"
)

// Cache ç¼“å­˜æ¥å£
type Cache interface {
    Get(ctx context.Context, key string) ([]byte, error)
    Set(ctx context.Context, key string, value []byte, ttl time.Duration) error
    Delete(ctx context.Context, key string) error
    Clear(ctx context.Context) error
}

// MemoryCache å†…å­˜ç¼“å­˜å®ç°
type MemoryCache struct {
    data map[string]*cacheItem
    mu   sync.RWMutex
}

type cacheItem struct {
    value     []byte
    expiresAt time.Time
}

func NewMemoryCache() *MemoryCache {
    cache := &MemoryCache{
        data: make(map[string]*cacheItem),
    }
    
    // å¯åŠ¨æ¸…ç†åç¨‹
    go cache.cleanup()
    
    return cache
}

func (mc *MemoryCache) Get(ctx context.Context, key string) ([]byte, error) {
    mc.mu.RLock()
    defer mc.mu.RUnlock()
    
    item, exists := mc.data[key]
    if !exists {
        return nil, fmt.Errorf("key not found")
    }
    
    if time.Now().After(item.expiresAt) {
        return nil, fmt.Errorf("key expired")
    }
    
    return item.value, nil
}

func (mc *MemoryCache) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    mc.data[key] = &cacheItem{
        value:     value,
        expiresAt: time.Now().Add(ttl),
    }
    
    return nil
}

func (mc *MemoryCache) Delete(ctx context.Context, key string) error {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    delete(mc.data, key)
    return nil
}

func (mc *MemoryCache) Clear(ctx context.Context) error {
    mc.mu.Lock()
    defer mc.mu.Unlock()
    
    mc.data = make(map[string]*cacheItem)
    return nil
}

func (mc *MemoryCache) cleanup() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()
    
    for range ticker.C {
        mc.mu.Lock()
        now := time.Now()
        for key, item := range mc.data {
            if now.After(item.expiresAt) {
                delete(mc.data, key)
            }
        }
        mc.mu.Unlock()
    }
}

// CacheManager ç¼“å­˜ç®¡ç†å™¨
type CacheManager struct {
    cache  Cache
    prefix string
}

func NewCacheManager(cache Cache, prefix string) *CacheManager {
    return &CacheManager{
        cache:  cache,
        prefix: prefix,
    }
}

func (cm *CacheManager) GetOrSet(ctx context.Context, key string, ttl time.Duration, fn func() (any, error)) (any, error) {
    fullKey := cm.prefix + ":" + key
    
    // å°è¯•ä»ç¼“å­˜è·å–
    data, err := cm.cache.Get(ctx, fullKey)
    if err == nil {
        var result any
        if err := json.Unmarshal(data, &result); err == nil {
            return result, nil
        }
    }
    
    // ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
    result, err := fn()
    if err != nil {
        return nil, err
    }
    
    // å­˜å‚¨åˆ°ç¼“å­˜
    data, err = json.Marshal(result)
    if err == nil {
        cm.cache.Set(ctx, fullKey, data, ttl)
    }
    
    return result, nil
}

func (cm *CacheManager) GenerateKey(parts ...string) string {
    h := md5.New()
    for _, part := range parts {
        h.Write([]byte(part))
    }
    return hex.EncodeToString(h.Sum(nil))
}

// ä½¿ç”¨ç¤ºä¾‹
func CachedChatCompletion(ctx context.Context, cacheManager *CacheManager, input string) (*schema.Message, error) {
    key := cacheManager.GenerateKey("chat", input)
    
    result, err := cacheManager.GetOrSet(ctx, key, 10*time.Minute, func() (any, error) {
        // å®é™…çš„èŠå¤©å®Œæˆé€»è¾‘
        return performChatCompletion(ctx, input)
    })
    
    if err != nil {
        return nil, err
    }
    
    return result.(*schema.Message), nil
}
```

## ğŸ” ç›‘æ§ä¸å¯è§‚æµ‹æ€§

### 1. æŒ‡æ ‡æ”¶é›†

```go
// monitoring/metrics.go
package monitoring

import (
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// Metrics æŒ‡æ ‡æ”¶é›†å™¨
type Metrics struct {
    // è¯·æ±‚æŒ‡æ ‡
    requestsTotal    *prometheus.CounterVec
    requestDuration  *prometheus.HistogramVec
    requestErrors    *prometheus.CounterVec
    
    // ç»„ä»¶æŒ‡æ ‡
    componentCalls   *prometheus.CounterVec
    componentLatency *prometheus.HistogramVec
    componentErrors  *prometheus.CounterVec
    
    // èµ„æºæŒ‡æ ‡
    activeConnections prometheus.Gauge
    memoryUsage      prometheus.Gauge
    goroutineCount   prometheus.Gauge
    
    // ä¸šåŠ¡æŒ‡æ ‡
    tokenUsage       *prometheus.CounterVec
    cacheHitRate     *prometheus.GaugeVec
    queueLength      *prometheus.GaugeVec
}

func NewMetrics() *Metrics {
    return &Metrics{
        requestsTotal: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "eino_requests_total",
                Help: "Total number of requests",
            },
            []string{"method", "endpoint", "status"},
        ),
        
        requestDuration: promauto.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "eino_request_duration_seconds",
                Help:    "Request duration in seconds",
                Buckets: prometheus.DefBuckets,
            },
            []string{"method", "endpoint"},
        ),
        
        requestErrors: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "eino_request_errors_total",
                Help: "Total number of request errors",
            },
            []string{"method", "endpoint", "error_type"},
        ),
        
        componentCalls: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "eino_component_calls_total",
                Help: "Total number of component calls",
            },
            []string{"component_type", "component_name"},
        ),
        
        componentLatency: promauto.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "eino_component_latency_seconds",
                Help:    "Component call latency in seconds",
                Buckets: prometheus.DefBuckets,
            },
            []string{"component_type", "component_name"},
        ),
        
        componentErrors: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "eino_component_errors_total",
                Help: "Total number of component errors",
            },
            []string{"component_type", "component_name", "error_type"},
        ),
        
        activeConnections: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "eino_active_connections",
                Help: "Number of active connections",
            },
        ),
        
        memoryUsage: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "eino_memory_usage_bytes",
                Help: "Memory usage in bytes",
            },
        ),
        
        goroutineCount: promauto.NewGauge(
            prometheus.GaugeOpts{
                Name: "eino_goroutines",
                Help: "Number of goroutines",
            },
        ),
        
        tokenUsage: promauto.NewCounterVec(
            prometheus.CounterOpts{
                Name: "eino_token_usage_total",
                Help: "Total token usage",
            },
            []string{"model", "type"},
        ),
        
        cacheHitRate: promauto.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "eino_cache_hit_rate",
                Help: "Cache hit rate",
            },
            []string{"cache_type"},
        ),
        
        queueLength: promauto.NewGaugeVec(
            prometheus.GaugeOpts{
                Name: "eino_queue_length",
                Help: "Queue length",
            },
            []string{"queue_name"},
        ),
    }
}

// æŒ‡æ ‡è®°å½•æ–¹æ³•
func (m *Metrics) IncRequests(method, endpoint, status string) {
    m.requestsTotal.WithLabelValues(method, endpoint, status).Inc()
}

func (m *Metrics) ObserveRequestDuration(method, endpoint string, duration time.Duration) {
    m.requestDuration.WithLabelValues(method, endpoint).Observe(duration.Seconds())
}

func (m *Metrics) IncRequestErrors(method, endpoint, errorType string) {
    m.requestErrors.WithLabelValues(method, endpoint, errorType).Inc()
}

func (m *Metrics) IncComponentCalls(componentType, componentName string) {
    m.componentCalls.WithLabelValues(componentType, componentName).Inc()
}

func (m *Metrics) ObserveComponentLatency(componentType, componentName string, duration time.Duration) {
    m.componentLatency.WithLabelValues(componentType, componentName).Observe(duration.Seconds())
}

func (m *Metrics) IncComponentErrors(componentType, componentName, errorType string) {
    m.componentErrors.WithLabelValues(componentType, componentName, errorType).Inc()
}

func (m *Metrics) SetActiveConnections(count float64) {
    m.activeConnections.Set(count)
}

func (m *Metrics) SetMemoryUsage(bytes float64) {
    m.memoryUsage.Set(bytes)
}

func (m *Metrics) SetGoroutineCount(count float64) {
    m.goroutineCount.Set(count)
}

func (m *Metrics) IncTokenUsage(model, tokenType string, count float64) {
    m.tokenUsage.WithLabelValues(model, tokenType).Add(count)
}

func (m *Metrics) SetCacheHitRate(cacheType string, rate float64) {
    m.cacheHitRate.WithLabelValues(cacheType).Set(rate)
}

func (m *Metrics) SetQueueLength(queueName string, length float64) {
    m.queueLength.WithLabelValues(queueName).Set(length)
}
```

### 2. é“¾è·¯è¿½è¸ª

```go
// monitoring/tracing.go
package monitoring

import (
    "context"
    "fmt"
    
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/attribute"
    "go.opentelemetry.io/otel/codes"
    "go.opentelemetry.io/otel/trace"
)

const (
    TracerName = "eino"
)

// TraceableComponent å¯è¿½è¸ªçš„ç»„ä»¶æ¥å£
type TraceableComponent interface {
    GetTraceInfo() TraceInfo
}

// TraceInfo è¿½è¸ªä¿¡æ¯
type TraceInfo struct {
    ComponentType string
    ComponentName string
    Version       string
    Attributes    map[string]any
}

// TracingMiddleware è¿½è¸ªä¸­é—´ä»¶
func TracingMiddleware(componentType, componentName string) func(next func(context.Context, any) (any, error)) func(context.Context, any) (any, error) {
    return func(next func(context.Context, any) (any, error)) func(context.Context, any) (any, error) {
        return func(ctx context.Context, input any) (any, error) {
            tracer := otel.Tracer(TracerName)
            
            spanName := fmt.Sprintf("%s.%s", componentType, componentName)
            ctx, span := tracer.Start(ctx, spanName)
            defer span.End()
            
            // è®¾ç½®åŸºç¡€å±æ€§
            span.SetAttributes(
                attribute.String("component.type", componentType),
                attribute.String("component.name", componentName),
                attribute.String("input.type", fmt.Sprintf("%T", input)),
            )
            
            // æ‰§è¡Œç»„ä»¶é€»è¾‘
            output, err := next(ctx, input)
            
            if err != nil {
                span.RecordError(err)
                span.SetStatus(codes.Error, err.Error())
                span.SetAttributes(
                    attribute.String("error.type", fmt.Sprintf("%T", err)),
                    attribute.String("error.message", err.Error()),
                )
            } else {
                span.SetStatus(codes.Ok, "success")
                span.SetAttributes(
                    attribute.String("output.type", fmt.Sprintf("%T", output)),
                )
            }
            
            return output, err
        }
    }
}

// TraceChainExecution è¿½è¸ªé“¾æ‰§è¡Œ
func TraceChainExecution(ctx context.Context, chainName string, fn func(context.Context) (any, error)) (any, error) {
    tracer := otel.Tracer(TracerName)
    
    spanName := fmt.Sprintf("chain.%s", chainName)
    ctx, span := tracer.Start(ctx, spanName)
    defer span.End()
    
    span.SetAttributes(
        attribute.String("chain.name", chainName),
        attribute.String("operation", "execute"),
    )
    
    result, err := fn(ctx)
    
    if err != nil {
        span.RecordError(err)
        span.SetStatus(codes.Error, err.Error())
    } else {
        span.SetStatus(codes.Ok, "success")
    }
    
    return result, err
}

// AddSpanEvent æ·»åŠ  Span äº‹ä»¶
func AddSpanEvent(ctx context.Context, name string, attributes map[string]any) {
    span := trace.SpanFromContext(ctx)
    if !span.IsRecording() {
        return
    }
    
    attrs := make([]attribute.KeyValue, 0, len(attributes))
    for k, v := range attributes {
        attrs = append(attrs, attribute.String(k, fmt.Sprintf("%v", v)))
    }
    
    span.AddEvent(name, trace.WithAttributes(attrs...))
}

// SetSpanAttributes è®¾ç½® Span å±æ€§
func SetSpanAttributes(ctx context.Context, attributes map[string]any) {
    span := trace.SpanFromContext(ctx)
    if !span.IsRecording() {
        return
    }
    
    attrs := make([]attribute.KeyValue, 0, len(attributes))
    for k, v := range attributes {
        attrs = append(attrs, attribute.String(k, fmt.Sprintf("%v", v)))
    }
    
    span.SetAttributes(attrs...)
}
```

### 3. æ—¥å¿—è®°å½•

```go
// monitoring/logging.go
package monitoring

import (
    "context"
    "fmt"
    "time"
    
    "github.com/sirupsen/logrus"
    "go.opentelemetry.io/otel/trace"
)

// Logger æ—¥å¿—æ¥å£
type Logger interface {
    Debug(msg string, fields ...any)
    Info(msg string, fields ...any)
    Warn(msg string, fields ...any)
    Error(msg string, fields ...any)
    Fatal(msg string, fields ...any)
    
    WithContext(ctx context.Context) Logger
    WithFields(fields map[string]any) Logger
}

// StructuredLogger ç»“æ„åŒ–æ—¥å¿—å®ç°
type StructuredLogger struct {
    logger *logrus.Logger
    fields logrus.Fields
}

func NewStructuredLogger() *StructuredLogger {
    logger := logrus.New()
    logger.SetFormatter(&logrus.JSONFormatter{
        TimestampFormat: time.RFC3339,
        FieldMap: logrus.FieldMap{
            logrus.FieldKeyTime:  "timestamp",
            logrus.FieldKeyLevel: "level",
            logrus.FieldKeyMsg:   "message",
        },
    })
    
    return &StructuredLogger{
        logger: logger,
        fields: make(logrus.Fields),
    }
}

func (sl *StructuredLogger) Debug(msg string, fields ...any) {
    sl.logWithFields(logrus.DebugLevel, msg, fields...)
}

func (sl *StructuredLogger) Info(msg string, fields ...any) {
    sl.logWithFields(logrus.InfoLevel, msg, fields...)
}

func (sl *StructuredLogger) Warn(msg string, fields ...any) {
    sl.logWithFields(logrus.WarnLevel, msg, fields...)
}

func (sl *StructuredLogger) Error(msg string, fields ...any) {
    sl.logWithFields(logrus.ErrorLevel, msg, fields...)
}

func (sl *StructuredLogger) Fatal(msg string, fields ...any) {
    sl.logWithFields(logrus.FatalLevel, msg, fields...)
}

func (sl *StructuredLogger) WithContext(ctx context.Context) Logger {
    newFields := make(logrus.Fields)
    for k, v := range sl.fields {
        newFields[k] = v
    }
    
    // æ·»åŠ è¿½è¸ªä¿¡æ¯
    if span := trace.SpanFromContext(ctx); span.SpanContext().IsValid() {
        newFields["trace_id"] = span.SpanContext().TraceID().String()
        newFields["span_id"] = span.SpanContext().SpanID().String()
    }
    
    return &StructuredLogger{
        logger: sl.logger,
        fields: newFields,
    }
}

func (sl *StructuredLogger) WithFields(fields map[string]any) Logger {
    newFields := make(logrus.Fields)
    for k, v := range sl.fields {
        newFields[k] = v
    }
    for k, v := range fields {
        newFields[k] = v
    }
    
    return &StructuredLogger{
        logger: sl.logger,
        fields: newFields,
    }
}

func (sl *StructuredLogger) logWithFields(level logrus.Level, msg string, fields ...any) {
    entry := sl.logger.WithFields(sl.fields)
    
    // å¤„ç†é¢å¤–å­—æ®µ
    if len(fields) > 0 {
        extraFields := make(logrus.Fields)
        for i := 0; i < len(fields); i += 2 {
            if i+1 < len(fields) {
                key := fmt.Sprintf("%v", fields[i])
                value := fields[i+1]
                extraFields[key] = value
            }
        }
        entry = entry.WithFields(extraFields)
    }
    
    entry.Log(level, msg)
}

// ComponentLogger ç»„ä»¶æ—¥å¿—åŒ…è£…å™¨
type ComponentLogger struct {
    logger        Logger
    componentType string
    componentName string
}

func NewComponentLogger(logger Logger, componentType, componentName string) *ComponentLogger {
    return &ComponentLogger{
        logger: logger.WithFields(map[string]any{
            "component_type": componentType,
            "component_name": componentName,
        }),
        componentType: componentType,
        componentName: componentName,
    }
}

func (cl *ComponentLogger) LogExecution(ctx context.Context, operation string, duration time.Duration, err error) {
    logger := cl.logger.WithContext(ctx)
    
    fields := map[string]any{
        "operation": operation,
        "duration":  duration.String(),
    }
    
    if err != nil {
        fields["error"] = err.Error()
        logger.Error("Component execution failed", "fields", fields)
    } else {
        logger.Info("Component execution completed", "fields", fields)
    }
}

func (cl *ComponentLogger) LogInput(ctx context.Context, input any) {
    logger := cl.logger.WithContext(ctx)
    logger.Debug("Component input", 
        "input_type", fmt.Sprintf("%T", input),
        "input_size", getInputSize(input))
}

func (cl *ComponentLogger) LogOutput(ctx context.Context, output any) {
    logger := cl.logger.WithContext(ctx)
    logger.Debug("Component output", 
        "output_type", fmt.Sprintf("%T", output),
        "output_size", getOutputSize(output))
}

func getInputSize(input any) int {
    // å®ç°è¾“å…¥å¤§å°è®¡ç®—é€»è¾‘
    return 0
}

func getOutputSize(output any) int {
    // å®ç°è¾“å‡ºå¤§å°è®¡ç®—é€»è¾‘
    return 0
}
```

## ğŸš€ éƒ¨ç½²ä¸è¿ç»´æœ€ä½³å®è·µ

### 1. Docker å®¹å™¨åŒ–

```dockerfile
# Dockerfile
FROM golang:1.21-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ä¾èµ–
RUN apk add --no-cache git ca-certificates tzdata

# å¤åˆ¶ go mod æ–‡ä»¶
COPY go.mod go.sum ./

# ä¸‹è½½ä¾èµ–
RUN go mod download

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main ./cmd/server

# è¿è¡Œé˜¶æ®µ
FROM alpine:latest

# å®‰è£… ca-certificates
RUN apk --no-cache add ca-certificates tzdata

WORKDIR /root/

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶
COPY --from=builder /app/main .
COPY --from=builder /app/configs ./configs

# åˆ›å»ºé root ç”¨æˆ·
RUN adduser -D -s /bin/sh appuser
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1

# å¯åŠ¨åº”ç”¨
CMD ["./main"]
```

### 2. Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  eino-app:
    build: .
    ports:
      - "8080:8080"
    environment:
      - ENV=production
      - LOG_LEVEL=info
      - DATABASE_URL=postgres://user:password@postgres:5432/einodb
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    volumes:
      - ./configs:/root/configs:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=einodb
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d einodb"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
```

### 3. Kubernetes éƒ¨ç½²

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: eino-app
  labels:
    app: eino-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: eino-app
  template:
    metadata:
      labels:
        app: eino-app
    spec:
      containers:
      - name: eino-app
        image: your-registry/eino-app:latest
        ports:
        - containerPort: 8080
        env:
        - name: ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: eino-secrets
              key: database-url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: eino-secrets
              key: redis-url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /root/configs
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: eino-config

---
apiVersion: v1
kind: Service
metadata:
  name: eino-service
spec:
  selector:
    app: eino-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: eino-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.yourdomain.com
    secretName: eino-tls
  rules:
  - host: api.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: eino-service
            port:
              number: 80
```

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

### 1. API å®‰å…¨

```go
// security/auth.go
package security

import (
    "context"
    "crypto/rand"
    "crypto/subtle"
    "encoding/base64"
    "fmt"
    "strings"
    "time"
    
    "github.com/golang-jwt/jwt/v5"
)

// AuthService è®¤è¯æœåŠ¡
type AuthService struct {
    jwtSecret     []byte
    tokenExpiry   time.Duration
    refreshExpiry time.Duration
}

func NewAuthService(secret string, tokenExpiry, refreshExpiry time.Duration) *AuthService {
    return &AuthService{
        jwtSecret:     []byte(secret),
        tokenExpiry:   tokenExpiry,
        refreshExpiry: refreshExpiry,
    }
}

// GenerateToken ç”Ÿæˆè®¿é—®ä»¤ç‰Œ
func (as *AuthService) GenerateToken(userID string, roles []string) (string, error) {
    claims := jwt.MapClaims{
        "user_id": userID,
        "roles":   roles,
        "exp":     time.Now().Add(as.tokenExpiry).Unix(),
        "iat":     time.Now().Unix(),
    }
    
    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
    return token.SignedString(as.jwtSecret)
}

// ValidateToken éªŒè¯ä»¤ç‰Œ
func (as *AuthService) ValidateToken(tokenString string) (*jwt.MapClaims, error) {
    token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
            return nil, fmt.Errorf("unexpected signing method: %v", token.Header["alg"])
        }
        return as.jwtSecret, nil
    })
    
    if err != nil {
        return nil, err
    }
    
    if claims, ok := token.Claims.(jwt.MapClaims); ok && token.Valid {
        return &claims, nil
    }
    
    return nil, fmt.Errorf("invalid token")
}

// RateLimitMiddleware é€Ÿç‡é™åˆ¶ä¸­é—´ä»¶
func RateLimitMiddleware(limiter *RateLimiter) gin.HandlerFunc {
    return func(c *gin.Context) {
        clientIP := c.ClientIP()
        
        if err := limiter.Wait(c.Request.Context()); err != nil {
            c.JSON(http.StatusTooManyRequests, gin.H{
                "error": "Rate limit exceeded",
            })
            c.Abort()
            return
        }
        
        c.Next()
    }
}

// APIKeyMiddleware API å¯†é’¥éªŒè¯ä¸­é—´ä»¶
func APIKeyMiddleware(validKeys map[string]bool) gin.HandlerFunc {
    return func(c *gin.Context) {
        apiKey := c.GetHeader("X-API-Key")
        if apiKey == "" {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "API key required",
            })
            c.Abort()
            return
        }
        
        if !validKeys[apiKey] {
            c.JSON(http.StatusUnauthorized, gin.H{
                "error": "Invalid API key",
            })
            c.Abort()
            return
        }
        
        c.Next()
    }
}

// SecureHeaders å®‰å…¨å¤´ä¸­é—´ä»¶
func SecureHeadersMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        c.Header("X-Content-Type-Options", "nosniff")
        c.Header("X-Frame-Options", "DENY")
        c.Header("X-XSS-Protection", "1; mode=block")
        c.Header("Strict-Transport-Security", "max-age=31536000; includeSubDomains")
        c.Header("Content-Security-Policy", "default-src 'self'")
        c.Next()
    }
}
```

### 2. æ•°æ®åŠ å¯†

```go
// security/encryption.go
package security

import (
    "crypto/aes"
    "crypto/cipher"
    "crypto/rand"
    "crypto/sha256"
    "encoding/base64"
    "fmt"
    "io"
    
    "golang.org/x/crypto/pbkdf2"
)

// EncryptionService åŠ å¯†æœåŠ¡
type EncryptionService struct {
    key []byte
}

func NewEncryptionService(password string, salt []byte) *EncryptionService {
    key := pbkdf2.Key([]byte(password), salt, 10000, 32, sha256.New)
    return &EncryptionService{key: key}
}

// Encrypt åŠ å¯†æ•°æ®
func (es *EncryptionService) Encrypt(plaintext []byte) (string, error) {
    block, err := aes.NewCipher(es.key)
    if err != nil {
        return "", err
    }
    
    gcm, err := cipher.NewGCM(block)
    if err != nil {
        return "", err
    }
    
    nonce := make([]byte, gcm.NonceSize())
    if _, err := io.ReadFull(rand.Reader, nonce); err != nil {
        return "", err
    }
    
    ciphertext := gcm.Seal(nonce, nonce, plaintext, nil)
    return base64.StdEncoding.EncodeToString(ciphertext), nil
}

// Decrypt è§£å¯†æ•°æ®
func (es *EncryptionService) Decrypt(ciphertext string) ([]byte, error) {
    data, err := base64.StdEncoding.DecodeString(ciphertext)
    if err != nil {
        return nil, err
    }
    
    block, err := aes.NewCipher(es.key)
    if err != nil {
        return nil, err
    }
    
    gcm, err := cipher.NewGCM(block)
    if err != nil {
        return nil, err
    }
    
    nonceSize := gcm.NonceSize()
    if len(data) < nonceSize {
        return nil, fmt.Errorf("ciphertext too short")
    }
    
    nonce, ciphertext := data[:nonceSize], data[nonceSize:]
    return gcm.Open(nil, nonce, ciphertext, nil)
}

// SensitiveDataHandler æ•æ„Ÿæ•°æ®å¤„ç†å™¨
type SensitiveDataHandler struct {
    encryption *EncryptionService
}

func NewSensitiveDataHandler(encryption *EncryptionService) *SensitiveDataHandler {
    return &SensitiveDataHandler{encryption: encryption}
}

// MaskSensitiveData è„±æ•æ•æ„Ÿæ•°æ®
func (sdh *SensitiveDataHandler) MaskSensitiveData(data string, dataType string) string {
    switch dataType {
    case "email":
        return maskEmail(data)
    case "phone":
        return maskPhone(data)
    case "id_card":
        return maskIDCard(data)
    case "credit_card":
        return maskCreditCard(data)
    default:
        return maskDefault(data)
    }
}

func maskEmail(email string) string {
    parts := strings.Split(email, "@")
    if len(parts) != 2 {
        return "***"
    }
    
    username := parts[0]
    domain := parts[1]
    
    if len(username) <= 2 {
        return "***@" + domain
    }
    
    return username[:1] + "***" + username[len(username)-1:] + "@" + domain
}

func maskPhone(phone string) string {
    if len(phone) < 7 {
        return "***"
    }
    
    return phone[:3] + "****" + phone[len(phone)-3:]
}

func maskIDCard(idCard string) string {
    if len(idCard) < 8 {
        return "***"
    }
    
    return idCard[:4] + "**********" + idCard[len(idCard)-4:]
}

func maskCreditCard(card string) string {
    if len(card) < 8 {
        return "***"
    }
    
    return card[:4] + " **** **** " + card[len(card)-4:]
}

func maskDefault(data string) string {
    if len(data) <= 4 {
        return "***"
    }
    
    return data[:2] + "***" + data[len(data)-2:]
}
```

## ğŸ“ˆ æ€§èƒ½æµ‹è¯•ä¸ä¼˜åŒ–

### 1. åŸºå‡†æµ‹è¯•

```go
// benchmark/benchmark_test.go
package benchmark

import (
    "context"
    "testing"
    "time"
    
    "github.com/cloudwego/eino/compose"
    "github.com/cloudwego/eino/schema"
)

func BenchmarkChainExecution(b *testing.B) {
    ctx := context.Background()
    
    // åˆ›å»ºæµ‹è¯•é“¾
    chain := createTestChain()
    runnable, err := chain.Compile(ctx)
    if err != nil {
        b.Fatal(err)
    }
    
    input := "test input"
    
    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            _, err := runnable.Invoke(ctx, input)
            if err != nil {
                b.Error(err)
            }
        }
    })
}

func BenchmarkStreamProcessing(b *testing.B) {
    ctx := context.Background()
    
    // åˆ›å»ºæµå¤„ç†é“¾
    chain := createStreamChain()
    runnable, err := chain.Compile(ctx)
    if err != nil {
        b.Fatal(err)
    }
    
    input := "test stream input"
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        stream, err := runnable.Stream(ctx, input)
        if err != nil {
            b.Error(err)
            continue
        }
        
        // æ¶ˆè´¹æµæ•°æ®
        for {
            _, err := stream.Recv()
            if err == io.EOF {
                break
            }
            if err != nil {
                b.Error(err)
                break
            }
        }
        stream.Close()
    }
}

func BenchmarkConcurrentExecution(b *testing.B) {
    ctx := context.Background()
    
    chain := createTestChain()
    runnable, err := chain.Compile(ctx)
    if err != nil {
        b.Fatal(err)
    }
    
    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            input := fmt.Sprintf("test input %d", time.Now().UnixNano())
            _, err := runnable.Invoke(ctx, input)
            if err != nil {
                b.Error(err)
            }
        }
    })
}

// æ€§èƒ½åˆ†æè¾…åŠ©å‡½æ•°
func BenchmarkMemoryAllocation(b *testing.B) {
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        // æµ‹è¯•å†…å­˜åˆ†é…
        msg := &schema.Message{
            Role:    schema.User,
            Content: "test message",
            Extra:   make(map[string]any),
        }
        
        // æ¨¡æ‹Ÿå¤„ç†
        _ = processMessage(msg)
    }
}

func processMessage(msg *schema.Message) *schema.Message {
    return &schema.Message{
        Role:    schema.Assistant,
        Content: "processed: " + msg.Content,
    }
}

func createTestChain() *compose.Chain[string, string] {
    processor := compose.InvokableLambda(func(ctx context.Context, input string) (string, error) {
        return "processed: " + input, nil
    })
    
    return compose.NewChain[string, string]().
        AppendLambda("processor", processor)
}

func createStreamChain() *compose.Chain[string, string] {
    processor := compose.StreamableLambda(func(ctx context.Context, input string) (*schema.StreamReader[string], error) {
        words := strings.Fields(input)
        return schema.StreamReaderFromArray(words), nil
    })
    
    return compose.NewChain[string, string]().
        AppendLambda("processor", processor)
}
```

### 2. è´Ÿè½½æµ‹è¯•

```go
// loadtest/loadtest.go
package loadtest

import (
    "context"
    "fmt"
    "sync"
    "sync/atomic"
    "time"
)

// LoadTestConfig è´Ÿè½½æµ‹è¯•é…ç½®
type LoadTestConfig struct {
    Concurrency int           // å¹¶å‘æ•°
    Duration    time.Duration // æµ‹è¯•æŒç»­æ—¶é—´
    RampUp      time.Duration // é¢„çƒ­æ—¶é—´
    Target      string        // ç›®æ ‡åœ°å€
}

// LoadTestResult è´Ÿè½½æµ‹è¯•ç»“æœ
type LoadTestResult struct {
    TotalRequests    int64
    SuccessRequests  int64
    FailedRequests   int64
    AverageLatency   time.Duration
    MinLatency       time.Duration
    MaxLatency       time.Duration
    P95Latency       time.Duration
    P99Latency       time.Duration
    RequestsPerSecond float64
}

// LoadTester è´Ÿè½½æµ‹è¯•å™¨
type LoadTester struct {
    config  *LoadTestConfig
    client  HTTPClient
    metrics *LoadTestMetrics
}

type HTTPClient interface {
    Do(ctx context.Context, request any) (any, error)
}

type LoadTestMetrics struct {
    totalRequests   int64
    successRequests int64
    failedRequests  int64
    latencies       []time.Duration
    mu              sync.Mutex
}

func NewLoadTester(config *LoadTestConfig, client HTTPClient) *LoadTester {
    return &LoadTester{
        config:  config,
        client:  client,
        metrics: &LoadTestMetrics{},
    }
}

func (lt *LoadTester) Run(ctx context.Context) (*LoadTestResult, error) {
    fmt.Printf("Starting load test with %d concurrent users for %v\n", 
        lt.config.Concurrency, lt.config.Duration)
    
    // åˆ›å»ºå·¥ä½œåç¨‹
    var wg sync.WaitGroup
    startTime := time.Now()
    
    // é¢„çƒ­é˜¶æ®µ
    if lt.config.RampUp > 0 {
        fmt.Printf("Ramping up for %v\n", lt.config.RampUp)
        time.Sleep(lt.config.RampUp)
    }
    
    // å¯åŠ¨è´Ÿè½½æµ‹è¯•
    testCtx, cancel := context.WithTimeout(ctx, lt.config.Duration)
    defer cancel()
    
    for i := 0; i < lt.config.Concurrency; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            lt.worker(testCtx, workerID)
        }(i)
    }
    
    wg.Wait()
    endTime := time.Now()
    
    return lt.calculateResults(startTime, endTime), nil
}

func (lt *LoadTester) worker(ctx context.Context, workerID int) {
    for {
        select {
        case <-ctx.Done():
            return
        default:
            lt.executeRequest(ctx)
        }
    }
}

func (lt *LoadTester) executeRequest(ctx context.Context) {
    startTime := time.Now()
    
    atomic.AddInt64(&lt.metrics.totalRequests, 1)
    
    // æ‰§è¡Œè¯·æ±‚
    _, err := lt.client.Do(ctx, createTestRequest())
    
    latency := time.Since(startTime)
    
    lt.metrics.mu.Lock()
    lt.metrics.latencies = append(lt.metrics.latencies, latency)
    lt.metrics.mu.Unlock()
    
    if err != nil {
        atomic.AddInt64(&lt.metrics.failedRequests, 1)
    } else {
        atomic.AddInt64(&lt.metrics.successRequests, 1)
    }
}

func (lt *LoadTester) calculateResults(startTime, endTime time.Time) *LoadTestResult {
    duration := endTime.Sub(startTime)
    
    lt.metrics.mu.Lock()
    latencies := make([]time.Duration, len(lt.metrics.latencies))
    copy(latencies, lt.metrics.latencies)
    lt.metrics.mu.Unlock()
    
    // æ’åºå»¶è¿Ÿæ•°æ®
    sort.Slice(latencies, func(i, j int) bool {
        return latencies[i] < latencies[j]
    })
    
    var avgLatency time.Duration
    if len(latencies) > 0 {
        var total time.Duration
        for _, lat := range latencies {
            total += lat
        }
        avgLatency = total / time.Duration(len(latencies))
    }
    
    result := &LoadTestResult{
        TotalRequests:     atomic.LoadInt64(&lt.metrics.totalRequests),
        SuccessRequests:   atomic.LoadInt64(&lt.metrics.successRequests),
        FailedRequests:    atomic.LoadInt64(&lt.metrics.failedRequests),
        AverageLatency:    avgLatency,
        RequestsPerSecond: float64(atomic.LoadInt64(&lt.metrics.totalRequests)) / duration.Seconds(),
    }
    
    if len(latencies) > 0 {
        result.MinLatency = latencies[0]
        result.MaxLatency = latencies[len(latencies)-1]
        result.P95Latency = latencies[int(float64(len(latencies))*0.95)]
        result.P99Latency = latencies[int(float64(len(latencies))*0.99)]
    }
    
    return result
}

func createTestRequest() any {
    return map[string]any{
        "message": "test message",
        "user_id": "test_user",
    }
}
```

## ğŸ¯ æ€»ç»“

æœ¬æ–‡æ¡£æ¶µç›–äº† Eino æ¡†æ¶åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬ï¼š

1. **æ¶æ„è®¾è®¡**: åˆ†å±‚æ¶æ„ã€æœåŠ¡è®¾è®¡ã€é…ç½®ç®¡ç†
2. **ç»„ä»¶å¼€å‘**: è‡ªå®šä¹‰ç»„ä»¶ã€Lambdaå‡½æ•°ã€é”™è¯¯å¤„ç†
3. **æ€§èƒ½ä¼˜åŒ–**: å†…å­˜ç®¡ç†ã€å¹¶å‘æ§åˆ¶ã€ç¼“å­˜ç­–ç•¥
4. **ç›‘æ§è¿ç»´**: æŒ‡æ ‡æ”¶é›†ã€é“¾è·¯è¿½è¸ªã€æ—¥å¿—è®°å½•
5. **éƒ¨ç½²è¿ç»´**: å®¹å™¨åŒ–ã€Kubernetesã€CI/CD
6. **å®‰å…¨å®è·µ**: è®¤è¯æˆæƒã€æ•°æ®åŠ å¯†ã€å®‰å…¨é˜²æŠ¤
7. **æ€§èƒ½æµ‹è¯•**: åŸºå‡†æµ‹è¯•ã€è´Ÿè½½æµ‹è¯•ã€æ€§èƒ½åˆ†æ

éµå¾ªè¿™äº›æœ€ä½³å®è·µï¼Œå¯ä»¥å¸®åŠ©æ‚¨æ„å»ºé«˜æ€§èƒ½ã€å¯é ã€å®‰å…¨çš„ LLM åº”ç”¨ç³»ç»Ÿã€‚

---

**ä¸Šä¸€ç¯‡**: [å…³é”®æ•°æ®ç»“æ„ä¸ç»§æ‰¿å…³ç³»](eino-09-data-structures.md)

**æ›´æ–°æ—¶é—´**: 2024-12-19 | **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
