---
title: "Python3 æ ¸å¿ƒå®¹å™¨æ·±åº¦æºç åˆ†æ"
date: 2025-09-28T01:46:41+08:00
draft: false
tags: ['æºç åˆ†æ', 'Python']
categories: ['Python']
description: "Python3 æ ¸å¿ƒå®¹å™¨æ·±åº¦æºç åˆ†æçš„æ·±å…¥æŠ€æœ¯åˆ†ææ–‡æ¡£"
keywords: ['æºç åˆ†æ', 'Python']
author: "æŠ€æœ¯åˆ†æå¸ˆ"
weight: 1
---

## ğŸ“‹ æ¦‚è¿°

Pythonçš„æ ¸å¿ƒå®¹å™¨ï¼ˆlistã€dictã€set/frozensetã€tupleï¼‰æ˜¯Pythonç¼–ç¨‹çš„åŸºç¡€æ•°æ®ç»“æ„ã€‚æœ¬æ–‡æ¡£å°†æ·±å…¥åˆ†æCPythonä¸­è¿™äº›å®¹å™¨çš„å®ç°æœºåˆ¶ï¼ŒåŒ…æ‹¬å†…å­˜å¸ƒå±€ã€ç®—æ³•ä¼˜åŒ–ã€åŠ¨æ€æ‰©å±•ç­–ç•¥ã€ä»¥åŠæ€§èƒ½ç‰¹å¾ï¼Œå¸®åŠ©å¼€å‘è€…ç†è§£Pythonå®¹å™¨çš„å†…éƒ¨å·¥ä½œåŸç†ã€‚

## ğŸ¯ æ ¸å¿ƒå®¹å™¨ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    subgraph "å®¹å™¨ç±»å‹å±‚æ¬¡"
        A[PyObjectåŸºç±»] --> B[PyVarObjectå˜é•¿å¯¹è±¡]
        B --> C[PyListObject]
        B --> D[PyTupleObject]
        A --> E[PyDictObject]
        A --> F[PySetObject]
        A --> G[PyFrozenSetObject]
    end

    subgraph "å†…å­˜å¸ƒå±€"
        H[å¯¹è±¡å¤´] --> I[å¼•ç”¨è®¡æ•°+ç±»å‹]
        I --> J[å®¹å™¨ç‰¹å®šå­—æ®µ]
        J --> K[æ•°æ®å­˜å‚¨åŒº]
    end

    subgraph "ç®—æ³•æ ¸å¿ƒ"
        L[åŠ¨æ€æ•°ç»„] --> M[list/tuple]
        N[å“ˆå¸Œè¡¨] --> O[dict/set]
        P[å¼€æ”¾å¯»å€] --> N
        Q[Perturbç®—æ³•] --> P
    end

    C --> L
    D --> L
    E --> N
    F --> N
    G --> N
```

## 1. Listå®¹å™¨æ·±åº¦å®ç°

### 1.1 Listå†…éƒ¨ç»“æ„ä¸å†…å­˜å¸ƒå±€

```c
/* Objects/listobject.c - PyListObjectç»“æ„å®šä¹‰ */

typedef struct {
    PyVarObject ob_base;        /* å˜é•¿å¯¹è±¡å¤´ */
    PyObject **ob_item;         /* æŒ‡å‘å…ƒç´ æ•°ç»„çš„æŒ‡é’ˆ */
    Py_ssize_t allocated;       /* å·²åˆ†é…çš„æ§½ä½æ•° */
} PyListObject;

/*
 * Listå†…å­˜å¸ƒå±€ç¤ºæ„ï¼š
 *
 * PyListObject:
 * +-------------------+
 * | PyVarObject       | <- å¯¹è±¡å¤´(å¼•ç”¨è®¡æ•°ã€ç±»å‹ã€å¤§å°)
 * | ob_item ----------|----> +----------+
 * | allocated         |      | PyObject*| <- å…ƒç´ 0
 * +-------------------+      | PyObject*| <- å…ƒç´ 1
 *                            | PyObject*| <- å…ƒç´ 2
 *                            |   ...    |
 *                            | NULL     | <- æœªä½¿ç”¨æ§½ä½
 *                            | NULL     |
 *                            +----------+
 */

/* Liståˆ›å»ºå‡½æ•° */
PyObject *
PyList_New(Py_ssize_t size)
{
    if (size < 0) {
        PyErr_BadInternalCall();
        return NULL;
    }

    /* ä»ç©ºé—²åˆ—è¡¨è·å–æˆ–åˆ†é…æ–°çš„PyListObject */
    PyListObject *op = _Py_FREELIST_POP(PyListObject, lists);
    if (op == NULL) {
        op = PyObject_GC_New(PyListObject, &PyList_Type);
        if (op == NULL) {
            return NULL;
        }
    }

    if (size <= 0) {
        /* ç©ºåˆ—è¡¨ï¼šä¸åˆ†é…å…ƒç´ æ•°ç»„ */
        op->ob_item = NULL;
    }
    else {
        /* åˆ†é…å…ƒç´ æ•°ç»„ */
#ifdef Py_GIL_DISABLED
        /* æ— GILæ¨¡å¼ï¼šä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ•°ç»„åˆ†é… */
        _PyListArray *array = list_allocate_array(size);
        if (array == NULL) {
            Py_DECREF(op);
            return PyErr_NoMemory();
        }
        memset(&array->ob_item, 0, size * sizeof(PyObject *));
        op->ob_item = array->ob_item;
#else
        /* æ ‡å‡†æ¨¡å¼ï¼šç›´æ¥åˆ†é… */
        op->ob_item = (PyObject **) PyMem_Calloc(size, sizeof(PyObject *));
#endif
        if (op->ob_item == NULL) {
            Py_DECREF(op);
            return PyErr_NoMemory();
        }
    }

    /* è®¾ç½®åˆ—è¡¨å¤§å°å’Œåˆ†é…å¤§å° */
    Py_SET_SIZE(op, size);
    op->allocated = size;

    /* å¼€å¯åƒåœ¾å›æ”¶è·Ÿè¸ª */
    _PyObject_GC_TRACK(op);
    return (PyObject *) op;
}

/* ListåŠ¨æ€æ‰©å±•ç®—æ³• */
static int
list_resize(PyListObject *self, Py_ssize_t newsize)
{
    Py_ssize_t new_allocated, num_allocated_bytes;
    size_t new_allocated_bytes;

    /* å¿«é€Ÿè·¯å¾„ï¼šå¤§å°æ²¡æœ‰è¶…å‡ºå·²åˆ†é…ç©ºé—´ */
    if (newsize <= self->allocated && newsize >= (self->allocated >> 1)) {
        assert(self->ob_item != NULL || newsize == 0);
        Py_SET_SIZE(self, newsize);
        return 0;
    }

    /*
     * åŠ¨æ€æ‰©å±•ç­–ç•¥ï¼š
     * æ–°åˆ†é…å¤§å° = newsize + (newsize >> 3) + (newsize < 9 ? 3 : 6)
     *
     * è¿™ä¸ªå…¬å¼çš„è®¾è®¡ç†å¿µï¼š
     * 1. ä¸ºå°åˆ—è¡¨æä¾›é¢å¤–çš„3-6ä¸ªæ§½ä½
     * 2. ä¸ºå¤§åˆ—è¡¨æŒ‰12.5%çš„æ¯”ä¾‹å¢é•¿
     * 3. å¹³è¡¡å†…å­˜ä½¿ç”¨å’Œé‡æ–°åˆ†é…é¢‘ç‡
     */
    new_allocated = (size_t)newsize + (newsize >> 3) + (newsize < 9 ? 3 : 6);

    /* æ£€æŸ¥æ•´æ•°æº¢å‡º */
    if (new_allocated > (size_t)PY_SSIZE_T_MAX / sizeof(PyObject *)) {
        PyErr_NoMemory();
        return -1;
    }

    if (newsize == 0) {
        /* ç¼©å‡åˆ°ç©ºåˆ—è¡¨ */
        PyMem_Free(self->ob_item);
        self->ob_item = NULL;
        Py_SET_SIZE(self, 0);
        self->allocated = 0;
        return 0;
    }

    /* é‡æ–°åˆ†é…å†…å­˜ */
    new_allocated_bytes = new_allocated * sizeof(PyObject *);
    PyObject **items = (PyObject **)PyMem_Realloc(self->ob_item, new_allocated_bytes);
    if (items == NULL) {
        PyErr_NoMemory();
        return -1;
    }

    self->ob_item = items;
    Py_SET_SIZE(self, newsize);
    self->allocated = new_allocated;
    return 0;
}

/* Listæ’å…¥æ“ä½œå®ç° */
static int
ins1(PyListObject *self, Py_ssize_t where, PyObject *v)
{
    Py_ssize_t i, n = Py_SIZE(self);
    PyObject **items;

    if (v == NULL) {
        PyErr_BadInternalCall();
        return -1;
    }

    /* è¾¹ç•Œæ£€æŸ¥ */
    if (where < 0) {
        where += n;
        if (where < 0)
            where = 0;
    }
    if (where > n)
        where = n;

    /* æ‰©å±•åˆ—è¡¨å¤§å° */
    if (list_resize(self, n+1) < 0)
        return -1;

    /* ç§»åŠ¨å…ƒç´ ä¸ºæ–°å…ƒç´ è…¾å‡ºç©ºé—´ */
    items = self->ob_item;
    for (i = n; --i >= where; )
        items[i+1] = items[i];

    /* æ’å…¥æ–°å…ƒç´  */
    Py_INCREF(v);
    items[where] = v;
    return 0;
}

/* Liståˆ‡ç‰‡æ“ä½œ */
static PyObject *
list_subscript(PyListObject* self, PyObject* item)
{
    if (_PyIndex_Check(item)) {
        /* å•ä¸ªç´¢å¼•è®¿é—® */
        Py_ssize_t i = PyNumber_AsSsize_t(item, PyExc_IndexError);
        if (i == -1 && PyErr_Occurred())
            return NULL;
        if (i < 0)
            i += PyList_GET_SIZE(self);
        return list_item(self, i);
    }
    else if (PySlice_Check(item)) {
        /* åˆ‡ç‰‡è®¿é—® */
        Py_ssize_t start, stop, step, slicelength;

        if (PySlice_Unpack(item, &start, &stop, &step) < 0) {
            return NULL;
        }
        slicelength = PySlice_AdjustIndices(Py_SIZE(self), &start, &stop, step);

        if (slicelength <= 0) {
            return PyList_New(0);
        }
        else if (step == 1) {
            /* è¿ç»­åˆ‡ç‰‡ï¼šä¼˜åŒ–è·¯å¾„ */
            return list_slice(self, start, stop);
        }
        else {
            /* æ­¥é•¿åˆ‡ç‰‡ï¼šé€ä¸ªå¤åˆ¶ */
            PyListObject *result = (PyListObject *)PyList_New(slicelength);
            if (!result) return NULL;

            PyObject **src = self->ob_item;
            PyObject **dest = result->ob_item;

            for (Py_ssize_t cur = start, i = 0; i < slicelength;
                 cur += step, i++) {
                PyObject *it = src[cur];
                Py_INCREF(it);
                dest[i] = it;
            }
            return (PyObject *)result;
        }
    }
    else {
        PyErr_Format(PyExc_TypeError,
                     "list indices must be integers or slices, not %.200s",
                     Py_TYPE(item)->tp_name);
        return NULL;
    }
}
```

### 1.2 Listæ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

```python
# Listæ€§èƒ½ç‰¹å¾åˆ†æå’Œä¼˜åŒ–æ¼”ç¤º
import sys
import time
import gc
from typing import List, Any

class ListPerformanceAnalyzer:
    """Listæ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.test_results = {}

    def analyze_memory_layout(self):
        """åˆ†æListå†…å­˜å¸ƒå±€"""

        print("=== Listå†…å­˜å¸ƒå±€åˆ†æ ===")

        # ç©ºåˆ—è¡¨çš„å†…å­˜å¼€é”€
        empty_list = []
        empty_size = sys.getsizeof(empty_list)
        print(f"ç©ºåˆ—è¡¨å†…å­˜: {empty_size} bytes")

        # ä¸åŒå¤§å°åˆ—è¡¨çš„å†…å­˜ä½¿ç”¨
        sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]

        print(f"åˆ—è¡¨å¤§å° -> å†…å­˜ä½¿ç”¨ (bytes) -> æ¯å…ƒç´ å¼€é”€ (bytes)")
        for size in sizes:
            test_list = [None] * size
            total_memory = sys.getsizeof(test_list)
            # è®¡ç®—å…ƒç´ æŒ‡é’ˆæ•°ç»„çš„å¤§å°
            element_array_size = size * 8  # 64ä½ç³»ç»Ÿä¸ŠæŒ‡é’ˆæ˜¯8å­—èŠ‚
            overhead = total_memory - element_array_size
            per_element = total_memory / size if size > 0 else 0

            print(f"{size:4d} -> {total_memory:6d} -> {per_element:5.1f}")

        # åˆ†æåˆ—è¡¨çš„åŠ¨æ€æ‰©å±•
        print(f"\nåˆ—è¡¨åŠ¨æ€æ‰©å±•ç­–ç•¥åˆ†æ:")
        test_list = []
        last_capacity = 0

        for i in range(20):
            test_list.append(i)
            # é€šè¿‡å†…å­˜å¤§å°æ¨ç®—å®¹é‡
            current_memory = sys.getsizeof(test_list)
            estimated_capacity = (current_memory - empty_size) // 8

            if estimated_capacity != last_capacity:
                print(f"å…ƒç´ æ•°: {i+1:2d}, ä¼°ç®—å®¹é‡: {estimated_capacity:2d}, "
                      f"æ‰©å±•æ¯”ä¾‹: {estimated_capacity / (i+1):.2f}")
                last_capacity = estimated_capacity

    def benchmark_operations(self):
        """åŸºå‡†æµ‹è¯•å„ç§æ“ä½œ"""

        print(f"\n=== Listæ“ä½œæ€§èƒ½åŸºå‡†æµ‹è¯• ===")

        # æµ‹è¯•æ•°æ®
        test_sizes = [1000, 10000, 100000]

        for size in test_sizes:
            print(f"\næµ‹è¯•å¤§å°: {size:,} å…ƒç´ ")

            # 1. è¿½åŠ æ“ä½œæ€§èƒ½
            def test_append():
                test_list = []
                start = time.perf_counter()
                for i in range(size):
                    test_list.append(i)
                return time.perf_counter() - start

            append_time = test_append()
            print(f"  appendæ“ä½œ: {append_time:.4f}s ({size/append_time/1000:.1f}K ops/s)")

            # 2. é¢„åˆ†é…vsåŠ¨æ€å¢é•¿
            def test_prealloc():
                start = time.perf_counter()
                test_list = [None] * size
                for i in range(size):
                    test_list[i] = i
                return time.perf_counter() - start

            prealloc_time = test_prealloc()
            print(f"  é¢„åˆ†é…+èµ‹å€¼: {prealloc_time:.4f}s ({size/prealloc_time/1000:.1f}K ops/s)")
            print(f"  é¢„åˆ†é…ä¼˜åŠ¿: {append_time/prealloc_time:.1f}x")

            # 3. æ’å…¥æ“ä½œæ€§èƒ½
            test_list = list(range(size))

            def test_insert_head():
                start = time.perf_counter()
                for i in range(min(1000, size//10)):  # é¿å…è¿‡åº¦æµ‹è¯•
                    test_list.insert(0, -i)
                return time.perf_counter() - start

            insert_time = test_insert_head()
            operations = min(1000, size//10)
            print(f"  å¤´éƒ¨æ’å…¥: {insert_time:.4f}s ({operations/insert_time:.1f} ops/s)")

            # 4. åˆ‡ç‰‡æ“ä½œæ€§èƒ½
            def test_slice():
                start = time.perf_counter()
                for _ in range(100):
                    _ = test_list[size//4:3*size//4]  # ä¸­é—´50%åˆ‡ç‰‡
                return time.perf_counter() - start

            slice_time = test_slice()
            print(f"  åˆ‡ç‰‡æ“ä½œ: {slice_time:.4f}s ({100/slice_time:.1f} ops/s)")

            # 5. æŸ¥æ‰¾æ“ä½œæ€§èƒ½
            def test_index():
                start = time.perf_counter()
                for i in range(min(1000, size//10)):
                    try:
                        test_list.index(size - 1 - i)  # æŸ¥æ‰¾æœ«å°¾å…ƒç´ 
                    except ValueError:
                        pass
                return time.perf_counter() - start

            index_time = test_index()
            print(f"  indexæŸ¥æ‰¾: {index_time:.4f}s ({min(1000, size//10)/index_time:.1f} ops/s)")

    def analyze_memory_patterns(self):
        """åˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼"""

        print(f"\n=== Listå†…å­˜ä½¿ç”¨æ¨¡å¼åˆ†æ ===")

        # 1. å¼•ç”¨vsæ‹·è´
        original_list = list(range(10000))

        print("å¼•ç”¨ vs æ‹·è´å†…å­˜å¯¹æ¯”:")

        # æµ…æ‹·è´
        shallow_copy = original_list[:]
        print(f"  åŸåˆ—è¡¨å†…å­˜: {sys.getsizeof(original_list):,} bytes")
        print(f"  æµ…æ‹·è´å†…å­˜: {sys.getsizeof(shallow_copy):,} bytes")

        # å¼•ç”¨åŒä¸€æ•°æ®
        reference = original_list
        print(f"  å¼•ç”¨å†…å­˜: {sys.getsizeof(reference):,} bytes")

        # 2. å†…å­˜ç¢ç‰‡åˆ†æ
        print(f"\nå†…å­˜ç¢ç‰‡åˆ†æ:")

        # åˆ›å»ºå¤§é‡å°åˆ—è¡¨
        small_lists = []
        for i in range(1000):
            small_lists.append([i] * 10)

        # åˆ›å»ºå°‘é‡å¤§åˆ—è¡¨
        large_lists = []
        for i in range(10):
            large_lists.append([i] * 1000)

        small_total = sum(sys.getsizeof(lst) for lst in small_lists)
        large_total = sum(sys.getsizeof(lst) for lst in large_lists)

        print(f"  1000ä¸ªå°åˆ—è¡¨(10å…ƒç´ ): {small_total:,} bytes")
        print(f"  10ä¸ªå¤§åˆ—è¡¨(1000å…ƒç´ ): {large_total:,} bytes")
        print(f"  å°åˆ—è¡¨å¼€é”€æ¯”ä¾‹: {(small_total/large_total - 1)*100:.1f}%")

        # 3. å†…å­˜é‡Šæ”¾æ¨¡å¼
        print(f"\nå†…å­˜é‡Šæ”¾æ¨¡å¼:")

        gc_before = gc.collect()

        # åˆ›å»ºå¾ªç¯å¼•ç”¨
        circular_lists = []
        for i in range(100):
            lst = [None] * 100
            lst[0] = lst  # åˆ›å»ºå¾ªç¯å¼•ç”¨
            circular_lists.append(lst)

        del circular_lists
        gc_after = gc.collect()

        print(f"  åƒåœ¾å›æ”¶æ¸…ç†å¯¹è±¡: {gc_after} ä¸ª")

    def demonstrate_optimization_techniques(self):
        """æ¼”ç¤ºä¼˜åŒ–æŠ€æœ¯"""

        print(f"\n=== Listä¼˜åŒ–æŠ€æœ¯æ¼”ç¤º ===")

        size = 100000

        # 1. åˆ—è¡¨æ¨å¯¼å¼ vs å¾ªç¯
        def test_list_comprehension():
            start = time.perf_counter()
            result = [i * 2 for i in range(size)]
            return time.perf_counter() - start

        def test_loop_append():
            start = time.perf_counter()
            result = []
            for i in range(size):
                result.append(i * 2)
            return time.perf_counter() - start

        comp_time = test_list_comprehension()
        loop_time = test_loop_append()

        print(f"åˆ—è¡¨æ¨å¯¼å¼: {comp_time:.4f}s")
        print(f"å¾ªç¯è¿½åŠ : {loop_time:.4f}s")
        print(f"æ¨å¯¼å¼ä¼˜åŠ¿: {loop_time/comp_time:.1f}x")

        # 2. é¢„åˆ†é…ä¼˜åŒ–
        def test_extend():
            start = time.perf_counter()
            result = []
            result.extend(range(size))
            return time.perf_counter() - start

        extend_time = test_extend()
        print(f"extendæ–¹æ³•: {extend_time:.4f}s")
        print(f"extend vs æ¨å¯¼å¼: {comp_time/extend_time:.1f}x")

        # 3. å†…å­˜è§†å›¾ä¼˜åŒ–
        import array

        def test_array():
            start = time.perf_counter()
            result = array.array('i', range(size))
            return time.perf_counter() - start

        array_time = test_array()
        print(f"array.array: {array_time:.4f}s")

        # å†…å­˜ä½¿ç”¨å¯¹æ¯”
        list_obj = list(range(1000))
        array_obj = array.array('i', range(1000))

        print(f"\nå†…å­˜ä½¿ç”¨å¯¹æ¯” (1000ä¸ªæ•´æ•°):")
        print(f"  list: {sys.getsizeof(list_obj):,} bytes")
        print(f"  array: {sys.getsizeof(array_obj):,} bytes")
        print(f"  arrayèŠ‚çœ: {(1 - sys.getsizeof(array_obj)/sys.getsizeof(list_obj))*100:.1f}%")

    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""

        print("Python Listå®¹å™¨æ·±åº¦æ€§èƒ½åˆ†æ\n")

        self.analyze_memory_layout()
        self.benchmark_operations()
        self.analyze_memory_patterns()
        self.demonstrate_optimization_techniques()

        print(f"\n{'='*50}")
        print("Liståˆ†æå®Œæˆ")
        print(f"{'='*50}")

# è¿è¡ŒListåˆ†æ
if __name__ == "__main__":
    analyzer = ListPerformanceAnalyzer()
    analyzer.run_analysis()
```

## 2. Dictå®¹å™¨æ·±åº¦å®ç°

### 2.1 Dictå“ˆå¸Œè¡¨ç»“æ„

```c
/* Objects/dictobject.c - PyDictObjectç»“æ„å®šä¹‰ */

/*
 * Pythonå­—å…¸é‡‡ç”¨å¼€æ”¾å¯»å€çš„å“ˆå¸Œè¡¨å®ç°
 *
 * æ ¸å¿ƒæ€æƒ³ï¼š
 * 1. åˆ†ç¦»ç´¢å¼•è¡¨å’Œæ¡ç›®è¡¨ï¼Œæé«˜ç¼“å­˜å±€éƒ¨æ€§
 * 2. ä½¿ç”¨Perturbç®—æ³•å‡å°‘èšé›†
 * 3. ä¿æŒæ’å…¥é¡ºåºï¼ˆä»Python 3.7å¼€å§‹ï¼‰
 */

typedef struct {
    PyObject_HEAD

    /* å·²ä½¿ç”¨çš„æ¡ç›®æ•° */
    Py_ssize_t ma_used;

    /* é”®è¡¨æŒ‡é’ˆ */
    PyDictKeysObject *ma_keys;

    /* å€¼æ•°ç»„æŒ‡é’ˆï¼ˆç”¨äºåˆ†ç¦»é”®å€¼çš„å­—å…¸ï¼‰ */
    PyDictValues *ma_values;

    /* ç›‘è§†å™¨æ ‡ç­¾ */
    uint8_t _ma_watcher_tag;
} PyDictObject;

/* é”®è¡¨ç»“æ„ */
typedef struct {
    Py_ssize_t dk_refcnt;       /* å¼•ç”¨è®¡æ•° */
    uint8_t dk_log2_size;       /* log2(dk_size) */
    uint8_t dk_log2_index_bytes; /* log2(index_table_entry_size) */
    uint8_t dk_kind;            /* å­—å…¸ç±»å‹æ ‡å¿— */
    uint32_t dk_version;        /* ç‰ˆæœ¬å·ï¼Œç”¨äºä¼˜åŒ– */
    Py_ssize_t dk_usable;       /* å¯ç”¨æ¡ç›®æ•° */
    Py_ssize_t dk_nentries;     /* å·²ä½¿ç”¨æ¡ç›®æ•° */

    /*
     * å†…å­˜å¸ƒå±€ï¼š
     * dk_indices[dk_size]      <- ç´¢å¼•è¡¨
     * dk_entries[dk_usable]    <- æ¡ç›®è¡¨
     */
    char dk_indices[];          /* å¯å˜å¤§å°çš„ç´¢å¼•+æ¡ç›®æ•°æ® */
} PyDictKeysObject;

/* Unicodeå­—ç¬¦ä¸²ä¼˜åŒ–çš„æ¡ç›®ç»“æ„ */
typedef struct {
    PyObject *me_key;           /* é”®å¯¹è±¡ */
    PyObject *me_value;         /* å€¼å¯¹è±¡ */
} PyDictUnicodeEntry;

/* é€šç”¨æ¡ç›®ç»“æ„ */
typedef struct {
    Py_hash_t me_hash;          /* é”®çš„å“ˆå¸Œå€¼ */
    PyObject *me_key;           /* é”®å¯¹è±¡ */
    PyObject *me_value;         /* å€¼å¯¹è±¡ */
} PyDictKeyEntry;

/* å­—å…¸åˆ›å»ºå‡½æ•° */
PyObject *
PyDict_New(void)
{
    /* ä½¿ç”¨ç©ºé”®è¡¨åˆ›å»ºæ–°å­—å…¸ */
    return new_dict(Py_EMPTY_KEYS, NULL, 0, 0);
}

/* é€šç”¨å­—å…¸åˆ›å»ºå‡½æ•° */
static PyObject *
new_dict(PyDictKeysObject *keys, PyDictValues *values,
         Py_ssize_t used, int free_values_on_failure)
{
    assert(keys != NULL);

    /* ä»ç©ºé—²åˆ—è¡¨è·å–æˆ–åˆ†é…æ–°çš„PyDictObject */
    PyDictObject *mp = _Py_FREELIST_POP(PyDictObject, dicts);
    if (mp == NULL) {
        mp = PyObject_GC_New(PyDictObject, &PyDict_Type);
        if (mp == NULL) {
            dictkeys_decref(keys, false);
            if (free_values_on_failure) {
                free_values(values, false);
            }
            return NULL;
        }
    }

    assert(Py_IS_TYPE(mp, &PyDict_Type));
    mp->ma_keys = keys;
    mp->ma_values = values;
    mp->ma_used = used;
    mp->_ma_watcher_tag = 0;

    /* å¼€å¯åƒåœ¾å›æ”¶è·Ÿè¸ª */
    _PyObject_GC_TRACK(mp);
    return (PyObject *)mp;
}

/* å“ˆå¸ŒæŸ¥æ‰¾å®ç° - æ ¸å¿ƒç®—æ³• */
static Py_ssize_t
lookdict_index(PyDictKeysObject *k, Py_hash_t hash, Py_ssize_t index)
{
    size_t mask = DK_MASK(k);
    size_t perturb = (size_t)hash;
    size_t i = (size_t)hash & mask;

    for (;;) {
        Py_ssize_t ix = dictkeys_get_index(k, i);
        if (ix == DKIX_EMPTY) {
            /* æ‰¾åˆ°ç©ºæ§½ */
            return DKIX_EMPTY;
        }
        if (ix >= 0) {
            /* æ‰¾åˆ°å·²ä½¿ç”¨çš„æ§½ */
            if (ix == index) {
                return index;
            }
        }

        /* ä½¿ç”¨Perturbç®—æ³•è®¡ç®—ä¸‹ä¸€ä¸ªæ¢æµ‹ä½ç½® */
        perturb >>= PERTURB_SHIFT;
        i = (i*5 + 1 + perturb) & mask;
    }
}

/* Unicodeå­—ç¬¦ä¸²ç‰¹åŒ–çš„æŸ¥æ‰¾å‡½æ•° */
static Py_ssize_t
unicodekeys_lookup_unicode(PyDictKeysObject* dk, PyObject *key, Py_hash_t hash)
{
    /*
     * Unicodeå­—å…¸çš„ä¼˜åŒ–æŸ¥æ‰¾ï¼š
     * 1. è·³è¿‡å“ˆå¸Œå€¼æ¯”è¾ƒï¼ˆå·²çŸ¥ä¸ºUnicodeï¼‰
     * 2. ä½¿ç”¨æ›´ç®€å•çš„å­—ç¬¦ä¸²æ¯”è¾ƒ
     * 3. åˆ©ç”¨å­—ç¬¦ä¸²é©»ç•™ä¼˜åŒ–
     */

    assert(PyUnicode_CheckExact(key));

    PyDictUnicodeEntry *ep0 = DK_UNICODE_ENTRIES(dk);
    size_t mask = DK_MASK(dk);
    size_t perturb = hash;
    size_t i = (size_t)hash & mask;

    for (;;) {
        Py_ssize_t ix = dictkeys_get_index(dk, i);
        if (ix == DKIX_EMPTY) {
            return DKIX_EMPTY;
        }
        if (ix >= 0) {
            PyDictUnicodeEntry *ep = &ep0[ix];
            assert(ep->me_key != NULL);

            if (ep->me_key == key) {
                /* å¯¹è±¡èº«ä»½ç›¸ç­‰ï¼ˆå­—ç¬¦ä¸²é©»ç•™ï¼‰ */
                return ix;
            }

            if (PyUnicode_CheckExact(ep->me_key)) {
                if (unicode_get_hash(ep->me_key) == hash) {
                    /* å“ˆå¸Œå€¼ç›¸ç­‰ï¼Œè¿›è¡Œå­—ç¬¦ä¸²æ¯”è¾ƒ */
                    int cmp = unicode_eq(ep->me_key, key);
                    if (cmp < 0) {
                        return DKIX_ERROR;
                    }
                    if (cmp > 0) {
                        return ix;
                    }
                }
            }
        }

        /* ç»§ç»­æ¢æµ‹ */
        perturb >>= PERTURB_SHIFT;
        i = (i*5 + 1 + perturb) & mask;
    }
}

/* å­—å…¸æ’å…¥/æ›´æ–°æ“ä½œ */
static int
insertdict(PyDictObject *mp, PyObject *key, Py_hash_t hash, PyObject *value)
{
    PyObject *old_value;
    PyDictKeysObject *dk;
    Py_ssize_t ix;

    /* ç¡®ä¿å­—å…¸å¯å†™ */
    if (mp->ma_values != NULL && !PyUnicode_CheckExact(key)) {
        if (insertion_resize(mp, 1) < 0) {
            return -1;
        }
    }

    dk = mp->ma_keys;
    assert(dk != NULL);

    /* æŸ¥æ‰¾æ’å…¥ä½ç½® */
    if (DK_IS_UNICODE(dk) && PyUnicode_CheckExact(key)) {
        ix = unicodekeys_lookup_unicode(dk, key, hash);
    }
    else {
        ix = lookdict(mp, key, hash, &old_value);
    }

    if (ix == DKIX_ERROR) {
        return -1;
    }

    if (ix == DKIX_EMPTY) {
        /* æ–°é”®ï¼šéœ€è¦æ’å…¥æ–°æ¡ç›® */
        uint64_t new_version = _PyDict_NotifyEvent(
            mp, PyDict_EVENT_ADDED, key, value);
        return insert_to_emptydict(mp, key, hash, value, new_version);
    }

    /* æ›´æ–°ç°æœ‰é”®çš„å€¼ */
    if (DK_IS_UNICODE(dk)) {
        PyDictUnicodeEntry *ep = &DK_UNICODE_ENTRIES(dk)[ix];
        old_value = ep->me_value;
        ep->me_value = value;
    }
    else {
        PyDictKeyEntry *ep = &DK_ENTRIES(dk)[ix];
        old_value = ep->me_value;
        ep->me_value = value;
    }

    /* é‡Šæ”¾æ—§å€¼ï¼Œå¢åŠ æ–°å€¼å¼•ç”¨ */
    Py_XDECREF(old_value);
    Py_INCREF(value);

    _PyDict_NotifyEvent(mp, PyDict_EVENT_MODIFIED, key, value);
    return 0;
}

/* å­—å…¸æ‰©å®¹ç­–ç•¥ */
static int
dictresize(PyDictObject *mp, uint8_t log2_newsize, int unicode)
{
    PyDictKeysObject *oldkeys;
    PyDictValues *oldvalues;

    oldkeys = mp->ma_keys;
    oldvalues = mp->ma_values;

    /* åˆ†é…æ–°çš„é”®è¡¨ */
    PyDictKeysObject *newkeys = new_keys_object(
        1 << log2_newsize, unicode);
    if (newkeys == NULL) {
        return -1;
    }

    /*
     * å­—å…¸æ‰©å®¹ç­–ç•¥ï¼š
     * 1. å°å­—å…¸(< 50000): 4å€å¢é•¿
     * 2. å¤§å­—å…¸: 2å€å¢é•¿
     * 3. ä¿æŒè´Ÿè½½å› å­åœ¨2/3ä»¥ä¸‹
     */

    if (oldvalues != NULL) {
        /* åˆ†ç¦»é”®å€¼å­—å…¸çš„å¤åˆ¶ */
        if (copy_values_to_keys(mp, newkeys) < 0) {
            dictkeys_decref(newkeys, unicode);
            return -1;
        }
        mp->ma_values = NULL;
    }
    else {
        /* åˆå¹¶é”®å€¼å­—å…¸çš„å¤åˆ¶ */
        if (copy_entries_to_keys(oldkeys, newkeys) < 0) {
            dictkeys_decref(newkeys, unicode);
            return -1;
        }
    }

    /* åˆ‡æ¢åˆ°æ–°é”®è¡¨ */
    mp->ma_keys = newkeys;
    dictkeys_decref(oldkeys, DK_IS_UNICODE(oldkeys));

    if (oldvalues != NULL) {
        free_values(oldvalues, false);
    }

    return 0;
}
```

### 2.2 Dictæ€§èƒ½ä¼˜åŒ–ä¸ç‰¹æ®ŠåŒ–

```python
# Dictæ€§èƒ½åˆ†æå’Œä¼˜åŒ–æ¼”ç¤º
import sys
import time
import string
import random
from typing import Dict, Any

class DictPerformanceAnalyzer:
    """Dictæ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.test_results = {}

    def analyze_hash_distribution(self):
        """åˆ†æå“ˆå¸Œåˆ†å¸ƒè´¨é‡"""

        print("=== Dictå“ˆå¸Œåˆ†å¸ƒåˆ†æ ===")

        # 1. å­—ç¬¦ä¸²é”®çš„å“ˆå¸Œåˆ†å¸ƒ
        string_keys = [f"key_{i}" for i in range(1000)]
        hash_values = [hash(key) for key in string_keys]

        # è®¡ç®—å“ˆå¸Œå€¼åœ¨ä¸åŒæ¡¶ä¸­çš„åˆ†å¸ƒ
        bucket_counts = {}
        table_size = 1024  # å‡è®¾å“ˆå¸Œè¡¨å¤§å°

        for h in hash_values:
            bucket = h % table_size
            bucket_counts[bucket] = bucket_counts.get(bucket, 0) + 1

        # åˆ†æåˆ†å¸ƒå‡åŒ€æ€§
        used_buckets = len(bucket_counts)
        max_collisions = max(bucket_counts.values())
        avg_collisions = sum(bucket_counts.values()) / used_buckets

        print(f"å­—ç¬¦ä¸²é”®å“ˆå¸Œåˆ†å¸ƒ:")
        print(f"  ä½¿ç”¨çš„æ¡¶: {used_buckets}/{table_size} ({used_buckets/table_size*100:.1f}%)")
        print(f"  æœ€å¤§å†²çª: {max_collisions}")
        print(f"  å¹³å‡å†²çª: {avg_collisions:.2f}")

        # 2. æ•´æ•°é”®çš„å“ˆå¸Œåˆ†å¸ƒ
        int_keys = list(range(1000))
        int_hashes = [hash(key) for key in int_keys]

        int_bucket_counts = {}
        for h in int_hashes:
            bucket = h % table_size
            int_bucket_counts[bucket] = int_bucket_counts.get(bucket, 0) + 1

        int_used_buckets = len(int_bucket_counts)
        int_max_collisions = max(int_bucket_counts.values())

        print(f"\næ•´æ•°é”®å“ˆå¸Œåˆ†å¸ƒ:")
        print(f"  ä½¿ç”¨çš„æ¡¶: {int_used_buckets}/{table_size} ({int_used_buckets/table_size*100:.1f}%)")
        print(f"  æœ€å¤§å†²çª: {int_max_collisions}")

        # 3. æ··åˆé”®ç±»å‹çš„æ€§èƒ½å½±å“
        mixed_dict = {}
        string_dict = {}

        # åˆ›å»ºçº¯å­—ç¬¦ä¸²é”®å­—å…¸
        for i in range(1000):
            string_dict[f"str_{i}"] = i

        # åˆ›å»ºæ··åˆé”®å­—å…¸
        for i in range(500):
            mixed_dict[f"str_{i}"] = i
            mixed_dict[i] = f"val_{i}"

        print(f"\nå­—å…¸é”®ç±»å‹ä¼˜åŒ–:")
        print(f"  çº¯å­—ç¬¦ä¸²å­—å…¸å†…å­˜: {sys.getsizeof(string_dict):,} bytes")
        print(f"  æ··åˆé”®å­—å…¸å†…å­˜: {sys.getsizeof(mixed_dict):,} bytes")
        print(f"  æ··åˆé”®å¼€é”€: {(sys.getsizeof(mixed_dict)/sys.getsizeof(string_dict)-1)*100:.1f}%")

    def benchmark_dict_operations(self):
        """åŸºå‡†æµ‹è¯•å­—å…¸æ“ä½œ"""

        print(f"\n=== Dictæ“ä½œæ€§èƒ½åŸºå‡†æµ‹è¯• ===")

        sizes = [1000, 10000, 100000]

        for size in sizes:
            print(f"\næµ‹è¯•å¤§å°: {size:,} å…ƒç´ ")

            # 1. æ’å…¥æ€§èƒ½
            def test_insertion():
                test_dict = {}
                start = time.perf_counter()
                for i in range(size):
                    test_dict[f"key_{i}"] = i
                return time.perf_counter() - start

            insert_time = test_insertion()
            print(f"  æ’å…¥æ“ä½œ: {insert_time:.4f}s ({size/insert_time/1000:.1f}K ops/s)")

            # 2. æŸ¥æ‰¾æ€§èƒ½
            test_dict = {f"key_{i}": i for i in range(size)}

            def test_lookup():
                start = time.perf_counter()
                for i in range(min(10000, size)):
                    _ = test_dict[f"key_{i}"]
                return time.perf_counter() - start

            lookup_time = test_lookup()
            operations = min(10000, size)
            print(f"  æŸ¥æ‰¾æ“ä½œ: {lookup_time:.4f}s ({operations/lookup_time/1000:.1f}K ops/s)")

            # 3. åˆ é™¤æ€§èƒ½
            test_dict_copy = test_dict.copy()

            def test_deletion():
                start = time.perf_counter()
                for i in range(min(1000, size//2)):
                    del test_dict_copy[f"key_{i}"]
                return time.perf_counter() - start

            delete_time = test_deletion()
            del_ops = min(1000, size//2)
            print(f"  åˆ é™¤æ“ä½œ: {delete_time:.4f}s ({del_ops/delete_time/1000:.1f}K ops/s)")

            # 4. è¿­ä»£æ€§èƒ½
            def test_iteration():
                start = time.perf_counter()
                for _ in range(100):
                    for key in test_dict:
                        pass
                return time.perf_counter() - start

            iter_time = test_iteration()
            print(f"  è¿­ä»£æ“ä½œ: {iter_time:.4f}s ({100*size/iter_time/1000:.1f}K items/s)")

    def analyze_memory_efficiency(self):
        """åˆ†æå†…å­˜æ•ˆç‡"""

        print(f"\n=== Dictå†…å­˜æ•ˆç‡åˆ†æ ===")

        # 1. é”®ç±»å‹å¯¹å†…å­˜çš„å½±å“
        size = 10000

        # å­—ç¬¦ä¸²é”®
        str_dict = {f"key_{i}": i for i in range(size)}
        str_memory = sys.getsizeof(str_dict)

        # æ•´æ•°é”®
        int_dict = {i: f"value_{i}" for i in range(size)}
        int_memory = sys.getsizeof(int_dict)

        # å…ƒç»„é”®
        tuple_dict = {(i, i+1): f"value_{i}" for i in range(size)}
        tuple_memory = sys.getsizeof(tuple_dict)

        print(f"ä¸åŒé”®ç±»å‹çš„å†…å­˜ä½¿ç”¨ ({size:,} å…ƒç´ ):")
        print(f"  å­—ç¬¦ä¸²é”®: {str_memory:,} bytes ({str_memory/size:.1f} bytes/item)")
        print(f"  æ•´æ•°é”®: {int_memory:,} bytes ({int_memory/size:.1f} bytes/item)")
        print(f"  å…ƒç»„é”®: {tuple_memory:,} bytes ({tuple_memory/size:.1f} bytes/item)")

        # 2. åˆ†ç¦»å¼å­˜å‚¨ vs åˆå¹¶å¼å­˜å‚¨
        print(f"\nåˆ†ç¦»å¼å­˜å‚¨åˆ†æ:")

        # æ¨¡æ‹Ÿç±»çš„__dict__ï¼ˆä½¿ç”¨åˆ†ç¦»å¼å­˜å‚¨ï¼‰
        class TestClass:
            def __init__(self):
                self.attr1 = 1
                self.attr2 = 2
                self.attr3 = 3
                self.attr4 = 4
                self.attr5 = 5

        instances = [TestClass() for _ in range(1000)]

        # è®¡ç®—å®ä¾‹å­—å…¸çš„æ€»å†…å­˜
        total_dict_memory = sum(sys.getsizeof(inst.__dict__) for inst in instances)
        avg_dict_memory = total_dict_memory / len(instances)

        print(f"  1000ä¸ªå®ä¾‹çš„__dict__:")
        print(f"  æ€»å†…å­˜: {total_dict_memory:,} bytes")
        print(f"  å¹³å‡æ¯ä¸ª: {avg_dict_memory:.1f} bytes")

        # 3. å­—å…¸æ¨å¯¼å¼ vs å¾ªç¯æ„å»º
        def test_dict_comprehension():
            start = time.perf_counter()
            result = {f"key_{i}": i*2 for i in range(size)}
            return time.perf_counter() - start

        def test_dict_loop():
            start = time.perf_counter()
            result = {}
            for i in range(size):
                result[f"key_{i}"] = i*2
            return time.perf_counter() - start

        comp_time = test_dict_comprehension()
        loop_time = test_dict_loop()

        print(f"\næ„å»ºæ–¹å¼æ€§èƒ½å¯¹æ¯”:")
        print(f"  å­—å…¸æ¨å¯¼å¼: {comp_time:.4f}s")
        print(f"  å¾ªç¯æ„å»º: {loop_time:.4f}s")
        print(f"  æ¨å¯¼å¼ä¼˜åŠ¿: {loop_time/comp_time:.1f}x")

    def analyze_advanced_features(self):
        """åˆ†æé«˜çº§ç‰¹æ€§"""

        print(f"\n=== Dicté«˜çº§ç‰¹æ€§åˆ†æ ===")

        # 1. æ’å…¥é¡ºåºä¿æŒï¼ˆPython 3.7+ï¼‰
        print("æ’å…¥é¡ºåºä¿æŒæµ‹è¯•:")
        test_dict = {}
        keys = [f"key_{i}" for i in range(100)]
        random.shuffle(keys)  # éšæœºé¡ºåºæ’å…¥

        for key in keys:
            test_dict[key] = len(test_dict)

        # æ£€æŸ¥è¿­ä»£é¡ºåºæ˜¯å¦ä¸æ’å…¥é¡ºåºä¸€è‡´
        dict_keys = list(test_dict.keys())
        order_preserved = dict_keys == keys
        print(f"  æ’å…¥é¡ºåºä¿æŒ: {order_preserved}")

        # 2. å­—å…¸åˆå¹¶æ€§èƒ½
        dict1 = {f"key1_{i}": i for i in range(5000)}
        dict2 = {f"key2_{i}": i for i in range(5000)}

        def test_dict_merge_update():
            d = dict1.copy()
            start = time.perf_counter()
            d.update(dict2)
            return time.perf_counter() - start

        def test_dict_merge_operator():
            start = time.perf_counter()
            d = dict1 | dict2  # Python 3.9+
            return time.perf_counter() - start

        update_time = test_dict_merge_update()
        try:
            operator_time = test_dict_merge_operator()
            print(f"\nå­—å…¸åˆå¹¶æ€§èƒ½:")
            print(f"  updateæ–¹æ³•: {update_time:.4f}s")
            print(f"  |æ“ä½œç¬¦: {operator_time:.4f}s")
            print(f"  æ“ä½œç¬¦ä¼˜åŠ¿: {update_time/operator_time:.1f}x")
        except TypeError:
            print(f"\nå­—å…¸åˆå¹¶æ€§èƒ½:")
            print(f"  updateæ–¹æ³•: {update_time:.4f}s")
            print(f"  |æ“ä½œç¬¦: ä¸æ”¯æŒ (Python < 3.9)")

        # 3. è§†å›¾å¯¹è±¡æ€§èƒ½
        large_dict = {i: f"value_{i}" for i in range(10000)}

        def test_keys_iteration():
            start = time.perf_counter()
            for _ in range(100):
                for key in large_dict.keys():
                    pass
            return time.perf_counter() - start

        def test_items_iteration():
            start = time.perf_counter()
            for _ in range(100):
                for key, value in large_dict.items():
                    pass
            return time.perf_counter() - start

        keys_time = test_keys_iteration()
        items_time = test_items_iteration()

        print(f"\nè§†å›¾å¯¹è±¡è¿­ä»£æ€§èƒ½:")
        print(f"  keys()è¿­ä»£: {keys_time:.4f}s")
        print(f"  items()è¿­ä»£: {items_time:.4f}s")
        print(f"  itemså¼€é”€: {(items_time/keys_time-1)*100:.1f}%")

    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""

        print("Python Dictå®¹å™¨æ·±åº¦æ€§èƒ½åˆ†æ\n")

        self.analyze_hash_distribution()
        self.benchmark_dict_operations()
        self.analyze_memory_efficiency()
        self.analyze_advanced_features()

        print(f"\n{'='*50}")
        print("Dictåˆ†æå®Œæˆ")
        print(f"{'='*50}")

# è¿è¡ŒDictåˆ†æ
if __name__ == "__main__":
    analyzer = DictPerformanceAnalyzer()
    analyzer.run_analysis()
```

## 3. Setå®¹å™¨æ·±åº¦å®ç°

### 3.1 Setå“ˆå¸Œè¡¨ç»“æ„

```c
/* Objects/setobject.c - PySetObjectç»“æ„å®šä¹‰ */

/*
 * Setå®ç°åŸºäºå¼€æ”¾å¯»å€çš„å“ˆå¸Œè¡¨
 * ä¸dictç±»ä¼¼ï¼Œä½†åªå­˜å‚¨é”®ï¼Œä¸å­˜å‚¨å€¼
 */

typedef struct {
    PyObject_HEAD

    Py_ssize_t fill;            /* å·²ä½¿ç”¨æ§½ä½æ•°ï¼ˆåŒ…æ‹¬dummyï¼‰ */
    Py_ssize_t used;            /* æ´»è·ƒå…ƒç´ æ•° */
    Py_ssize_t mask;            /* å“ˆå¸Œè¡¨æ©ç  (size - 1) */

    setentry *table;            /* å“ˆå¸Œè¡¨æŒ‡é’ˆ */
    Py_hash_t hash;             /* frozensetçš„å“ˆå¸Œå€¼ç¼“å­˜ */
    Py_ssize_t finger;          /* è¿­ä»£å™¨ä½ç½® */

    setentry smalltable[PySet_MINSIZE];  /* å°è¡¨ä¼˜åŒ– */
    PyObject *weakreflist;      /* å¼±å¼•ç”¨åˆ—è¡¨ */
} PySetObject;

/* Setæ¡ç›®ç»“æ„ */
typedef struct {
    PyObject *key;              /* å…ƒç´ å¯¹è±¡ */
    Py_hash_t hash;             /* å“ˆå¸Œå€¼ç¼“å­˜ */
} setentry;

/* Setåˆ›å»ºå‡½æ•° */
PyObject *
PySet_New(PyObject *iterable)
{
    return make_new_set(&PySet_Type, iterable);
}

/* é€šç”¨Setåˆ›å»ºå‡½æ•° */
static PyObject *
make_new_set(PyTypeObject *type, PyObject *iterable)
{
    assert(PyType_Check(type));
    PySetObject *so;

    /* åˆ†é…Setå¯¹è±¡ */
    so = (PySetObject *)type->tp_alloc(type, 0);
    if (so == NULL)
        return NULL;

    /* åˆå§‹åŒ–Setç»“æ„ */
    so->fill = 0;
    so->used = 0;
    so->mask = PySet_MINSIZE - 1;    /* åˆå§‹å¤§å°ä¸º8 */
    so->table = so->smalltable;      /* ä½¿ç”¨å†…ç½®å°è¡¨ */
    so->hash = -1;                   /* æœªè®¡ç®—å“ˆå¸Œå€¼ */
    so->finger = 0;                  /* è¿­ä»£å™¨èµ·å§‹ä½ç½® */
    so->weakreflist = NULL;

    if (iterable != NULL) {
        /* ä»å¯è¿­ä»£å¯¹è±¡åˆå§‹åŒ– */
        if (set_update_local(so, iterable)) {
            Py_DECREF(so);
            return NULL;
        }
    }

    return (PyObject *)so;
}

/* SetæŸ¥æ‰¾å®ç° */
static setentry *
set_lookkey(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *table;
    setentry *entry;
    size_t perturb = hash;
    size_t mask = so->mask;
    size_t i = (size_t)hash & mask;     /* åˆå§‹æ¢æµ‹ä½ç½® */

    table = so->table;
    entry = &table[i];

    if (entry->key == NULL) {
        /* ç©ºæ§½ï¼Œå…ƒç´ ä¸å­˜åœ¨ */
        return entry;
    }

    if (entry->key == key) {
        /* å¯¹è±¡èº«ä»½ç›¸ç­‰ */
        return entry;
    }

    if (entry->hash == hash && entry->key != dummy) {
        /* å“ˆå¸Œå€¼ç›¸ç­‰ï¼Œè¿›è¡Œæ·±åº¦æ¯”è¾ƒ */
        int cmp = PyObject_RichCompareBool(entry->key, key, Py_EQ);
        if (cmp < 0) {
            return NULL;
        }
        if (cmp > 0) {
            return entry;
        }
    }

    /* ä½¿ç”¨Perturbç®—æ³•è¿›è¡Œå¼€æ”¾å¯»å€ */
    while (1) {
        perturb >>= PERTURB_SHIFT;
        i = (i * 5 + 1 + perturb) & mask;
        entry = &table[i];

        if (entry->key == NULL) {
            return entry;
        }
        if (entry->key == key) {
            return entry;
        }
        if (entry->hash == hash && entry->key != dummy) {
            int cmp = PyObject_RichCompareBool(entry->key, key, Py_EQ);
            if (cmp < 0) {
                return NULL;
            }
            if (cmp > 0) {
                return entry;
            }
        }
    }
}

/* Setæ·»åŠ å…ƒç´  */
static int
set_add_entry(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *entry;

    assert(so->fill <= so->mask);

    /* æŸ¥æ‰¾æ’å…¥ä½ç½® */
    entry = set_lookkey(so, key, hash);
    if (entry == NULL) {
        return -1;
    }

    if (entry->key == NULL) {
        /* æ–°å…ƒç´  */
        entry->key = key;
        entry->hash = hash;
        so->fill++;
        so->used++;
        Py_INCREF(key);
    }
    else if (entry->key == dummy) {
        /* é‡ç”¨deletedæ§½ä½ */
        entry->key = key;
        entry->hash = hash;
        so->used++;
        Py_INCREF(key);
    }
    /* å…ƒç´ å·²å­˜åœ¨ï¼Œä¸åšä»»ä½•æ“ä½œ */

    return 0;
}

/* Setæ‰©å®¹ç­–ç•¥ */
static int
set_table_resize(PySetObject *so, Py_ssize_t minused)
{
    Py_ssize_t newsize;
    setentry *oldtable, *newtable, *entry;
    Py_ssize_t oldfill = so->fill;
    Py_ssize_t oldused = so->used;
    Py_ssize_t oldmask = so->mask;
    size_t i;

    assert(minused >= 0);

    /*
     * Setæ‰©å®¹ç­–ç•¥ï¼š
     * - æ‰¾åˆ°èƒ½å®¹çº³minusedä¸ªå…ƒç´ çš„æœ€å°2çš„å¹‚
     * - è´Ÿè½½å› å­ä¿æŒåœ¨2/3ä»¥ä¸‹
     */
    for (newsize = PySet_MINSIZE; newsize < minused; newsize <<= 1)
        ;

    /* åˆ†é…æ–°è¡¨ */
    if (newsize == PySet_MINSIZE) {
        /* ä½¿ç”¨å†…ç½®å°è¡¨ */
        newtable = so->smalltable;
    }
    else {
        newtable = PyMem_New(setentry, newsize);
        if (newtable == NULL) {
            PyErr_NoMemory();
            return -1;
        }
    }

    /* åˆå§‹åŒ–æ–°è¡¨ */
    memset(newtable, 0, sizeof(setentry) * newsize);

    /* ä¿å­˜æ—§è¡¨ */
    oldtable = so->table;

    /* è®¾ç½®æ–°è¡¨å‚æ•° */
    so->table = newtable;
    so->mask = newsize - 1;
    so->fill = 0;
    so->used = 0;

    /* é‡æ–°æ’å…¥æ‰€æœ‰å…ƒç´  */
    for (i = 0; i <= oldmask; i++) {
        entry = &oldtable[i];
        if (entry->key != NULL && entry->key != dummy) {
            if (set_add_entry(so, entry->key, entry->hash)) {
                /* å›æ»š */
                so->table = oldtable;
                so->mask = oldmask;
                so->fill = oldfill;
                so->used = oldused;

                if (newtable != so->smalltable) {
                    PyMem_Free(newtable);
                }
                return -1;
            }
            Py_DECREF(entry->key);  /* ç§»é™¤æ—§å¼•ç”¨ */
        }
    }

    /* é‡Šæ”¾æ—§è¡¨ */
    if (oldtable != so->smalltable) {
        PyMem_Free(oldtable);
    }

    return 0;
}

/* Setåˆ é™¤å…ƒç´  */
static int
set_discard_entry(PySetObject *so, PyObject *key, Py_hash_t hash)
{
    setentry *entry;

    entry = set_lookkey(so, key, hash);
    if (entry == NULL) {
        return -1;
    }
    if (entry->key == NULL) {
        return DISCARD_NOTFOUND;
    }

    /* æ ‡è®°ä¸ºå·²åˆ é™¤ */
    Py_DECREF(entry->key);
    entry->key = dummy;
    entry->hash = -1;
    so->used--;

    return DISCARD_FOUND;
}

/* frozensetå“ˆå¸Œå€¼è®¡ç®— */
static Py_hash_t
frozenset_hash(PyObject *self)
{
    PySetObject *so = (PySetObject *)self;
    Py_uhash_t hash = 0;
    setentry *entry;
    Py_ssize_t pos = 0;

    if (so->hash != -1) {
        /* è¿”å›ç¼“å­˜çš„å“ˆå¸Œå€¼ */
        return so->hash;
    }

    /*
     * frozensetå“ˆå¸Œç®—æ³•ï¼š
     * 1. å¯¹æ‰€æœ‰å…ƒç´ çš„å“ˆå¸Œå€¼è¿›è¡ŒXOR
     * 2. ä½¿ç”¨ä¹˜æ³•å’Œä½ç§»æ··åˆ
     * 3. ç¡®ä¿ç»“æœä¸å…ƒç´ é¡ºåºæ— å…³
     */
    while (set_next(so, &pos, &entry)) {
        /* æ··åˆå…ƒç´ å“ˆå¸Œå€¼ */
        Py_uhash_t h = (Py_uhash_t)entry->hash;
        hash ^= ((h ^ 89869747UL) ^ (h << 16)) * 3644798167UL;
    }

    /* æœ€ç»ˆæ··åˆ */
    hash = hash * 69069U + 907133923UL;
    if (hash == (Py_uhash_t)-1) {
        hash = 590923713UL;
    }

    /* ç¼“å­˜å“ˆå¸Œå€¼ */
    so->hash = (Py_hash_t)hash;
    return (Py_hash_t)hash;
}
```

## 4. å®¹å™¨æ€§èƒ½å¯¹æ¯”ä¸æœ€ä½³å®è·µ

### 4.1 å®¹å™¨é€‰æ‹©æŒ‡å—

```python
# å®¹å™¨æ€§èƒ½å¯¹æ¯”å’Œé€‰æ‹©æŒ‡å—
import time
import sys
import random
from collections import deque, defaultdict, Counter
from typing import List, Dict, Set, Tuple

class ContainerComparisonAnalyzer:
    """å®¹å™¨å¯¹æ¯”åˆ†æå™¨"""

    def __init__(self):
        self.test_sizes = [1000, 10000, 100000]
        self.results = {}

    def compare_sequence_containers(self):
        """å¯¹æ¯”åºåˆ—å®¹å™¨æ€§èƒ½"""

        print("=== åºåˆ—å®¹å™¨æ€§èƒ½å¯¹æ¯” ===")

        for size in self.test_sizes:
            print(f"\næµ‹è¯•å¤§å°: {size:,} å…ƒç´ ")

            # 1. è¿½åŠ æ“ä½œå¯¹æ¯”
            def test_list_append():
                container = []
                start = time.perf_counter()
                for i in range(size):
                    container.append(i)
                return time.perf_counter() - start

            def test_deque_append():
                container = deque()
                start = time.perf_counter()
                for i in range(size):
                    container.append(i)
                return time.perf_counter() - start

            list_append_time = test_list_append()
            deque_append_time = test_deque_append()

            print(f"  è¿½åŠ æ“ä½œ:")
            print(f"    list: {list_append_time:.4f}s")
            print(f"    deque: {deque_append_time:.4f}s")
            print(f"    dequeä¼˜åŠ¿: {list_append_time/deque_append_time:.1f}x")

            # 2. å¤´éƒ¨æ’å…¥å¯¹æ¯”
            test_list = list(range(min(1000, size//10)))
            test_deque = deque(range(min(1000, size//10)))

            def test_list_prepend():
                start = time.perf_counter()
                for i in range(100):
                    test_list.insert(0, -i)
                return time.perf_counter() - start

            def test_deque_prepend():
                start = time.perf_counter()
                for i in range(100):
                    test_deque.appendleft(-i)
                return time.perf_counter() - start

            list_prepend_time = test_list_prepend()
            deque_prepend_time = test_deque_prepend()

            print(f"  å¤´éƒ¨æ’å…¥:")
            print(f"    list.insert(0): {list_prepend_time:.4f}s")
            print(f"    deque.appendleft: {deque_prepend_time:.4f}s")
            print(f"    dequeä¼˜åŠ¿: {list_prepend_time/deque_prepend_time:.1f}x")

            # 3. éšæœºè®¿é—®å¯¹æ¯”
            test_list = list(range(size))
            test_tuple = tuple(range(size))

            def test_list_access():
                start = time.perf_counter()
                for _ in range(min(10000, size)):
                    idx = random.randint(0, size-1)
                    _ = test_list[idx]
                return time.perf_counter() - start

            def test_tuple_access():
                start = time.perf_counter()
                for _ in range(min(10000, size)):
                    idx = random.randint(0, size-1)
                    _ = test_tuple[idx]
                return time.perf_counter() - start

            list_access_time = test_list_access()
            tuple_access_time = test_tuple_access()

            print(f"  éšæœºè®¿é—®:")
            print(f"    list: {list_access_time:.4f}s")
            print(f"    tuple: {tuple_access_time:.4f}s")
            print(f"    tupleä¼˜åŠ¿: {list_access_time/tuple_access_time:.1f}x")

    def compare_mapping_containers(self):
        """å¯¹æ¯”æ˜ å°„å®¹å™¨æ€§èƒ½"""

        print(f"\n=== æ˜ å°„å®¹å™¨æ€§èƒ½å¯¹æ¯” ===")

        for size in self.test_sizes:
            print(f"\næµ‹è¯•å¤§å°: {size:,} å…ƒç´ ")

            # 1. æ„å»ºæ€§èƒ½å¯¹æ¯”
            def test_dict_build():
                start = time.perf_counter()
                container = {}
                for i in range(size):
                    container[f"key_{i}"] = i
                return time.perf_counter() - start

            def test_defaultdict_build():
                start = time.perf_counter()
                container = defaultdict(int)
                for i in range(size):
                    container[f"key_{i}"] = i
                return time.perf_counter() - start

            dict_build_time = test_dict_build()
            defaultdict_build_time = test_defaultdict_build()

            print(f"  æ„å»ºæ€§èƒ½:")
            print(f"    dict: {dict_build_time:.4f}s")
            print(f"    defaultdict: {defaultdict_build_time:.4f}s")
            print(f"    å¼€é”€æ¯”ä¾‹: {(defaultdict_build_time/dict_build_time-1)*100:.1f}%")

            # 2. ç¼ºå¤±é”®å¤„ç†å¯¹æ¯”
            test_dict = {f"key_{i}": i for i in range(size)}
            test_defaultdict = defaultdict(int, test_dict)

            def test_dict_get():
                start = time.perf_counter()
                for i in range(1000):
                    _ = test_dict.get(f"missing_{i}", 0)
                return time.perf_counter() - start

            def test_defaultdict_access():
                start = time.perf_counter()
                for i in range(1000):
                    _ = test_defaultdict[f"missing_{i}"]
                return time.perf_counter() - start

            dict_get_time = test_dict_get()
            defaultdict_access_time = test_defaultdict_access()

            print(f"  ç¼ºå¤±é”®å¤„ç†:")
            print(f"    dict.get(): {dict_get_time:.4f}s")
            print(f"    defaultdict[]: {defaultdict_access_time:.4f}s")
            print(f"    defaultdictä¼˜åŠ¿: {dict_get_time/defaultdict_access_time:.1f}x")

    def compare_set_containers(self):
        """å¯¹æ¯”é›†åˆå®¹å™¨æ€§èƒ½"""

        print(f"\n=== é›†åˆå®¹å™¨æ€§èƒ½å¯¹æ¯” ===")

        for size in self.test_sizes:
            print(f"\næµ‹è¯•å¤§å°: {size:,} å…ƒç´ ")

            # 1. æ„å»ºæ€§èƒ½å¯¹æ¯”
            data = list(range(size))

            def test_set_build():
                start = time.perf_counter()
                container = set(data)
                return time.perf_counter() - start

            def test_frozenset_build():
                start = time.perf_counter()
                container = frozenset(data)
                return time.perf_counter() - start

            set_build_time = test_set_build()
            frozenset_build_time = test_frozenset_build()

            print(f"  æ„å»ºæ€§èƒ½:")
            print(f"    set: {set_build_time:.4f}s")
            print(f"    frozenset: {frozenset_build_time:.4f}s")
            print(f"    frozensetå¼€é”€: {(frozenset_build_time/set_build_time-1)*100:.1f}%")

            # 2. æˆå‘˜æµ‹è¯•æ€§èƒ½
            test_set = set(data)
            test_frozenset = frozenset(data)
            test_list = data.copy()

            def test_set_membership():
                start = time.perf_counter()
                for i in range(min(10000, size)):
                    _ = i in test_set
                return time.perf_counter() - start

            def test_frozenset_membership():
                start = time.perf_counter()
                for i in range(min(10000, size)):
                    _ = i in test_frozenset
                return time.perf_counter() - start

            def test_list_membership():
                start = time.perf_counter()
                for i in range(min(1000, size//10)):  # å‡å°‘æµ‹è¯•æ¬¡æ•°
                    _ = i in test_list
                return time.perf_counter() - start

            set_membership_time = test_set_membership()
            frozenset_membership_time = test_frozenset_membership()
            list_membership_time = test_list_membership()

            # æ ‡å‡†åŒ–åˆ°ç›¸åŒçš„æ“ä½œæ¬¡æ•°
            list_ops = min(1000, size//10)
            set_ops = min(10000, size)
            list_normalized_time = list_membership_time * (set_ops / list_ops)

            print(f"  æˆå‘˜æµ‹è¯•:")
            print(f"    set: {set_membership_time:.4f}s")
            print(f"    frozenset: {frozenset_membership_time:.4f}s")
            print(f"    list: {list_normalized_time:.4f}s (æ ‡å‡†åŒ–)")
            print(f"    set vs listä¼˜åŠ¿: {list_normalized_time/set_membership_time:.1f}x")

            # 3. é›†åˆæ“ä½œæ€§èƒ½
            set1 = set(range(size//2))
            set2 = set(range(size//4, 3*size//4))

            def test_set_union():
                start = time.perf_counter()
                for _ in range(100):
                    _ = set1 | set2
                return time.perf_counter() - start

            def test_set_intersection():
                start = time.perf_counter()
                for _ in range(100):
                    _ = set1 & set2
                return time.perf_counter() - start

            union_time = test_set_union()
            intersection_time = test_set_intersection()

            print(f"  é›†åˆæ“ä½œ (100æ¬¡):")
            print(f"    å¹¶é›†: {union_time:.4f}s")
            print(f"    äº¤é›†: {intersection_time:.4f}s")

    def analyze_memory_usage(self):
        """åˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼"""

        print(f"\n=== å®¹å™¨å†…å­˜ä½¿ç”¨åˆ†æ ===")

        size = 10000

        # åˆ›å»ºä¸åŒç±»å‹çš„å®¹å™¨
        test_list = list(range(size))
        test_tuple = tuple(range(size))
        test_set = set(range(size))
        test_frozenset = frozenset(range(size))
        test_dict = {i: i for i in range(size)}

        containers = {
            'list': test_list,
            'tuple': test_tuple,
            'set': test_set,
            'frozenset': test_frozenset,
            'dict': test_dict
        }

        print(f"å†…å­˜ä½¿ç”¨å¯¹æ¯” ({size:,} æ•´æ•°å…ƒç´ ):")

        base_memory = None
        for name, container in containers.items():
            memory = sys.getsizeof(container)
            per_element = memory / size

            if base_memory is None:
                base_memory = memory
                print(f"  {name:10s}: {memory:,} bytes ({per_element:.1f} bytes/å…ƒç´ )")
            else:
                ratio = memory / base_memory
                print(f"  {name:10s}: {memory:,} bytes ({per_element:.1f} bytes/å…ƒç´ ) [{ratio:.1f}x]")

    def provide_usage_recommendations(self):
        """æä¾›ä½¿ç”¨å»ºè®®"""

        print(f"\n=== å®¹å™¨é€‰æ‹©å»ºè®® ===")

        recommendations = {
            "åºåˆ—å®¹å™¨": {
                "list": {
                    "ä¼˜åŠ¿": ["åŠ¨æ€å¤§å°", "éšæœºè®¿é—®O(1)", "å°¾éƒ¨æ“ä½œO(1)"],
                    "åŠ£åŠ¿": ["å¤´éƒ¨æ“ä½œO(n)", "å†…å­˜å¼€é”€å¤§"],
                    "é€‚ç”¨": ["é€šç”¨åºåˆ—", "éœ€è¦ä¿®æ”¹", "éšæœºè®¿é—®"]
                },
                "tuple": {
                    "ä¼˜åŠ¿": ["ä¸å¯å˜", "å†…å­˜æ•ˆç‡é«˜", "å¯å“ˆå¸Œ"],
                    "åŠ£åŠ¿": ["ä¸èƒ½ä¿®æ”¹", "æ„å»ºå¼€é”€å¤§"],
                    "é€‚ç”¨": ["å›ºå®šæ•°æ®", "å­—å…¸é”®", "é…ç½®å‚æ•°"]
                },
                "deque": {
                    "ä¼˜åŠ¿": ["ä¸¤ç«¯æ“ä½œO(1)", "çº¿ç¨‹å®‰å…¨çš„æ“ä½œ"],
                    "åŠ£åŠ¿": ["éšæœºè®¿é—®O(n)", "å†…å­˜å¼€é”€å¤§"],
                    "é€‚ç”¨": ["é˜Ÿåˆ—/æ ˆ", "æ»‘åŠ¨çª—å£", "ä¸¤ç«¯æ“ä½œ"]
                }
            },
            "æ˜ å°„å®¹å™¨": {
                "dict": {
                    "ä¼˜åŠ¿": ["æŸ¥æ‰¾O(1)", "æ’å…¥é¡ºåºä¿æŒ", "å†…å­˜ä¼˜åŒ–"],
                    "åŠ£åŠ¿": ["å†…å­˜å¼€é”€", "ä¸å¯å“ˆå¸Œ"],
                    "é€‚ç”¨": ["é€šç”¨æ˜ å°„", "ç¼“å­˜", "è®¡æ•°å™¨"]
                },
                "defaultdict": {
                    "ä¼˜åŠ¿": ["è‡ªåŠ¨åˆå§‹åŒ–", "ç®€åŒ–ä»£ç "],
                    "åŠ£åŠ¿": ["è½»å¾®æ€§èƒ½å¼€é”€"],
                    "é€‚ç”¨": ["åˆ†ç»„", "åµŒå¥—ç»“æ„", "è®¡æ•°å™¨"]
                }
            },
            "é›†åˆå®¹å™¨": {
                "set": {
                    "ä¼˜åŠ¿": ["å”¯ä¸€æ€§", "é›†åˆè¿ç®—", "æˆå‘˜æµ‹è¯•O(1)"],
                    "åŠ£åŠ¿": ["æ— åº", "å†…å­˜å¼€é”€"],
                    "é€‚ç”¨": ["å»é‡", "æˆå‘˜æµ‹è¯•", "é›†åˆè¿ç®—"]
                },
                "frozenset": {
                    "ä¼˜åŠ¿": ["ä¸å¯å˜", "å¯å“ˆå¸Œ", "å¯åšå­—å…¸é”®"],
                    "åŠ£åŠ¿": ["ä¸èƒ½ä¿®æ”¹"],
                    "é€‚ç”¨": ["ä¸å˜é›†åˆ", "å­—å…¸é”®", "é›†åˆçš„é›†åˆ"]
                }
            }
        }

        for category, containers in recommendations.items():
            print(f"\n{category}:")
            for container, info in containers.items():
                print(f"  {container}:")
                print(f"    ä¼˜åŠ¿: {', '.join(info['ä¼˜åŠ¿'])}")
                print(f"    åŠ£åŠ¿: {', '.join(info['åŠ£åŠ¿'])}")
                print(f"    é€‚ç”¨: {', '.join(info['é€‚ç”¨'])}")

    def run_comparison(self):
        """è¿è¡Œå®Œæ•´å¯¹æ¯”åˆ†æ"""

        print("Pythonæ ¸å¿ƒå®¹å™¨æ€§èƒ½å¯¹æ¯”åˆ†æ\n")

        self.compare_sequence_containers()
        self.compare_mapping_containers()
        self.compare_set_containers()
        self.analyze_memory_usage()
        self.provide_usage_recommendations()

        print(f"\n{'='*50}")
        print("å®¹å™¨å¯¹æ¯”åˆ†æå®Œæˆ")
        print(f"{'='*50}")

# è¿è¡Œå®¹å™¨å¯¹æ¯”åˆ†æ
if __name__ == "__main__":
    analyzer = ContainerComparisonAnalyzer()
    analyzer.run_comparison()
```

## 5. å®¹å™¨æ¶æ„æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant App as åº”ç”¨ç¨‹åº
    participant Container as å®¹å™¨æ¥å£
    participant HashTable as å“ˆå¸Œè¡¨
    participant Memory as å†…å­˜ç®¡ç†

    Note over App,Memory: Listæ“ä½œæµç¨‹
    App->>Container: list.append(item)
    Container->>Container: æ£€æŸ¥å®¹é‡
    alt éœ€è¦æ‰©å®¹
        Container->>Memory: é‡æ–°åˆ†é…å†…å­˜
        Memory-->>Container: æ–°å†…å­˜å—
        Container->>Container: å¤åˆ¶ç°æœ‰å…ƒç´ 
    end
    Container->>Container: æ·»åŠ æ–°å…ƒç´ 
    Container-->>App: æ“ä½œå®Œæˆ

    Note over App,Memory: Dictæ“ä½œæµç¨‹
    App->>Container: dict[key] = value
    Container->>HashTable: è®¡ç®—å“ˆå¸Œå€¼
    HashTable->>HashTable: æŸ¥æ‰¾æ’å…¥ä½ç½®
    alt å‘ç”Ÿå†²çª
        HashTable->>HashTable: Perturbç®—æ³•æ¢æµ‹
    end
    alt éœ€è¦æ‰©å®¹
        Container->>Memory: åˆ†é…æ–°å“ˆå¸Œè¡¨
        Container->>HashTable: é‡æ–°å“ˆå¸Œæ‰€æœ‰å…ƒç´ 
    end
    HashTable->>HashTable: æ’å…¥é”®å€¼å¯¹
    Container-->>App: æ“ä½œå®Œæˆ

    Note over App,Memory: Setæ“ä½œæµç¨‹
    App->>Container: set.add(item)
    Container->>HashTable: è®¡ç®—å…ƒç´ å“ˆå¸Œ
    HashTable->>HashTable: æŸ¥æ‰¾ä½ç½®
    alt å…ƒç´ å·²å­˜åœ¨
        HashTable-->>Container: æ— æ“ä½œ
    else æ–°å…ƒç´ 
        HashTable->>HashTable: æ’å…¥å…ƒç´ 
        alt è´Ÿè½½å› å­è¿‡é«˜
            Container->>Memory: æ‰©å®¹å“ˆå¸Œè¡¨
        end
    end
    Container-->>App: æ“ä½œå®Œæˆ
```

## 6. æ€»ç»“

Pythonçš„æ ¸å¿ƒå®¹å™¨ç³»ç»Ÿå±•ç°äº†é«˜åº¦ä¼˜åŒ–çš„è®¾è®¡ï¼š

### 6.1 è®¾è®¡ç²¾å

1. **List**: åŠ¨æ€æ•°ç»„ï¼Œæ™ºèƒ½æ‰©å®¹ç­–ç•¥ï¼Œä¼˜åŒ–å†…å­˜å±€éƒ¨æ€§
2. **Dict**: å¼€æ”¾å¯»å€ï¼ŒPerturbç®—æ³•ï¼ŒUnicodeä¼˜åŒ–ï¼Œæ’å…¥é¡ºåºä¿æŒ
3. **Set**: å“ˆå¸Œå»é‡ï¼Œé›†åˆè¿ç®—ä¼˜åŒ–ï¼Œfrozensetå¯å“ˆå¸Œæ€§
4. **Tuple**: ä¸å¯å˜ä¼˜åŒ–ï¼Œå†…å­˜ç´§å‡‘ï¼Œå¯å“ˆå¸Œç‰¹æ€§

### 6.2 æ€§èƒ½ç‰¹å¾

1. **æ—¶é—´å¤æ‚åº¦**: å¤§éƒ¨åˆ†æ“ä½œè¾¾åˆ°ç†è®ºæœ€ä¼˜
2. **ç©ºé—´æ•ˆç‡**: é’ˆå¯¹ä¸åŒä½¿ç”¨æ¨¡å¼ä¼˜åŒ–å†…å­˜å¸ƒå±€
3. **ç¼“å­˜å‹å¥½**: æ•°æ®ç»“æ„è®¾è®¡è€ƒè™‘ç°ä»£CPUç¼“å­˜ç‰¹æ€§

### 6.3 åº”ç”¨æŒ‡å¯¼

1. **é€‰æ‹©åˆé€‚çš„å®¹å™¨**: æ ¹æ®è®¿é—®æ¨¡å¼å’Œæ€§èƒ½éœ€æ±‚
2. **ç†è§£æ€§èƒ½ç‰¹å¾**: é¿å…æ„å¤–çš„æ€§èƒ½é™·é˜±
3. **å†…å­˜ä¼˜åŒ–**: åˆç†ä½¿ç”¨ä¸åŒå®¹å™¨å‡å°‘å†…å­˜å¼€é”€
4. **ç®—æ³•é…åˆ**: å®¹å™¨ç‰¹æ€§ä¸ç®—æ³•è®¾è®¡ç›¸ç»“åˆ

### 6.4 ä¼˜åŒ–å»ºè®®

1. **é¢„åˆ†é…**: å·²çŸ¥å¤§å°æ—¶é¢„åˆ†é…å®¹å™¨
2. **æ‰¹é‡æ“ä½œ**: ä½¿ç”¨extendã€updateç­‰æ‰¹é‡æ–¹æ³•
3. **åˆé€‚çš„æ•°æ®ç»“æ„**: æ ¹æ®ä½¿ç”¨æ¨¡å¼é€‰æ‹©æœ€ä¼˜å®¹å™¨
4. **å†…å­˜ç®¡ç†**: æ³¨æ„å®¹å™¨çš„å†…å­˜ä½¿ç”¨æ¨¡å¼

Pythonçš„æ ¸å¿ƒå®¹å™¨ä¸ºé«˜æ•ˆçš„æ•°æ®æ“ä½œæä¾›äº†åšå®çš„åŸºç¡€ï¼Œç†è§£å…¶å®ç°åŸç†å¯¹äºç¼–å†™é«˜æ€§èƒ½Pythonç¨‹åºè‡³å…³é‡è¦ã€‚
