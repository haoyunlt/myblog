---
title: "02 - æ ¸å¿ƒAPIè¯¦ç»†åˆ†æ"
date: 2025-09-28T00:47:16+08:00
draft: false
tags: ['æºç åˆ†æ', 'æŠ€æœ¯æ–‡æ¡£', 'API']
categories: ['qwenagent', 'æŠ€æœ¯åˆ†æ']
description: "02 - æ ¸å¿ƒAPIè¯¦ç»†åˆ†æçš„æ·±å…¥æŠ€æœ¯åˆ†ææ–‡æ¡£"
keywords: ['æºç åˆ†æ', 'æŠ€æœ¯æ–‡æ¡£', 'API']
author: "æŠ€æœ¯åˆ†æå¸ˆ"
weight: 1
---

## ğŸ“ æ¦‚è¿°

Qwen-Agentæ¡†æ¶å¯¹å¤–æš´éœ²äº†æ¸…æ™°ç®€æ´çš„APIæ¥å£ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾æ„å»ºå„ç§ç±»å‹çš„AIä»£ç†åº”ç”¨ã€‚æœ¬æ–‡æ¡£æ·±å…¥åˆ†ææ¡†æ¶çš„æ ¸å¿ƒAPIè®¾è®¡ã€è°ƒç”¨é“¾è·¯å’Œå…³é”®å‡½æ•°å®ç°ã€‚

## ğŸš€ å¯¹å¤–æ ¸å¿ƒAPIæ¦‚è§ˆ

### 1. æ¡†æ¶å…¥å£API

```python
# ä¸»è¦å¯¼å…¥æ¥å£
from qwen_agent import Agent, MultiAgentHub
from qwen_agent.agents import Assistant, FnCallAgent, ReActChat
from qwen_agent.llm import get_chat_model
from qwen_agent.tools import register_tool, BaseTool
from qwen_agent.gui import WebUI
```

### APIåˆ†ç±»å›¾

```mermaid
graph TB
    subgraph "æ ¸å¿ƒAPI"
        A[Agentç±»] --> A1[Agent.run<br/>æ¶ˆæ¯å¤„ç†å…¥å£]
        A --> A2[Agent.run_nonstream<br/>éæµå¼è°ƒç”¨]
        B[MultiAgentHub] --> B1[agentså±æ€§<br/>ä»£ç†ç®¡ç†]
    end
    
    subgraph "Agentå…·ä½“å®ç°API"
        C[Assistant] --> C1[__init__<br/>åˆå§‹åŒ–åŠ©æ‰‹]
        D[FnCallAgent] --> D1[__init__<br/>å‡½æ•°è°ƒç”¨ä»£ç†]
        E[ReActChat] --> E1[__init__<br/>æ¨ç†è¡ŒåŠ¨ä»£ç†]
    end
    
    subgraph "LLMæœåŠ¡API" 
        F[get_chat_model] --> F1[æ¨¡å‹å·¥å‚æ–¹æ³•]
        G[BaseChatModel] --> G1[chat<br/>èŠå¤©æ¥å£]
        G --> G2[quick_chat<br/>å¿«é€ŸèŠå¤©]
    end
    
    subgraph "å·¥å…·ç³»ç»ŸAPI"
        H[register_tool] --> H1[å·¥å…·æ³¨å†Œè£…é¥°å™¨]
        I[BaseTool] --> I1[call<br/>å·¥å…·è°ƒç”¨æ¥å£] 
        I --> I2[functionå±æ€§<br/>å·¥å…·æè¿°]
    end
    
    subgraph "GUIç•Œé¢API"
        J[WebUI] --> J1[__init__<br/>åˆå§‹åŒ–ç•Œé¢]
        J --> J2[run<br/>å¯åŠ¨WebæœåŠ¡]
    end
```

## ğŸ” æ ¸å¿ƒAPIè¯¦ç»†åˆ†æ

### 1. AgentåŸºç±»API

#### 1.1 Agent.run() - ä¸»è¦æ¶ˆæ¯å¤„ç†å…¥å£

**å‡½æ•°ç­¾å**:
```python
def run(self, messages: List[Union[Dict, Message]], **kwargs) -> Union[Iterator[List[Message]], Iterator[List[Dict]]]:
    """è¿”å›åŸºäºæ¥æ”¶æ¶ˆæ¯çš„å“åº”ç”Ÿæˆå™¨
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ”¯æŒå­—å…¸æˆ–Messageå¯¹è±¡
        **kwargs: é¢å¤–å‚æ•°ï¼Œå¦‚langç­‰
        
    Yields:
        å“åº”ç”Ÿæˆå™¨ï¼Œæ”¯æŒæµå¼è¾“å‡º
    """
```

**å®Œæ•´æºç åˆ†æ**:
```python
def run(self, messages: List[Union[Dict, Message]], **kwargs) -> Union[Iterator[List[Message]], Iterator[List[Dict]]]:
    """Agentè¿è¡Œçš„ä¸»å…¥å£æ–¹æ³•ï¼Œè´Ÿè´£æ¶ˆæ¯é¢„å¤„ç†å’Œç±»å‹è½¬æ¢"""
    
    # 1. æ·±æ‹·è´æ¶ˆæ¯ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    messages = copy.deepcopy(messages)
    _return_message_type = 'dict'
    new_messages = []
    
    # 2. ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼è½¬æ¢
    if not messages:
        _return_message_type = 'message'
    for msg in messages:
        if isinstance(msg, dict):
            new_messages.append(Message(**msg))  # å­—å…¸è½¬Messageå¯¹è±¡
        else:
            new_messages.append(msg)
            _return_message_type = 'message'
    
    # 3. è‡ªåŠ¨è¯­è¨€æ£€æµ‹
    if 'lang' not in kwargs:
        if has_chinese_messages(new_messages):
            kwargs['lang'] = 'zh'  # æ£€æµ‹åˆ°ä¸­æ–‡è®¾ç½®ä¸ºä¸­æ–‡
        else:
            kwargs['lang'] = 'en'  # é»˜è®¤è‹±æ–‡
    
    # 4. æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    if self.system_message:
        if not new_messages or new_messages[0][ROLE] != SYSTEM:
            # å¦‚æœæ²¡æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œåˆ™æ·»åŠ 
            new_messages.insert(0, Message(role=SYSTEM, content=self.system_message))
        else:
            # å¦‚æœå·²æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œåˆ™åˆå¹¶
            if isinstance(new_messages[0][CONTENT], str):
                new_messages[0][CONTENT] = self.system_message + '\n\n' + new_messages[0][CONTENT]
            else:
                # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                assert isinstance(new_messages[0][CONTENT], list)
                new_messages[0][CONTENT] = [ContentItem(text=self.system_message + '\n\n')] + new_messages[0][CONTENT]
    
    # 5. è°ƒç”¨å…·ä½“å®ç°çš„_runæ–¹æ³•
    for rsp in self._run(messages=new_messages, **kwargs):
        # è®¾ç½®ä»£ç†åç§°
        for i in range(len(rsp)):
            if not rsp[i].name and self.name:
                rsp[i].name = self.name
        
        # 6. æ ¹æ®è¾“å…¥ç±»å‹è¿”å›ç›¸åº”æ ¼å¼
        if _return_message_type == 'message':
            yield [Message(**x) if isinstance(x, dict) else x for x in rsp]
        else:
            yield [x.model_dump() if not isinstance(x, dict) else x for x in rsp]
```

**è°ƒç”¨é“¾è·¯åˆ†æ**:

```mermaid
sequenceDiagram
    participant U as User Code
    participant A as Agent.run()
    participant AR as Agent._run()
    participant LLM as _call_llm()
    participant T as _call_tool()
    
    U->>A: agent.run(messages)
    Note over A: 1. æ¶ˆæ¯é¢„å¤„ç†
    A->>A: æ·±æ‹·è´æ¶ˆæ¯
    A->>A: ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼
    A->>A: è¯­è¨€æ£€æµ‹
    A->>A: æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    
    A->>AR: è°ƒç”¨_run()æŠ½è±¡æ–¹æ³•
    Note over AR: 2. å…·ä½“Agentå®ç°
    
    loop æ¶ˆæ¯å¤„ç†å¾ªç¯
        AR->>LLM: è°ƒç”¨LLMæ¨ç†
        LLM-->>AR: è¿”å›LLMå“åº”
        
        opt å¦‚æœæœ‰å·¥å…·è°ƒç”¨
            AR->>T: æ‰§è¡Œå·¥å…·è°ƒç”¨
            T-->>AR: è¿”å›å·¥å…·ç»“æœ
            AR->>LLM: å‘é€å·¥å…·ç»“æœç»™LLM
            LLM-->>AR: åŸºäºç»“æœç”Ÿæˆå›å¤
        end
    end
    
    AR-->>A: è¿”å›å¤„ç†ç»“æœ
    Note over A: 3. åå¤„ç†
    A->>A: è®¾ç½®ä»£ç†åç§°
    A->>A: æ ¼å¼è½¬æ¢
    A-->>U: æµå¼è¿”å›ç»“æœ
```

#### 1.2 Agent._call_llm() - LLMè°ƒç”¨æ¥å£

**å‡½æ•°ç­¾å**:
```python
def _call_llm(
    self,
    messages: List[Message],
    functions: Optional[List[Dict]] = None,
    stream: bool = True,
    extra_generate_cfg: Optional[dict] = None,
) -> Iterator[List[Message]]:
```

**æºç å®ç°**:
```python
def _call_llm(self, messages: List[Message], functions: Optional[List[Dict]] = None, 
              stream: bool = True, extra_generate_cfg: Optional[dict] = None) -> Iterator[List[Message]]:
    """Agentè°ƒç”¨LLMçš„ç»Ÿä¸€æ¥å£
    
    åŠŸèƒ½è¯´æ˜:
    1. å°†Agentçš„ç³»ç»Ÿæ¶ˆæ¯å‰ç½®åˆ°æ¶ˆæ¯åˆ—è¡¨
    2. è°ƒç”¨LLMçš„chatæ–¹æ³•è¿›è¡Œæ¨ç†
    3. åˆå¹¶ç”Ÿæˆé…ç½®å‚æ•°
    
    å‚æ•°è¯´æ˜:
    - messages: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
    - functions: æä¾›ç»™LLMçš„å‡½æ•°åˆ—è¡¨ï¼ˆç”¨äºå‡½æ•°è°ƒç”¨ï¼‰
    - stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼Œé»˜è®¤ä¸ºTrueä¿è¯ä¸€è‡´æ€§
    - extra_generate_cfg: é¢å¤–çš„ç”Ÿæˆé…ç½®å‚æ•°
    """
    return self.llm.chat(
        messages=messages,
        functions=functions, 
        stream=stream,
        extra_generate_cfg=merge_generate_cfgs(
            base_generate_cfg=self.extra_generate_cfg,  # Agentçº§åˆ«é…ç½®
            new_generate_cfg=extra_generate_cfg,        # è°ƒç”¨æ—¶é…ç½®
        )
    )
```

#### 1.3 Agent._call_tool() - å·¥å…·è°ƒç”¨æ¥å£

**æºç å®ç°**:
```python  
def _call_tool(self, tool_name: str, tool_args: Union[str, dict] = '{}', **kwargs) -> Union[str, List[ContentItem]]:
    """Agentè°ƒç”¨å·¥å…·çš„ç»Ÿä¸€æ¥å£
    
    åŠŸèƒ½è¯´æ˜:
    1. éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨
    2. è°ƒç”¨å…·ä½“å·¥å…·å®ç°
    3. ç»Ÿä¸€å¼‚å¸¸å¤„ç†å’Œé”™è¯¯è¿”å›
    
    å‚æ•°è¯´æ˜:
    - tool_name: å·¥å…·åç§°
    - tool_args: æ¨¡å‹ç”Ÿæˆæˆ–ç”¨æˆ·æä¾›çš„å·¥å…·å‚æ•°
    - **kwargs: ä¼ é€’ç»™å·¥å…·çš„é¢å¤–å‚æ•°
    """
    # 1. å·¥å…·å­˜åœ¨æ€§æ£€æŸ¥
    if tool_name not in self.function_map:
        return f'Tool {tool_name} does not exists.'
    
    tool = self.function_map[tool_name]
    
    try:
        # 2. è°ƒç”¨å·¥å…·æ‰§è¡Œæ–¹æ³•
        tool_result = tool.call(tool_args, **kwargs)
    except (ToolServiceError, DocParserError) as ex:
        # 3. ä¸“é—¨çš„å·¥å…·æœåŠ¡å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
        raise ex
    except Exception as ex:
        # 4. å…¶ä»–å¼‚å¸¸çš„ç»Ÿä¸€å¤„ç†
        exception_type = type(ex).__name__
        exception_message = str(ex)
        traceback_info = ''.join(traceback.format_tb(ex.__traceback__))
        error_message = f'An error occurred when calling tool `{tool_name}`:\n' \
                       f'{exception_type}: {exception_message}\n' \
                       f'Traceback:\n{traceback_info}'
        logger.warning(error_message)
        return error_message
    
    # 5. ç»“æœæ ¼å¼åŒ–å¤„ç†
    if isinstance(tool_result, str):
        return tool_result
    elif isinstance(tool_result, list) and all(isinstance(item, ContentItem) for item in tool_result):
        return tool_result  # å¤šæ¨¡æ€å·¥å…·ç»“æœ
    else:
        return json.dumps(tool_result, ensure_ascii=False, indent=4)
```

### 2. LLMæœåŠ¡API

#### 2.1 get_chat_model() - æ¨¡å‹å·¥å‚æ–¹æ³•

**å‡½æ•°ç­¾å**:
```python
def get_chat_model(cfg: Union[dict, str] = 'qwen-plus') -> BaseChatModel:
```

**å®Œæ•´æºç åˆ†æ**:
```python
def get_chat_model(cfg: Union[dict, str] = 'qwen-plus') -> BaseChatModel:
    """LLMå¯¹è±¡å®ä¾‹åŒ–çš„ç»Ÿä¸€æ¥å£
    
    è¿™ä¸ªæ–¹æ³•æ˜¯æ¡†æ¶çš„æ ¸å¿ƒå·¥å‚æ–¹æ³•ï¼Œè´Ÿè´£æ ¹æ®é…ç½®åˆ›å»ºåˆé€‚çš„LLMå®ä¾‹
    æ”¯æŒå¤šç§é…ç½®æ–¹å¼å’Œè‡ªåŠ¨ç±»å‹æ¨æ–­
    """
    # 1. é…ç½®æ ‡å‡†åŒ–
    if isinstance(cfg, str):
        cfg = {'model': cfg}  # å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—å…¸é…ç½®
    
    # 2. æ˜¾å¼æ¨¡å‹ç±»å‹æŒ‡å®š
    if 'model_type' in cfg:
        model_type = cfg['model_type']
        if model_type in LLM_REGISTRY:
            # ç‰¹æ®Šå¤„ç†ï¼šDashScopeå…¼å®¹æ¨¡å¼
            if model_type in ('oai', 'qwenvl_oai'):
                if cfg.get('model_server', '').strip() == 'dashscope':
                    cfg = copy.deepcopy(cfg)
                    cfg['model_server'] = 'https://dashscope.aliyuncs.com/compatible-mode/v1'
            return LLM_REGISTRY[model_type](cfg)
        else:
            raise ValueError(f'Please set model_type from {str(LLM_REGISTRY.keys())}')
    
    # 3. è‡ªåŠ¨ç±»å‹æ¨æ–­
    # AzureæœåŠ¡æ£€æµ‹
    if 'azure_endpoint' in cfg:
        model_type = 'azure'
        cfg['model_type'] = model_type
        return LLM_REGISTRY[model_type](cfg)
    
    # OpenAIå…¼å®¹æœåŠ¡æ£€æµ‹
    if 'model_server' in cfg:
        if cfg['model_server'].strip().startswith('http'):
            model_type = 'oai'
            cfg['model_type'] = model_type  
            return LLM_REGISTRY[model_type](cfg)
    
    # åŸºäºæ¨¡å‹åç§°æ¨æ–­
    model = cfg.get('model', '')
    
    if '-vl' in model.lower():
        # è§†è§‰è¯­è¨€æ¨¡å‹
        model_type = 'qwenvl_dashscope'
        cfg['model_type'] = model_type
        return LLM_REGISTRY[model_type](cfg)
    
    if '-audio' in model.lower():
        # éŸ³é¢‘æ¨¡å‹
        model_type = 'qwenaudio_dashscope'  
        cfg['model_type'] = model_type
        return LLM_REGISTRY[model_type](cfg)
    
    if 'qwen' in model.lower():
        # Qwenç³»åˆ—æ¨¡å‹
        model_type = 'qwen_dashscope'
        cfg['model_type'] = model_type
        return LLM_REGISTRY[model_type](cfg)
    
    # 4. æ— æ³•æ¨æ–­åˆ™æŠ›å‡ºå¼‚å¸¸
    raise ValueError(f'Invalid model cfg: {cfg}')
```

#### 2.2 BaseChatModel.chat() - æ ¸å¿ƒèŠå¤©æ¥å£

**å‡½æ•°ç­¾å**:
```python
def chat(
    self,
    messages: List[Union[Message, Dict]],
    functions: Optional[List[Dict]] = None,
    stream: bool = True,
    delta_stream: bool = False,
    extra_generate_cfg: Optional[Dict] = None,
) -> Union[List[Message], List[Dict], Iterator[List[Message]], Iterator[List[Dict]]]:
```

**å…³é”®å®ç°é€»è¾‘**:
```python
def chat(self, messages, functions=None, stream=True, delta_stream=False, extra_generate_cfg=None):
    """LLMèŠå¤©çš„æ ¸å¿ƒæ¥å£ï¼Œå¤„ç†æ‰€æœ‰LLMäº¤äº’é€»è¾‘"""
    
    # 1. è¾“å…¥æ¶ˆæ¯ç»Ÿä¸€åŒ–
    messages = copy.deepcopy(messages)
    _return_message_type = 'dict'
    new_messages = []
    for msg in messages:
        if isinstance(msg, dict):
            new_messages.append(Message(**msg))
        else:
            new_messages.append(msg)
            _return_message_type = 'message'
    messages = new_messages
    
    # 2. ç¼“å­˜æŸ¥æ‰¾ 
    if self.cache is not None:
        cache_key = dict(messages=messages, functions=functions, extra_generate_cfg=extra_generate_cfg)
        cache_key: str = json_dumps_compact(cache_key, sort_keys=True)
        cache_value: str = self.cache.get(cache_key)
        if cache_value:
            # ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›
            cache_value: List[dict] = json.loads(cache_value)
            if _return_message_type == 'message':
                cache_value: List[Message] = [Message(**m) for m in cache_value]
            if stream:
                cache_value: Iterator = iter([cache_value])
            return cache_value
    
    # 3. ç”Ÿæˆé…ç½®åˆå¹¶
    generate_cfg = merge_generate_cfgs(base_generate_cfg=self.generate_cfg, new_generate_cfg=extra_generate_cfg)
    
    # 4. éšæœºç§å­è®¾ç½®
    if 'seed' not in generate_cfg:
        generate_cfg['seed'] = random.randint(a=0, b=2**30)
    
    # 5. è¯­è¨€æ£€æµ‹
    if 'lang' in generate_cfg:
        lang: Literal['en', 'zh'] = generate_cfg.pop('lang')
    else:
        lang: Literal['en', 'zh'] = 'zh' if has_chinese_messages(messages) else 'en'
    
    # 6. ç³»ç»Ÿæ¶ˆæ¯æ·»åŠ 
    if DEFAULT_SYSTEM_MESSAGE and messages[0].role != SYSTEM:
        messages = [Message(role=SYSTEM, content=DEFAULT_SYSTEM_MESSAGE)] + messages
    
    # 7. è¾“å…¥é•¿åº¦æˆªæ–­
    max_input_tokens = generate_cfg.pop('max_input_tokens', DEFAULT_MAX_INPUT_TOKENS)
    if max_input_tokens > 0:
        messages = _truncate_input_messages_roughly(messages=messages, max_tokens=max_input_tokens)
    
    # 8. å‡½æ•°è°ƒç”¨æ¨¡å¼æ£€æµ‹
    if functions:
        fncall_mode = True
    else:
        fncall_mode = False
    
    # 9. æ¶ˆæ¯é¢„å¤„ç†
    messages = self._preprocess_messages(messages, lang=lang, generate_cfg=generate_cfg, functions=functions, use_raw_api=self.use_raw_api)
    
    if not self.support_multimodal_input:
        messages = [format_as_text_message(msg, add_upload_info=False) for msg in messages]
    
    # 10. åŸç”ŸAPIæ¨¡å¼
    if self.use_raw_api:
        logger.debug('`use_raw_api` takes effect.')
        assert stream and (not delta_stream), '`use_raw_api` only support full stream!!!'
        return self.raw_chat(messages=messages, functions=functions, stream=stream, generate_cfg=generate_cfg)
    
    # 11. æ¨¡å‹æœåŠ¡è°ƒç”¨
    def _call_model_service():
        if fncall_mode:
            return self._chat_with_functions(messages=messages, functions=functions, stream=stream, delta_stream=delta_stream, generate_cfg=generate_cfg, lang=lang)
        else:
            if messages[-1].role == ASSISTANT:
                # ç»­å†™æ¨¡å¼
                return self._continue_assistant_response(messages, generate_cfg=generate_cfg, stream=stream)
            else:
                return self._chat(messages, stream=stream, delta_stream=delta_stream, generate_cfg=generate_cfg)
    
    # 12. é‡è¯•æœºåˆ¶
    if stream and delta_stream:
        output = _call_model_service()  # å¢é‡æµå¼æ— é‡è¯•
    elif stream and (not delta_stream):
        output = retry_model_service_iterator(_call_model_service, max_retries=self.max_retries)
    else:
        output = retry_model_service(_call_model_service, max_retries=self.max_retries)
    
    # 13. ç»“æœåå¤„ç†å’Œç¼“å­˜
    if isinstance(output, list):
        output = self._postprocess_messages(output, fncall_mode=fncall_mode, generate_cfg=generate_cfg)
        if not self.support_multimodal_output:
            output = _format_as_text_messages(messages=output)
        if self.cache:
            self.cache.set(cache_key, json_dumps_compact(output))
        return self._convert_messages_to_target_type(output, _return_message_type)
    else:
        # æµå¼åå¤„ç†
        output = self._postprocess_messages_iterator(output, fncall_mode=fncall_mode, generate_cfg=generate_cfg)
        # ... æµå¼ç¼“å­˜é€»è¾‘
        return self._convert_messages_iterator_to_target_type(_format_and_cache(), _return_message_type)
```

### 3. å·¥å…·ç³»ç»ŸAPI

#### 3.1 register_tool() - å·¥å…·æ³¨å†Œè£…é¥°å™¨

**æºç å®ç°**:
```python
def register_tool(name, allow_overwrite=False):
    """å·¥å…·æ³¨å†Œè£…é¥°å™¨ï¼Œå®ç°å·¥å…·çš„è‡ªåŠ¨æ³¨å†Œæœºåˆ¶
    
    å‚æ•°è¯´æ˜:
    - name: å·¥å…·åç§°ï¼Œå¿…é¡»å”¯ä¸€
    - allow_overwrite: æ˜¯å¦å…è®¸è¦†ç›–å·²å­˜åœ¨çš„å·¥å…·
    """
    def decorator(cls):
        # 1. é‡å¤æ³¨å†Œæ£€æŸ¥
        if name in TOOL_REGISTRY:
            if allow_overwrite:
                logger.warning(f'Tool `{name}` already exists! Overwriting with class {cls}.')
            else:
                raise ValueError(f'Tool `{name}` already exists! Please ensure that the tool name is unique.')
        
        # 2. åç§°ä¸€è‡´æ€§æ£€æŸ¥
        if cls.name and (cls.name != name):
            raise ValueError(f'{cls.__name__}.name="{cls.name}" conflicts with @register_tool(name="{name}").')
        
        # 3. è®¾ç½®å·¥å…·åç§°å¹¶æ³¨å†Œ
        cls.name = name
        TOOL_REGISTRY[name] = cls
        
        return cls
    
    return decorator
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
@register_tool('weather_query')  
class WeatherTool(BaseTool):
    """å¤©æ°”æŸ¥è¯¢å·¥å…·"""
    description = 'æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯'
    parameters = [{
        'name': 'city',
        'type': 'string',
        'description': 'åŸå¸‚åç§°', 
        'required': True
    }]
    
    def call(self, params: str, **kwargs) -> str:
        """å·¥å…·è°ƒç”¨å®ç°
        
        è¿™ä¸ªæ–¹æ³•ä¼šè¢«Agenté€šè¿‡_call_tool()è°ƒç”¨
        å‚æ•°ä¼šç»è¿‡_verify_json_format_args()éªŒè¯
        """
        # å‚æ•°è§£æå’ŒéªŒè¯
        params_json = self._verify_json_format_args(params)
        city = params_json['city']
        
        # å…·ä½“ä¸šåŠ¡é€»è¾‘
        weather_info = self._query_weather_api(city)
        
        return f"{city}çš„å¤©æ°”ï¼š{weather_info}"
```

### 4. GUIç•Œé¢API

#### 4.1 WebUIç±»åˆå§‹åŒ–

**æºç åˆ†æ**:
```python  
class WebUI:
    def __init__(self, agent: Union[Agent, MultiAgentHub, List[Agent]], chatbot_config: Optional[dict] = None):
        """WebUIåˆå§‹åŒ–æ–¹æ³•
        
        åŠŸèƒ½è¯´æ˜:
        1. æ”¯æŒå•Agentã€å¤šAgent Hubã€Agentåˆ—è¡¨ç­‰å¤šç§è¾“å…¥
        2. é…ç½®ç”¨æˆ·å’ŒAgentçš„æ˜¾ç¤ºä¿¡æ¯
        3. è®¾ç½®ç•Œé¢äº¤äº’å‚æ•°
        """
        chatbot_config = chatbot_config or {}
        
        # 1. Agentç»Ÿä¸€åŒ–å¤„ç†
        if isinstance(agent, MultiAgentHub):
            self.agent_list = [agent for agent in agent.nonuser_agents]  # æ’é™¤ç”¨æˆ·ä»£ç†
            self.agent_hub = agent
        elif isinstance(agent, list):
            self.agent_list = agent
            self.agent_hub = None
        else:
            self.agent_list = [agent]  # å•AgentåŒ…è£…ä¸ºåˆ—è¡¨
            self.agent_hub = None
        
        # 2. ç”¨æˆ·é…ç½®
        user_name = chatbot_config.get('user.name', 'user')
        self.user_config = {
            'name': user_name,
            'avatar': chatbot_config.get('user.avatar', get_avatar_image(user_name)),
        }
        
        # 3. Agenté…ç½®åˆ—è¡¨
        self.agent_config_list = [{
            'name': agent.name,
            'avatar': chatbot_config.get('agent.avatar', get_avatar_image(agent.name)),
            'description': agent.description or "I'm a helpful assistant.",
        } for agent in self.agent_list]
        
        # 4. ç•Œé¢å‚æ•°é…ç½®
        self.input_placeholder = chatbot_config.get('input.placeholder', 'è·Ÿæˆ‘èŠèŠå§ï½')
        self.prompt_suggestions = chatbot_config.get('prompt.suggestions', [])
        self.verbose = chatbot_config.get('verbose', False)
```

## ğŸ”— APIè°ƒç”¨é“¾è·¯æ·±åº¦åˆ†æ

### å®Œæ•´çš„æ¶ˆæ¯å¤„ç†è°ƒç”¨é“¾

```mermaid
graph TD
    A[ç”¨æˆ·è°ƒç”¨ agent.run] --> B[Agent.run æ–¹æ³•]
    B --> C[æ¶ˆæ¯é¢„å¤„ç†]
    C --> C1[æ·±æ‹·è´æ¶ˆæ¯]
    C --> C2[æ ¼å¼ç»Ÿä¸€è½¬æ¢]
    C --> C3[è¯­è¨€è‡ªåŠ¨æ£€æµ‹] 
    C --> C4[æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯]
    
    C --> D[è°ƒç”¨ _run æŠ½è±¡æ–¹æ³•]
    D --> E[å…·ä½“Agentå®ç°]
    
    subgraph "FnCallAgent._run"
        E --> F[åˆå§‹åŒ–å¾ªç¯è®¡æ•°å™¨]
        F --> G[è°ƒç”¨ _call_llm]
        G --> H[LLMæ¨ç†è·å¾—å“åº”]
        H --> I{æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨?}
        
        I -->|Yes| J[è§£æå·¥å…·è°ƒç”¨]
        J --> K[è°ƒç”¨ _call_tool]
        K --> L[æ‰§è¡Œå…·ä½“å·¥å…·é€»è¾‘]
        L --> M[å·¥å…·ç»“æœè¿”å›]
        M --> N[æ·»åŠ åˆ°æ¶ˆæ¯å†å²]
        N --> G
        
        I -->|No| O[ç›´æ¥è¿”å›æ–‡æœ¬å“åº”]
    end
    
    E --> P[æµå¼è¿”å›ç»“æœ]
    P --> Q[è®¾ç½®Agentåç§°]
    Q --> R[æ ¼å¼è½¬æ¢è¿”å›]
```

### LLMè°ƒç”¨çš„è¯¦ç»†é“¾è·¯

```mermaid
sequenceDiagram
    participant A as Agent._call_llm
    participant B as BaseChatModel.chat
    participant C as _preprocess_messages
    participant D as _chat_with_functions
    participant E as Model Service API
    participant F as _postprocess_messages
    
    A->>B: chat(messages, functions, stream=True)
    Note over B: 1. ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼
    
    B->>B: ç¼“å­˜æŸ¥æ‰¾
    alt ç¼“å­˜å‘½ä¸­
        B-->>A: è¿”å›ç¼“å­˜ç»“æœ
    else ç¼“å­˜æœªå‘½ä¸­
        B->>C: æ¶ˆæ¯é¢„å¤„ç†
        C->>C: å¤šæ¨¡æ€æ ¼å¼åŒ–
        C->>C: æ·»åŠ ä¸Šä¼ ä¿¡æ¯ 
        C-->>B: é¢„å¤„ç†å®Œæˆ
        
        B->>D: _chat_with_functions
        D->>E: è°ƒç”¨æ¨¡å‹API
        E-->>D: è¿”å›æ¨¡å‹å“åº”
        D-->>B: è¿”å›å¤„ç†ç»“æœ
        
        B->>F: _postprocess_messages
        F->>F: åœç”¨è¯åå¤„ç†
        F->>F: å¤šæ¨¡æ€æ ¼å¼åŒ–
        F-->>B: åå¤„ç†å®Œæˆ
        
        B->>B: å†™å…¥ç¼“å­˜
        B-->>A: è¿”å›æœ€ç»ˆç»“æœ
    end
```

### å·¥å…·è°ƒç”¨çš„å®Œæ•´é“¾è·¯

```mermaid
sequenceDiagram
    participant A as Agent._call_tool
    participant B as function_map
    participant C as Tool.call
    participant D as Tool._verify_json_format_args
    participant E as å…·ä½“ä¸šåŠ¡é€»è¾‘
    participant F as å¼‚å¸¸å¤„ç†
    
    A->>B: æŸ¥æ‰¾å·¥å…·å®ä¾‹
    alt å·¥å…·ä¸å­˜åœ¨
        B-->>A: è¿”å›é”™è¯¯ä¿¡æ¯
    else å·¥å…·å­˜åœ¨
        B-->>A: è¿”å›å·¥å…·å®ä¾‹
        
        A->>C: tool.call(params, **kwargs)
        C->>D: å‚æ•°éªŒè¯
        D->>D: JSONæ ¼å¼æ£€æŸ¥
        D->>D: å¿…éœ€å‚æ•°éªŒè¯
        D-->>C: éªŒè¯é€šè¿‡
        
        C->>E: æ‰§è¡Œä¸šåŠ¡é€»è¾‘
        
        alt æ‰§è¡ŒæˆåŠŸ
            E-->>C: è¿”å›ç»“æœ
            C-->>A: è¿”å›å·¥å…·ç»“æœ
        else æ‰§è¡Œå¼‚å¸¸
            E->>F: å¼‚å¸¸æ•è·
            F->>F: å¼‚å¸¸ä¿¡æ¯æ ¼å¼åŒ–
            F-->>A: è¿”å›é”™è¯¯ä¿¡æ¯
        end
        
        A->>A: ç»“æœæ ¼å¼åŒ–
        A-->>Agent: è¿”å›æœ€ç»ˆç»“æœ
    end
```

## ğŸ“‹ APIä½¿ç”¨æœ€ä½³å®è·µ

### 1. Agentåˆå§‹åŒ–æœ€ä½³å®è·µ

```python
# âœ… æ¨èçš„Agentåˆå§‹åŒ–æ–¹å¼
def create_assistant():
    """åˆ›å»ºAssistantçš„æœ€ä½³å®è·µ"""
    
    # 1. æ˜ç¡®çš„LLMé…ç½®
    llm_cfg = {
        'model': 'qwen3-235b-a22b',
        'model_type': 'qwen_dashscope',
        'generate_cfg': {
            'top_p': 0.8,
            'max_input_tokens': 6000,  # æ˜ç¡®è®¾ç½®è¾“å…¥é•¿åº¦é™åˆ¶
            'max_retries': 3,          # è®¾ç½®é‡è¯•æ¬¡æ•°
        }
    }
    
    # 2. å·¥å…·åˆ—è¡¨é…ç½®
    tools = [
        'code_interpreter',  # å†…ç½®å·¥å…·ä½¿ç”¨å­—ç¬¦ä¸²
        {                    # å·¥å…·é…ç½®ä½¿ç”¨å­—å…¸
            'name': 'web_search',
            'timeout': 30
        },
        CustomTool()         # è‡ªå®šä¹‰å·¥å…·å®ä¾‹
    ]
    
    # 3. ç³»ç»Ÿæ¶ˆæ¯é…ç½®
    system_msg = '''ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
    1. ä»£ç ç¼–å†™å’Œæ‰§è¡Œ
    2. ç½‘ç»œæœç´¢å’Œä¿¡æ¯æ£€ç´¢
    3. å¤šè½®å¯¹è¯å’Œä¸Šä¸‹æ–‡ç†è§£
    
    è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›å¤é£æ ¼ã€‚'''
    
    # 4. åˆ›å»ºAssistantå®ä¾‹
    agent = Assistant(
        llm=llm_cfg,
        function_list=tools,
        system_message=system_msg,
        name='ä¸“ä¸šåŠ©æ‰‹',
        description='ä¸€ä¸ªå…·å¤‡ä»£ç æ‰§è¡Œå’Œæœç´¢èƒ½åŠ›çš„AIåŠ©æ‰‹'
    )
    
    return agent
```

### 2. æ¶ˆæ¯å¤„ç†æœ€ä½³å®è·µ

```python
# âœ… æ¨èçš„æ¶ˆæ¯å¤„ç†æ–¹å¼
def chat_with_agent(agent, user_input: str, history: List[dict] = None):
    """ä¸Agentå¯¹è¯çš„æœ€ä½³å®è·µ"""
    
    # 1. æ„å»ºæ¶ˆæ¯å†å²
    messages = history or []
    messages.append({'role': 'user', 'content': user_input})
    
    try:
        # 2. æµå¼å¤„ç†å“åº”
        response_text = ""
        for response in agent.run(messages=messages):
            if response:
                # å®æ—¶æ›´æ–°å“åº”å†…å®¹
                response_text = response[-1].get('content', '')
                print(f"\r{response_text}", end='', flush=True)
        
        # 3. æ›´æ–°å†å²è®°å½•
        messages.extend(response)
        print()  # æ¢è¡Œ
        
        return response_text, messages
        
    except Exception as e:
        logger.error(f"Agentæ‰§è¡Œå¼‚å¸¸: {e}")
        return f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}", messages
```

### 3. å·¥å…·å¼€å‘æœ€ä½³å®è·µ

```python
# âœ… æ¨èçš„å·¥å…·å¼€å‘æ¨¡å¼
@register_tool('file_analyzer')
class FileAnalyzerTool(BaseTool):
    """æ–‡ä»¶åˆ†æå·¥å…· - æœ€ä½³å®è·µç¤ºä¾‹"""
    
    description = 'åˆ†ææ–‡ä»¶å†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯'
    parameters = {
        'type': 'object',
        'properties': {
            'file_path': {
                'type': 'string',
                'description': 'è¦åˆ†æçš„æ–‡ä»¶è·¯å¾„'
            },
            'analysis_type': {
                'type': 'string', 
                'enum': ['summary', 'keywords', 'structure'],
                'description': 'åˆ†æç±»å‹ï¼šæ‘˜è¦ã€å…³é”®è¯æˆ–ç»“æ„åˆ†æ'
            }
        },
        'required': ['file_path', 'analysis_type']
    }
    
    def call(self, params: str, **kwargs) -> str:
        """å·¥å…·è°ƒç”¨å®ç°
        
        Args:
            params: JSONæ ¼å¼å‚æ•°å­—ç¬¦ä¸²
            **kwargs: é¢å¤–å‚æ•°ï¼Œå¯èƒ½åŒ…å«messagesç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            str: åˆ†æç»“æœ
        """
        try:
            # 1. å‚æ•°éªŒè¯å’Œè§£æ
            params_dict = self._verify_json_format_args(params)
            file_path = params_dict['file_path']
            analysis_type = params_dict['analysis_type']
            
            # 2. è¾“å…¥åˆæ³•æ€§æ£€æŸ¥  
            if not os.path.exists(file_path):
                return f"é”™è¯¯ï¼šæ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
            
            # 3. æ–‡ä»¶å®‰å…¨æ£€æŸ¥
            if not self._is_safe_file(file_path):
                return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–æ–‡ä»¶è¿‡å¤§"
            
            # 4. æ‰§è¡Œå…·ä½“åˆ†æé€»è¾‘
            if analysis_type == 'summary':
                result = self._generate_summary(file_path)
            elif analysis_type == 'keywords':
                result = self._extract_keywords(file_path)
            elif analysis_type == 'structure':
                result = self._analyze_structure(file_path)
            
            return f"æ–‡ä»¶åˆ†æç»“æœï¼š\n{result}"
            
        except Exception as e:
            # 5. å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
            logger.error(f"æ–‡ä»¶åˆ†æå·¥å…·æ‰§è¡Œå¼‚å¸¸: {e}")
            return f"æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}"
    
    def _is_safe_file(self, file_path: str) -> bool:
        """æ–‡ä»¶å®‰å…¨æ£€æŸ¥"""
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶10MBï¼‰
        if os.path.getsize(file_path) > 10 * 1024 * 1024:
            return False
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.txt', '.md', '.py', '.js', '.json', '.csv'}
        _, ext = os.path.splitext(file_path.lower())
        return ext in allowed_extensions
    
    def _generate_summary(self, file_path: str) -> str:
        """ç”Ÿæˆæ–‡ä»¶æ‘˜è¦"""
        # å…·ä½“å®ç°é€»è¾‘
        pass
```

## ğŸ“Š APIæ€§èƒ½ä¸ç›‘æ§

### æ€§èƒ½ç›‘æ§è£…é¥°å™¨

```python
import time
import functools
from qwen_agent.log import logger

def monitor_api_performance(func):
    """APIæ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"{func.__name__} æ‰§è¡Œå¤±è´¥ ({execution_time:.2f}ç§’): {e}")
            raise
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@monitor_api_performance  
def monitored_agent_run(agent, messages):
    return list(agent.run(messages))
```

### APIä½¿ç”¨ç»Ÿè®¡

```python
class APIUsageTracker:
    """APIä½¿ç”¨ç»Ÿè®¡è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.stats = {
            'agent_calls': 0,
            'llm_calls': 0, 
            'tool_calls': 0,
            'errors': 0
        }
    
    def track_agent_call(self):
        self.stats['agent_calls'] += 1
    
    def track_llm_call(self):
        self.stats['llm_calls'] += 1
        
    def track_tool_call(self):
        self.stats['tool_calls'] += 1
        
    def track_error(self):
        self.stats['errors'] += 1
    
    def get_stats(self):
        return self.stats.copy()

# å…¨å±€å®ä¾‹
usage_tracker = APIUsageTracker()
```

## ğŸ¯ æ€»ç»“

Qwen-Agentæ¡†æ¶çš„APIè®¾è®¡ä½“ç°äº†ä»¥ä¸‹ç‰¹ç‚¹ï¼š

### è®¾è®¡ä¼˜åŠ¿
1. **ç»Ÿä¸€æŠ½è±¡**: é€šè¿‡åŸºç±»å®šä¹‰ç»Ÿä¸€æ¥å£ï¼Œç®€åŒ–ä½¿ç”¨å¤æ‚åº¦
2. **çµæ´»é…ç½®**: æ”¯æŒå¤šç§é…ç½®æ–¹å¼ï¼Œé€‚åº”ä¸åŒä½¿ç”¨åœºæ™¯
3. **æµå¼å¤„ç†**: åŸç”Ÿæ”¯æŒæµå¼è¾“å‡ºï¼Œæä¾›è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒ
4. **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
5. **æ‰©å±•æ€§å¼º**: æ”¯æŒè‡ªå®šä¹‰Agentã€å·¥å…·å’Œæ¨¡å‹

### å…³é”®è°ƒç”¨é“¾è·¯
1. **Agent.run()** â†’ **_run()** â†’ **_call_llm()** â†’ **BaseChatModel.chat()**
2. **å·¥å…·è°ƒç”¨**: **_detect_tool()** â†’ **_call_tool()** â†’ **tool.call()**
3. **æ¶ˆæ¯å¤„ç†**: **é¢„å¤„ç†** â†’ **LLMæ¨ç†** â†’ **åå¤„ç†** â†’ **æµå¼è¿”å›**

### æœ€ä½³å®è·µå»ºè®®
1. æ˜ç¡®é…ç½®LLMå’Œå·¥å…·å‚æ•°
2. ä½¿ç”¨æµå¼å¤„ç†æå‡å“åº”æ€§
3. å®ç°å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
4. æ·»åŠ æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•
5. éµå¾ªå·¥å…·å¼€å‘è§„èŒƒ

---

*æœ¬APIåˆ†ææ–‡æ¡£åŸºäºQwen-Agent v0.0.30ç‰ˆæœ¬ï¼Œæ¶µç›–äº†æ¡†æ¶çš„æ ¸å¿ƒAPIè®¾è®¡å’Œå®ç°åŸç†ã€‚*
