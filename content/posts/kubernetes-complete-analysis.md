# Kubernetes æ¶æ„ä¸æºç å®Œæ•´å‰–æ

## ğŸ“š æ–‡æ¡£æ¦‚è¿°

æœ¬æ–‡æ¡£æ·±å…¥åˆ†æ Kubernetes çš„æ•´ä½“æ¶æ„è®¾è®¡å’Œæ ¸å¿ƒç»„ä»¶æºç å®ç°ï¼Œé€šè¿‡è¯¦ç»†çš„æ¶æ„å›¾ã€æ—¶åºå›¾å’Œæºç åˆ†æï¼Œå¸®åŠ©è¯»è€…å…¨é¢ç†è§£ Kubernetes çš„å·¥ä½œåŸç†å’Œè®¾è®¡æ€æƒ³ã€‚

## ğŸ—ï¸ Kubernetes æ•´ä½“æ¶æ„

### 1.1 é›†ç¾¤æ¶æ„æ¦‚è§ˆ

Kubernetes é‡‡ç”¨ä¸»ä»æ¶æ„æ¨¡å¼ï¼Œç”±æ§åˆ¶å¹³é¢ï¼ˆControl Planeï¼‰å’Œæ•°æ®å¹³é¢ï¼ˆData Planeï¼‰ç»„æˆï¼š

```mermaid
graph TB
    subgraph "Kubernetes é›†ç¾¤å®Œæ•´æ¶æ„"
        subgraph "Control Plane æ§åˆ¶å¹³é¢"
            API[kube-apiserver<br/>APIæœåŠ¡å™¨<br/>- REST APIç½‘å…³<br/>- è®¤è¯æˆæƒ<br/>- æ•°æ®éªŒè¯]
            ETCD[(etcd<br/>åˆ†å¸ƒå¼å­˜å‚¨<br/>- é›†ç¾¤çŠ¶æ€å­˜å‚¨<br/>- é…ç½®æ•°æ®<br/>- æœåŠ¡å‘ç°)]
            SCHED[kube-scheduler<br/>è°ƒåº¦å™¨<br/>- Podè°ƒåº¦å†³ç­–<br/>- èµ„æºåˆ†é…<br/>- è°ƒåº¦ç­–ç•¥]
            CM[kube-controller-manager<br/>æ§åˆ¶å™¨ç®¡ç†å™¨<br/>- çŠ¶æ€åè°ƒ<br/>- èµ„æºç®¡ç†<br/>- è‡ªåŠ¨åŒ–è¿ç»´]
        end
        
        subgraph "Data Plane æ•°æ®å¹³é¢"
            KUBELET[kubelet<br/>èŠ‚ç‚¹ä»£ç†<br/>- Podç”Ÿå‘½å‘¨æœŸç®¡ç†<br/>- å®¹å™¨è¿è¡Œæ—¶äº¤äº’<br/>- èŠ‚ç‚¹çŠ¶æ€ä¸ŠæŠ¥]
            PROXY[kube-proxy<br/>ç½‘ç»œä»£ç†<br/>- æœåŠ¡å‘ç°<br/>- è´Ÿè½½å‡è¡¡<br/>- ç½‘ç»œè§„åˆ™ç®¡ç†]
            RUNTIME[Container Runtime<br/>å®¹å™¨è¿è¡Œæ—¶<br/>- å®¹å™¨ç”Ÿå‘½å‘¨æœŸ<br/>- é•œåƒç®¡ç†<br/>- èµ„æºéš”ç¦»]
        end
        
        subgraph "Add-ons æ’ä»¶ç³»ç»Ÿ"
            DNS[CoreDNS<br/>é›†ç¾¤DNS]
            INGRESS[Ingress Controller<br/>å…¥å£æ§åˆ¶å™¨]
            CNI[CNI Plugin<br/>ç½‘ç»œæ’ä»¶]
            CSI[CSI Driver<br/>å­˜å‚¨æ’ä»¶]
        end
        
        subgraph "External Components å¤–éƒ¨ç»„ä»¶"
            LB[Load Balancer<br/>è´Ÿè½½å‡è¡¡å™¨]
            STORAGE[External Storage<br/>å¤–éƒ¨å­˜å‚¨]
            REGISTRY[Container Registry<br/>é•œåƒä»“åº“]
        end
    end
    
    %% æ§åˆ¶å¹³é¢å†…éƒ¨è¿æ¥
    API <--> ETCD
    API <--> SCHED
    API <--> CM
    
    %% æ§åˆ¶å¹³é¢ä¸æ•°æ®å¹³é¢è¿æ¥
    API <--> KUBELET
    API <--> PROXY
    
    %% æ•°æ®å¹³é¢å†…éƒ¨è¿æ¥
    KUBELET <--> RUNTIME
    KUBELET <--> CNI
    
    %% æ’ä»¶ç³»ç»Ÿè¿æ¥
    DNS <--> API
    INGRESS <--> API
    CSI <--> API
    
    %% å¤–éƒ¨ç»„ä»¶è¿æ¥
    LB <--> INGRESS
    KUBELET <--> REGISTRY
    CSI <--> STORAGE
    
    %% æ ·å¼å®šä¹‰
    classDef controlPlane fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef dataPlane fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef addons fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef external fill:#fff3e0,stroke:#e65100,stroke-width:2px
    
    class API,ETCD,SCHED,CM controlPlane
    class KUBELET,PROXY,RUNTIME dataPlane
    class DNS,INGRESS,CNI,CSI addons
    class LB,STORAGE,REGISTRY external
```

### 1.2 ç»„ä»¶èŒè´£è¯¦è§£

#### æ§åˆ¶å¹³é¢ç»„ä»¶

**kube-apiserverï¼ˆAPIæœåŠ¡å™¨ï¼‰**
- **æ ¸å¿ƒåŠŸèƒ½**ï¼šä½œä¸ºé›†ç¾¤çš„ç»Ÿä¸€å…¥å£ï¼Œæä¾› RESTful API æ¥å£
- **ä¸»è¦èŒè´£**ï¼š
  - å¤„ç†æ‰€æœ‰ REST API è¯·æ±‚ï¼ˆCRUD æ“ä½œï¼‰
  - æ‰§è¡Œè®¤è¯ã€æˆæƒå’Œå‡†å…¥æ§åˆ¶
  - æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–/ååºåˆ—åŒ–
  - ä¸ etcd äº¤äº’ï¼ŒæŒä¹…åŒ–é›†ç¾¤çŠ¶æ€
  - æä¾› Watch æœºåˆ¶ï¼Œæ”¯æŒäº‹ä»¶é€šçŸ¥

**etcdï¼ˆåˆ†å¸ƒå¼å­˜å‚¨ï¼‰**
- **æ ¸å¿ƒåŠŸèƒ½**ï¼šåˆ†å¸ƒå¼é”®å€¼å­˜å‚¨ï¼Œä¿å­˜é›†ç¾¤çš„æ‰€æœ‰æ•°æ®
- **ä¸»è¦èŒè´£**ï¼š
  - å­˜å‚¨é›†ç¾¤é…ç½®ä¿¡æ¯å’ŒçŠ¶æ€æ•°æ®
  - æä¾›å¼ºä¸€è‡´æ€§ä¿è¯
  - æ”¯æŒ Watch æœºåˆ¶ï¼Œå®ç°äº‹ä»¶é€šçŸ¥
  - æä¾›åˆ†å¸ƒå¼é”å’Œé€‰ä¸»åŠŸèƒ½

**kube-schedulerï¼ˆè°ƒåº¦å™¨ï¼‰**
- **æ ¸å¿ƒåŠŸèƒ½**ï¼šè´Ÿè´£ Pod çš„è°ƒåº¦å†³ç­–
- **ä¸»è¦èŒè´£**ï¼š
  - ç›‘å¬æœªè°ƒåº¦çš„ Pod
  - æ ¹æ®è°ƒåº¦ç­–ç•¥é€‰æ‹©æœ€é€‚åˆçš„èŠ‚ç‚¹
  - è€ƒè™‘èµ„æºéœ€æ±‚ã€çº¦æŸæ¡ä»¶å’Œç­–ç•¥
  - å°†è°ƒåº¦å†³ç­–å†™å…¥ API Server

**kube-controller-managerï¼ˆæ§åˆ¶å™¨ç®¡ç†å™¨ï¼‰**
- **æ ¸å¿ƒåŠŸèƒ½**ï¼šè¿è¡Œå„ç§æ§åˆ¶å™¨ï¼Œå®ç°å£°æ˜å¼ç®¡ç†
- **ä¸»è¦èŒè´£**ï¼š
  - ç›‘æ§é›†ç¾¤çŠ¶æ€å˜åŒ–
  - æ‰§è¡Œæ§åˆ¶å¾ªç¯ï¼Œç¡®ä¿æœŸæœ›çŠ¶æ€ä¸å®é™…çŠ¶æ€ä¸€è‡´
  - ç®¡ç†å„ç§èµ„æºçš„ç”Ÿå‘½å‘¨æœŸ
  - å¤„ç†èŠ‚ç‚¹æ•…éšœå’Œè‡ªåŠ¨æ¢å¤

#### æ•°æ®å¹³é¢ç»„ä»¶

**kubeletï¼ˆèŠ‚ç‚¹ä»£ç†ï¼‰**
- **æ ¸å¿ƒåŠŸèƒ½**ï¼šæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„ä¸»è¦ä»£ç†ï¼Œç®¡ç† Pod å’Œå®¹å™¨
- **ä¸»è¦èŒè´£**ï¼š
  - ç®¡ç† Pod çš„ç”Ÿå‘½å‘¨æœŸ
  - ä¸å®¹å™¨è¿è¡Œæ—¶äº¤äº’
  - ç›‘æ§èŠ‚ç‚¹å’Œ Pod çŠ¶æ€
  - æ‰§è¡Œå¥åº·æ£€æŸ¥å’Œèµ„æºç›‘æ§

**kube-proxyï¼ˆç½‘ç»œä»£ç†ï¼‰**
- **æ ¸å¿ƒåŠŸèƒ½**ï¼šå®ç° Service çš„ç½‘ç»œä»£ç†å’Œè´Ÿè½½å‡è¡¡
- **ä¸»è¦èŒè´£**ï¼š
  - ç»´æŠ¤ç½‘ç»œè§„åˆ™ï¼ˆiptables/IPVSï¼‰
  - å®ç°æœåŠ¡å‘ç°å’Œè´Ÿè½½å‡è¡¡
  - å¤„ç†é›†ç¾¤å†…éƒ¨ç½‘ç»œé€šä¿¡
  - æ”¯æŒå¤šç§ä»£ç†æ¨¡å¼

### 1.3 æ ¸å¿ƒå·¥ä½œæµç¨‹

#### Pod åˆ›å»ºå®Œæ•´æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·/kubectl
    participant API as kube-apiserver
    participant ETCD as etcd
    participant SCHED as kube-scheduler
    participant CM as controller-manager
    participant KUBELET as kubelet
    participant RUNTIME as container-runtime
    participant PROXY as kube-proxy

    Note over User,PROXY: Pod åˆ›å»ºå®Œæ•´æµç¨‹

    %% 1. ç”¨æˆ·æäº¤è¯·æ±‚
    User->>+API: 1. POST /api/v1/namespaces/default/pods
    Note right of User: ç”¨æˆ·é€šè¿‡ kubectl åˆ›å»º Pod

    %% 2. API Server å¤„ç†
    API->>API: 2. è®¤è¯ã€æˆæƒã€å‡†å…¥æ§åˆ¶
    API->>+ETCD: 3. å­˜å‚¨ Pod å¯¹è±¡
    ETCD-->>-API: 4. ç¡®è®¤å­˜å‚¨æˆåŠŸ
    API-->>-User: 5. è¿”å›åˆ›å»ºæˆåŠŸå“åº”

    %% 3. Scheduler è°ƒåº¦
    SCHED->>+API: 6. Watch æœªè°ƒåº¦ Pod
    API-->>-SCHED: 7. é€šçŸ¥æ–° Pod äº‹ä»¶
    SCHED->>SCHED: 8. æ‰§è¡Œè°ƒåº¦ç®—æ³•
    SCHED->>+API: 9. æ›´æ–° Pod.spec.nodeName
    API->>+ETCD: 10. æ›´æ–° Pod è°ƒåº¦ä¿¡æ¯
    ETCD-->>-API: 11. ç¡®è®¤æ›´æ–°æˆåŠŸ
    API-->>-SCHED: 12. ç¡®è®¤è°ƒåº¦æˆåŠŸ

    %% 4. Kubelet æ‰§è¡Œ
    KUBELET->>+API: 13. Watch åˆ†é…åˆ°æœ¬èŠ‚ç‚¹çš„ Pod
    API-->>-KUBELET: 14. é€šçŸ¥ Pod è°ƒåº¦äº‹ä»¶
    KUBELET->>KUBELET: 15. å‡†å¤‡ Pod è¿è¡Œç¯å¢ƒ
    KUBELET->>+RUNTIME: 16. åˆ›å»ºå®¹å™¨
    RUNTIME-->>-KUBELET: 17. å®¹å™¨åˆ›å»ºæˆåŠŸ
    KUBELET->>+API: 18. æ›´æ–° Pod çŠ¶æ€ä¸º Running
    API->>+ETCD: 19. æŒä¹…åŒ– Pod çŠ¶æ€
    ETCD-->>-API: 20. ç¡®è®¤çŠ¶æ€æ›´æ–°
    API-->>-KUBELET: 21. ç¡®è®¤çŠ¶æ€æ›´æ–°æˆåŠŸ

    %% 5. ç½‘ç»œé…ç½®ï¼ˆå¦‚æœæ˜¯ Serviceï¼‰
    alt å¦‚æœ Pod å±äº Service
        CM->>+API: 22. Watch Service å’Œ Endpoints
        API-->>-CM: 23. é€šçŸ¥ Pod çŠ¶æ€å˜åŒ–
        CM->>+API: 24. æ›´æ–° Endpoints å¯¹è±¡
        API->>+ETCD: 25. å­˜å‚¨ Endpoints æ›´æ–°
        ETCD-->>-API: 26. ç¡®è®¤å­˜å‚¨æˆåŠŸ
        API-->>-CM: 27. ç¡®è®¤ Endpoints æ›´æ–°

        PROXY->>+API: 28. Watch Service å’Œ Endpoints
        API-->>-PROXY: 29. é€šçŸ¥ Endpoints å˜åŒ–
        PROXY->>PROXY: 30. æ›´æ–°ç½‘ç»œè§„åˆ™ï¼ˆiptables/IPVSï¼‰
    end

    Note over User,PROXY: Pod æˆåŠŸè¿è¡Œï¼ŒæœåŠ¡å¯è®¿é—®
```

#### Service è®¿é—®æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant CLIENT as å®¢æˆ·ç«¯
    participant PROXY as kube-proxy
    participant IPTABLES as iptables/IPVS
    participant POD1 as Pod-1
    participant POD2 as Pod-2
    participant POD3 as Pod-3

    Note over CLIENT,POD3: Service è´Ÿè½½å‡è¡¡è®¿é—®æµç¨‹

    CLIENT->>+PROXY: 1. è®¿é—® Service IP:Port
    Note right of CLIENT: å®¢æˆ·ç«¯è®¿é—® Service VIP

    PROXY->>IPTABLES: 2. æŸ¥è¯¢è´Ÿè½½å‡è¡¡è§„åˆ™
    IPTABLES->>IPTABLES: 3. æ‰§è¡Œè´Ÿè½½å‡è¡¡ç®—æ³•
    Note right of IPTABLES: æ ¹æ®é…ç½®çš„ç®—æ³•é€‰æ‹©åç«¯ Pod

    alt é€‰æ‹© Pod-1
        IPTABLES->>POD1: 4a. è½¬å‘è¯·æ±‚åˆ° Pod-1
        POD1-->>IPTABLES: 5a. è¿”å›å“åº”
    else é€‰æ‹© Pod-2
        IPTABLES->>POD2: 4b. è½¬å‘è¯·æ±‚åˆ° Pod-2
        POD2-->>IPTABLES: 5b. è¿”å›å“åº”
    else é€‰æ‹© Pod-3
        IPTABLES->>POD3: 4c. è½¬å‘è¯·æ±‚åˆ° Pod-3
        POD3-->>IPTABLES: 5c. è¿”å›å“åº”
    end

    IPTABLES-->>PROXY: 6. è½¬å‘å“åº”
    PROXY-->>-CLIENT: 7. è¿”å›æœ€ç»ˆå“åº”

    Note over CLIENT,POD3: å®ç°é€æ˜çš„è´Ÿè½½å‡è¡¡è®¿é—®
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶æºç å…¥å£åˆ†æ

### 2.1 ç»„ä»¶å¯åŠ¨å…¥å£

æ‰€æœ‰æ ¸å¿ƒç»„ä»¶éƒ½éµå¾ªç›¸ä¼¼çš„å¯åŠ¨æ¨¡å¼ï¼š

```go
// é€šç”¨å¯åŠ¨æ¨¡å¼ï¼ˆä»¥ kube-apiserver ä¸ºä¾‹ï¼‰
func main() {
    // 1. åˆ›å»ºå‘½ä»¤å¯¹è±¡
    command := app.NewAPIServerCommand()
    
    // 2. æ‰§è¡Œå‘½ä»¤
    code := cli.Run(command)
    
    // 3. é€€å‡ºç¨‹åº
    os.Exit(code)
}
```

#### kube-apiserver å¯åŠ¨å…¥å£

```go
// cmd/kube-apiserver/apiserver.go
/*
APIServer æ˜¯é›†ç¾¤çš„ä¸»è¦ API æœåŠ¡å™¨å’Œä¸»æ§èŠ‚ç‚¹ã€‚
å®ƒè´Ÿè´£æä¾›é›†ç¾¤ç®¡ç† API æœåŠ¡ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. æä¾› RESTful API æ¥å£
2. æ‰§è¡Œè®¤è¯ã€æˆæƒå’Œå‡†å…¥æ§åˆ¶
3. æ•°æ®éªŒè¯å’ŒæŒä¹…åŒ–
4. äº‹ä»¶é€šçŸ¥å’Œ Watch æœºåˆ¶
*/
package main

import (
    "os"
    _ "time/tzdata" // ä¸º CronJob æä¾›æ—¶åŒºæ”¯æŒ

    "k8s.io/component-base/cli"
    _ "k8s.io/component-base/logs/json/register"          // JSON æ—¥å¿—æ ¼å¼æ³¨å†Œ
    _ "k8s.io/component-base/metrics/prometheus/clientgo" // Prometheus å®¢æˆ·ç«¯æŒ‡æ ‡
    _ "k8s.io/component-base/metrics/prometheus/version"  // ç‰ˆæœ¬æŒ‡æ ‡æ³¨å†Œ
    "k8s.io/kubernetes/cmd/kube-apiserver/app"
)

func main() {
    // åˆ›å»º API Server å‘½ä»¤å¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰é…ç½®é€‰é¡¹å’Œå¯åŠ¨é€»è¾‘
    command := app.NewAPIServerCommand()
    
    // æ‰§è¡Œå‘½ä»¤ï¼Œå¯åŠ¨ API Server
    code := cli.Run(command)
    
    // æ ¹æ®æ‰§è¡Œç»“æœé€€å‡ºç¨‹åº
    os.Exit(code)
}
```

#### kube-controller-manager å¯åŠ¨å…¥å£

```go
// cmd/kube-controller-manager/controller-manager.go
/*
æ§åˆ¶å™¨ç®¡ç†å™¨è´Ÿè´£ç›‘æ§å¤åˆ¶æ§åˆ¶å™¨ï¼Œå¹¶åˆ›å»ºç›¸åº”çš„ Pod æ¥è¾¾åˆ°æœŸæœ›çŠ¶æ€ã€‚
å®ƒä½¿ç”¨ API æ¥ç›‘å¬æ–°çš„æ§åˆ¶å™¨å¹¶åˆ›å»º/åˆ é™¤ Podã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. è¿è¡Œå„ç§å†…ç½®æ§åˆ¶å™¨
2. ç›‘æ§é›†ç¾¤çŠ¶æ€å˜åŒ–
3. æ‰§è¡ŒçŠ¶æ€åè°ƒé€»è¾‘
4. å¤„ç†èµ„æºç”Ÿå‘½å‘¨æœŸç®¡ç†
*/
package main

import (
    "os"
    _ "time/tzdata" // ä¸º CronJob æ—¶åŒºæ”¯æŒ

    "k8s.io/component-base/cli"
    _ "k8s.io/component-base/logs/json/register"          // JSON æ—¥å¿—æ ¼å¼æ³¨å†Œ
    _ "k8s.io/component-base/metrics/prometheus/clientgo" // Prometheus å®¢æˆ·ç«¯æ’ä»¶
    _ "k8s.io/component-base/metrics/prometheus/version"  // ç‰ˆæœ¬æŒ‡æ ‡æ³¨å†Œ
    "k8s.io/kubernetes/cmd/kube-controller-manager/app"
)

func main() {
    // åˆ›å»ºæ§åˆ¶å™¨ç®¡ç†å™¨å‘½ä»¤å¯¹è±¡
    command := app.NewControllerManagerCommand()
    
    // æ‰§è¡Œå‘½ä»¤ï¼Œå¯åŠ¨æ‰€æœ‰æ§åˆ¶å™¨
    code := cli.Run(command)
    
    // é€€å‡ºç¨‹åº
    os.Exit(code)
}
```

#### kube-scheduler å¯åŠ¨å…¥å£

```go
// cmd/kube-scheduler/scheduler.go
/*
è°ƒåº¦å™¨è´Ÿè´£å°† Pod è°ƒåº¦åˆ°åˆé€‚çš„èŠ‚ç‚¹ä¸Šã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ç›‘å¬æœªè°ƒåº¦çš„ Pod
2. æ‰§è¡Œè°ƒåº¦ç®—æ³•å’Œç­–ç•¥
3. é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹
4. æ›´æ–° Pod çš„è°ƒåº¦ä¿¡æ¯
*/
package main

import (
    "os"

    "k8s.io/component-base/cli"
    _ "k8s.io/component-base/logs/json/register" // JSON æ—¥å¿—æ ¼å¼æ³¨å†Œ
    _ "k8s.io/component-base/metrics/prometheus/clientgo"
    _ "k8s.io/component-base/metrics/prometheus/version" // ç‰ˆæœ¬æŒ‡æ ‡æ³¨å†Œ
    "k8s.io/kubernetes/cmd/kube-scheduler/app"
)

func main() {
    // åˆ›å»ºè°ƒåº¦å™¨å‘½ä»¤å¯¹è±¡
    command := app.NewSchedulerCommand()
    
    // æ‰§è¡Œè°ƒåº¦å™¨
    code := cli.Run(command)
    
    // é€€å‡ºç¨‹åº
    os.Exit(code)
}
```

#### kubelet å¯åŠ¨å…¥å£

```go
// cmd/kubelet/kubelet.go
/*
kubelet äºŒè¿›åˆ¶æ–‡ä»¶è´Ÿè´£ç»´æŠ¤ç‰¹å®šä¸»æœº VM ä¸Šçš„ä¸€ç»„å®¹å™¨ã€‚
å®ƒä»é…ç½®æ–‡ä»¶å’Œ etcd æœåŠ¡å™¨çš„æ³•å®šäººæ•°åŒæ­¥æ•°æ®ã€‚
ç„¶åä¸å®¹å™¨è¿è¡Œæ—¶ï¼ˆæˆ–è¿è¡Œæ—¶çš„ CRI shimï¼‰é€šä¿¡ä»¥æŸ¥çœ‹å½“å‰è¿è¡Œçš„å†…å®¹ã€‚
å®ƒé€šè¿‡å¯åŠ¨æˆ–åœæ­¢å®¹å™¨æ¥åŒæ­¥é…ç½®æ•°æ®ä¸æ­£åœ¨è¿è¡Œçš„å®¹å™¨é›†ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. Pod ç”Ÿå‘½å‘¨æœŸç®¡ç†
2. å®¹å™¨è¿è¡Œæ—¶äº¤äº’
3. èŠ‚ç‚¹çŠ¶æ€ç›‘æ§å’Œä¸ŠæŠ¥
4. èµ„æºç®¡ç†å’Œå¥åº·æ£€æŸ¥
*/
package main

import (
    "context"
    "os"

    "k8s.io/component-base/cli"
    _ "k8s.io/component-base/logs/json/register"          // JSON æ—¥å¿—æ ¼å¼æ³¨å†Œ
    _ "k8s.io/component-base/metrics/prometheus/clientgo" // å®¢æˆ·ç«¯æŒ‡æ ‡æ³¨å†Œ
    _ "k8s.io/component-base/metrics/prometheus/version"  // ç‰ˆæœ¬æŒ‡æ ‡æ³¨å†Œ
    "k8s.io/kubernetes/cmd/kubelet/app"
)

func main() {
    // åˆ›å»º kubelet å‘½ä»¤å¯¹è±¡ï¼Œä¼ å…¥ä¸Šä¸‹æ–‡
    command := app.NewKubeletCommand(context.Background())
    
    // æ‰§è¡Œ kubelet
    code := cli.Run(command)
    
    // é€€å‡ºç¨‹åº
    os.Exit(code)
}
```

#### kube-proxy å¯åŠ¨å…¥å£

```go
// cmd/kube-proxy/proxy.go
/*
kube-proxy å®ç° Kubernetes Service çš„ç½‘ç»œä»£ç†åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ç»´æŠ¤ç½‘ç»œè§„åˆ™ï¼ˆiptables/IPVSï¼‰
2. å®ç°æœåŠ¡å‘ç°å’Œè´Ÿè½½å‡è¡¡
3. å¤„ç†é›†ç¾¤ç½‘ç»œé€šä¿¡
4. æ”¯æŒå¤šç§ä»£ç†æ¨¡å¼
*/
package main

import (
    "os"

    "k8s.io/component-base/cli"
    _ "k8s.io/component-base/logs/json/register"
    _ "k8s.io/component-base/metrics/prometheus/clientgo" // å®¢æˆ·ç«¯æŒ‡æ ‡æ³¨å†Œ
    _ "k8s.io/component-base/metrics/prometheus/version"  // ç‰ˆæœ¬æŒ‡æ ‡æ³¨å†Œ
    "k8s.io/kubernetes/cmd/kube-proxy/app"
)

func main() {
    // åˆ›å»ºä»£ç†å‘½ä»¤å¯¹è±¡
    command := app.NewProxyCommand()
    
    // æ‰§è¡Œä»£ç†
    code := cli.Run(command)
    
    // é€€å‡ºç¨‹åº
    os.Exit(code)
}
```

### 2.2 ç»„ä»¶é—´é€šä¿¡æ¨¡å¼

```mermaid
graph LR
    subgraph "é€šä¿¡æ¨¡å¼"
        A[HTTP/HTTPS REST API] --> B[gRPC]
        B --> C[etcd Client]
        C --> D[Watch æœºåˆ¶]
        D --> E[Event é€šçŸ¥]
    end
    
    subgraph "å®‰å…¨æœºåˆ¶"
        F[TLS åŠ å¯†] --> G[è¯ä¹¦è®¤è¯]
        G --> H[RBAC æˆæƒ]
        H --> I[å‡†å…¥æ§åˆ¶]
    end
    
    subgraph "æ•°æ®æµå‘"
        J[Client] --> K[API Server]
        K --> L[etcd]
        K --> M[Controller]
        K --> N[Scheduler]
        K --> O[Kubelet]
    end
```

## ğŸ“Š å…³é”®æ•°æ®ç»“æ„

### 3.1 æ ¸å¿ƒ API å¯¹è±¡

#### Pod æ•°æ®ç»“æ„

```go
// staging/src/k8s.io/api/core/v1/types.go
/*
Pod æ˜¯ Kubernetes ä¸­æœ€å°çš„å¯éƒ¨ç½²å•å…ƒï¼ŒåŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ã€‚

æ ¸å¿ƒå­—æ®µè¯´æ˜ï¼š
- TypeMeta: API ç‰ˆæœ¬å’Œç±»å‹ä¿¡æ¯
- ObjectMeta: å¯¹è±¡å…ƒæ•°æ®ï¼ˆåç§°ã€å‘½åç©ºé—´ã€æ ‡ç­¾ç­‰ï¼‰
- Spec: æœŸæœ›çŠ¶æ€è§„èŒƒ
- Status: å½“å‰å®é™…çŠ¶æ€
*/
type Pod struct {
    metav1.TypeMeta   `json:",inline"`
    metav1.ObjectMeta `json:"metadata,omitempty" protobuf:"bytes,1,opt,name=metadata"`
    
    // Spec å®šä¹‰äº† Pod çš„æœŸæœ›è¡Œä¸º
    Spec PodSpec `json:"spec,omitempty" protobuf:"bytes,2,opt,name=spec"`
    
    // Status è¡¨ç¤º Pod çš„å½“å‰çŠ¶æ€ä¿¡æ¯
    Status PodStatus `json:"status,omitempty" protobuf:"bytes,3,opt,name=status"`
}

/*
PodSpec æè¿°äº† Pod çš„æœŸæœ›çŠ¶æ€å’Œè¡Œä¸ºã€‚

å…³é”®å­—æ®µï¼š
- Containers: å®¹å™¨åˆ—è¡¨
- RestartPolicy: é‡å¯ç­–ç•¥
- NodeName: è°ƒåº¦åˆ°çš„èŠ‚ç‚¹åç§°
- Volumes: å­˜å‚¨å·å®šä¹‰
*/
type PodSpec struct {
    // å®¹å™¨åˆ—è¡¨ï¼Œè‡³å°‘åŒ…å«ä¸€ä¸ªå®¹å™¨
    Containers []Container `json:"containers" protobuf:"bytes,2,rep,name=containers"`
    
    // é‡å¯ç­–ç•¥ï¼šAlwaysã€OnFailureã€Never
    RestartPolicy RestartPolicy `json:"restartPolicy,omitempty" protobuf:"bytes,3,opt,name=restartPolicy,casttype=RestartPolicy"`
    
    // è°ƒåº¦åˆ°çš„èŠ‚ç‚¹åç§°
    NodeName string `json:"nodeName,omitempty" protobuf:"bytes,10,opt,name=nodeName"`
    
    // å­˜å‚¨å·å®šä¹‰
    Volumes []Volume `json:"volumes,omitempty" patchStrategy:"merge,retainKeys" patchMergeKey:"name" protobuf:"bytes,1,rep,name=volumes"`
    
    // æœåŠ¡è´¦æˆ·åç§°
    ServiceAccountName string `json:"serviceAccountName,omitempty" protobuf:"bytes,8,opt,name=serviceAccountName"`
}

/*
PodStatus è¡¨ç¤º Pod çš„å½“å‰çŠ¶æ€ä¿¡æ¯ã€‚

çŠ¶æ€å­—æ®µï¼š
- Phase: Pod ç”Ÿå‘½å‘¨æœŸé˜¶æ®µ
- Conditions: çŠ¶æ€æ¡ä»¶åˆ—è¡¨
- ContainerStatuses: å®¹å™¨çŠ¶æ€åˆ—è¡¨
- PodIP: Pod IP åœ°å€
*/
type PodStatus struct {
    // Pod ç”Ÿå‘½å‘¨æœŸé˜¶æ®µï¼šPendingã€Runningã€Succeededã€Failedã€Unknown
    Phase PodPhase `json:"phase,omitempty" protobuf:"bytes,1,opt,name=phase,casttype=PodPhase"`
    
    // çŠ¶æ€æ¡ä»¶åˆ—è¡¨
    Conditions []PodCondition `json:"conditions,omitempty" patchStrategy:"merge" patchMergeKey:"type" protobuf:"bytes,2,rep,name=conditions"`
    
    // å®¹å™¨çŠ¶æ€åˆ—è¡¨
    ContainerStatuses []ContainerStatus `json:"containerStatuses,omitempty" protobuf:"bytes,8,rep,name=containerStatuses"`
    
    // Pod IP åœ°å€
    PodIP string `json:"podIP,omitempty" protobuf:"bytes,6,opt,name=podIP"`
    
    // å¯åŠ¨æ—¶é—´
    StartTime *metav1.Time `json:"startTime,omitempty" protobuf:"bytes,7,opt,name=startTime"`
}
```

#### Service æ•°æ®ç»“æ„

```go
/*
Service å®šä¹‰äº†ä¸€ç»„ Pod çš„é€»è¾‘é›†åˆå’Œè®¿é—®ç­–ç•¥ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- æœåŠ¡å‘ç°å’Œè´Ÿè½½å‡è¡¡
- ç½‘ç»œæŠ½è±¡å’Œç«¯å£æ˜ å°„
- ä¼šè¯äº²å’Œæ€§
*/
type Service struct {
    metav1.TypeMeta   `json:",inline"`
    metav1.ObjectMeta `json:"metadata,omitempty" protobuf:"bytes,1,opt,name=metadata"`
    
    // Spec å®šä¹‰äº†æœåŠ¡çš„æœŸæœ›è¡Œä¸º
    Spec ServiceSpec `json:"spec,omitempty" protobuf:"bytes,2,opt,name=spec"`
    
    // Status è¡¨ç¤ºæœåŠ¡çš„å½“å‰çŠ¶æ€
    Status ServiceStatus `json:"status,omitempty" protobuf:"bytes,3,opt,name=status"`
}

/*
ServiceSpec æè¿°äº†æœåŠ¡çš„æœŸæœ›çŠ¶æ€ã€‚

å…³é”®é…ç½®ï¼š
- Selector: Pod é€‰æ‹©å™¨
- Ports: ç«¯å£æ˜ å°„
- Type: æœåŠ¡ç±»å‹
- ClusterIP: é›†ç¾¤å†…éƒ¨ IP
*/
type ServiceSpec struct {
    // Pod é€‰æ‹©å™¨ï¼Œç”¨äºç¡®å®šæœåŠ¡åç«¯
    Selector map[string]string `json:"selector,omitempty" protobuf:"bytes,1,rep,name=selector"`
    
    // ç«¯å£æ˜ å°„åˆ—è¡¨
    Ports []ServicePort `json:"ports,omitempty" patchStrategy:"merge" patchMergeKey:"port" protobuf:"bytes,1,rep,name=ports"`
    
    // æœåŠ¡ç±»å‹ï¼šClusterIPã€NodePortã€LoadBalancerã€ExternalName
    Type ServiceType `json:"type,omitempty" protobuf:"bytes,4,opt,name=type,casttype=ServiceType"`
    
    // é›†ç¾¤å†…éƒ¨ IP åœ°å€
    ClusterIP string `json:"clusterIP,omitempty" protobuf:"bytes,3,opt,name=clusterIP"`
    
    // ä¼šè¯äº²å’Œæ€§ï¼šNoneã€ClientIP
    SessionAffinity ServiceAffinity `json:"sessionAffinity,omitempty" protobuf:"bytes,7,opt,name=sessionAffinity,casttype=ServiceAffinity"`
}
```

### 3.2 æ ¸å¿ƒæ•°æ®ç»“æ„ UML å›¾

```mermaid
classDiagram
    class Pod {
        +TypeMeta
        +ObjectMeta
        +PodSpec spec
        +PodStatus status
        +GetName() string
        +GetNamespace() string
        +GetLabels() map[string]string
    }
    
    class PodSpec {
        +[]Container containers
        +RestartPolicy restartPolicy
        +string nodeName
        +[]Volume volumes
        +string serviceAccountName
        +int64 terminationGracePeriodSeconds
    }
    
    class PodStatus {
        +PodPhase phase
        +[]PodCondition conditions
        +[]ContainerStatus containerStatuses
        +string podIP
        +Time startTime
        +string qosClass
    }
    
    class Container {
        +string name
        +string image
        +[]string command
        +[]string args
        +[]EnvVar env
        +ResourceRequirements resources
        +[]VolumeMount volumeMounts
    }
    
    class Service {
        +TypeMeta
        +ObjectMeta
        +ServiceSpec spec
        +ServiceStatus status
    }
    
    class ServiceSpec {
        +map[string]string selector
        +[]ServicePort ports
        +ServiceType type
        +string clusterIP
        +ServiceAffinity sessionAffinity
    }
    
    class Node {
        +TypeMeta
        +ObjectMeta
        +NodeSpec spec
        +NodeStatus status
    }
    
    class NodeStatus {
        +[]NodeCondition conditions
        +NodeSystemInfo nodeInfo
        +ResourceList capacity
        +ResourceList allocatable
        +[]ContainerImage images
    }
    
    Pod ||--|| PodSpec : contains
    Pod ||--|| PodStatus : contains
    PodSpec ||--o{ Container : contains
    Service ||--|| ServiceSpec : contains
    Node ||--|| NodeStatus : contains
    
    Pod --> Node : scheduled on
    Service --> Pod : selects
```

## ğŸ”„ æ§åˆ¶å¾ªç¯æ¨¡å¼

### 4.1 æ§åˆ¶å™¨æ¨¡å¼åŸç†

Kubernetes é‡‡ç”¨æ§åˆ¶å™¨æ¨¡å¼å®ç°å£°æ˜å¼ç®¡ç†ï¼š

```mermaid
graph LR
    subgraph "æ§åˆ¶å¾ªç¯"
        A[è§‚å¯Ÿå½“å‰çŠ¶æ€] --> B[ä¸æœŸæœ›çŠ¶æ€æ¯”è¾ƒ]
        B --> C[è®¡ç®—å·®å¼‚]
        C --> D[æ‰§è¡Œè°ƒèŠ‚åŠ¨ä½œ]
        D --> A
    end
    
    subgraph "çŠ¶æ€å­˜å‚¨"
        E[etcd] --> F[æœŸæœ›çŠ¶æ€]
        E --> G[å½“å‰çŠ¶æ€]
    end
    
    subgraph "äº‹ä»¶é©±åŠ¨"
        H[Watch API] --> I[äº‹ä»¶é€šçŸ¥]
        I --> J[è§¦å‘æ§åˆ¶å¾ªç¯]
    end
    
    F --> B
    G --> B
    H --> A
```

### 4.2 å…¸å‹æ§åˆ¶å™¨å®ç°

```go
/*
é€šç”¨æ§åˆ¶å™¨æ¥å£å®šä¹‰
æ‰€æœ‰æ§åˆ¶å™¨éƒ½å®ç°æ­¤æ¥å£ï¼Œæä¾›ç»Ÿä¸€çš„æ§åˆ¶å¾ªç¯æœºåˆ¶
*/
type Controller interface {
    // Run å¯åŠ¨æ§åˆ¶å™¨ï¼Œç›´åˆ° stopCh å…³é—­
    Run(workers int, stopCh <-chan struct{})
    
    // HasSynced è¿”å›æ§åˆ¶å™¨æ˜¯å¦å·²å®Œæˆåˆå§‹åŒæ­¥
    HasSynced() bool
}

/*
æ§åˆ¶å™¨åŸºç¡€ç»“æ„
åŒ…å«å·¥ä½œé˜Ÿåˆ—ã€äº‹ä»¶å¤„ç†å™¨å’ŒåŒæ­¥é€»è¾‘
*/
type BaseController struct {
    // å·¥ä½œé˜Ÿåˆ—ï¼Œå­˜å‚¨å¾…å¤„ç†çš„å¯¹è±¡é”®
    queue workqueue.RateLimitingInterface
    
    // å¯¹è±¡ç´¢å¼•å™¨ï¼Œæä¾›æœ¬åœ°ç¼“å­˜
    indexer cache.Indexer
    
    // äº‹ä»¶é€šçŸ¥å™¨ï¼Œç›‘å¬ API å˜åŒ–
    informer cache.Controller
    
    // åŒæ­¥å¤„ç†å‡½æ•°
    syncHandler func(key string) error
}

/*
æ§åˆ¶å™¨è¿è¡Œé€»è¾‘
å®ç°æ ‡å‡†çš„æ§åˆ¶å¾ªç¯æ¨¡å¼
*/
func (c *BaseController) Run(workers int, stopCh <-chan struct{}) {
    defer utilruntime.HandleCrash()
    defer c.queue.ShutDown()
    
    klog.Info("å¯åŠ¨æ§åˆ¶å™¨")
    
    // å¯åŠ¨ informerï¼Œå¼€å§‹ç›‘å¬ API å˜åŒ–
    go c.informer.Run(stopCh)
    
    // ç­‰å¾…ç¼“å­˜åŒæ­¥å®Œæˆ
    if !cache.WaitForCacheSync(stopCh, c.informer.HasSynced) {
        utilruntime.HandleError(fmt.Errorf("ç­‰å¾…ç¼“å­˜åŒæ­¥è¶…æ—¶"))
        return
    }
    
    // å¯åŠ¨å·¥ä½œåç¨‹
    for i := 0; i < workers; i++ {
        go wait.Until(c.runWorker, time.Second, stopCh)
    }
    
    klog.Info("æ§åˆ¶å™¨å·²å¯åŠ¨")
    <-stopCh
    klog.Info("æ§åˆ¶å™¨æ­£åœ¨å…³é—­")
}

/*
å·¥ä½œåç¨‹é€»è¾‘
ä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡å¹¶å¤„ç†
*/
func (c *BaseController) runWorker() {
    for c.processNextWorkItem() {
    }
}

func (c *BaseController) processNextWorkItem() bool {
    // ä»é˜Ÿåˆ—è·å–ä¸‹ä¸€ä¸ªå·¥ä½œé¡¹
    obj, shutdown := c.queue.Get()
    if shutdown {
        return false
    }
    
    defer c.queue.Done(obj)
    
    var key string
    var ok bool
    
    if key, ok = obj.(string); !ok {
        c.queue.Forget(obj)
        utilruntime.HandleError(fmt.Errorf("æœŸæœ›å­—ç¬¦ä¸²ç±»å‹ï¼Œå¾—åˆ° %#v", obj))
        return true
    }
    
    // æ‰§è¡ŒåŒæ­¥é€»è¾‘
    if err := c.syncHandler(key); err != nil {
        // å¤„ç†å¤±è´¥ï¼Œé‡æ–°å…¥é˜Ÿ
        c.queue.AddRateLimited(key)
        utilruntime.HandleError(fmt.Errorf("åŒæ­¥ '%s' å¤±è´¥: %v", key, err))
        return true
    }
    
    // å¤„ç†æˆåŠŸï¼Œä»é˜Ÿåˆ—ä¸­ç§»é™¤
    c.queue.Forget(obj)
    klog.Infof("æˆåŠŸåŒæ­¥ '%s'", key)
    return true
}
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 5.1 API Server ä¼˜åŒ–

```yaml
# API Server æ€§èƒ½ä¼˜åŒ–é…ç½®
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
spec:
  containers:
  - name: kube-apiserver
    image: k8s.gcr.io/kube-apiserver:v1.29.0
    command:
    - kube-apiserver
    # è¿æ¥æ± ä¼˜åŒ–
    - --max-requests-inflight=400          # å¹¶å‘è¯·æ±‚é™åˆ¶
    - --max-mutating-requests-inflight=200 # å˜æ›´è¯·æ±‚é™åˆ¶
    
    # etcd è¿æ¥ä¼˜åŒ–
    - --etcd-servers-overrides=/events#https://etcd-events:2379  # äº‹ä»¶å­˜å‚¨åˆ†ç¦»
    - --etcd-compaction-interval=300s      # å‹ç¼©é—´éš”
    
    # ç¼“å­˜ä¼˜åŒ–
    - --default-watch-cache-size=100       # Watch ç¼“å­˜å¤§å°
    - --watch-cache-sizes=pods#1000,nodes#100  # åˆ†ç±»ç¼“å­˜å¤§å°
    
    # è®¤è¯ä¼˜åŒ–
    - --enable-bootstrap-token-auth=true   # å¯ç”¨å¼•å¯¼ä»¤ç‰Œ
    - --token-auth-file=/etc/tokens.csv    # ä»¤ç‰Œæ–‡ä»¶è®¤è¯
    
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2Gi
```

### 5.2 etcd ä¼˜åŒ–

```yaml
# etcd æ€§èƒ½ä¼˜åŒ–é…ç½®
apiVersion: v1
kind: Pod
metadata:
  name: etcd
spec:
  containers:
  - name: etcd
    image: k8s.gcr.io/etcd:3.5.9-0
    command:
    - etcd
    # å­˜å‚¨ä¼˜åŒ–
    - --quota-backend-bytes=8589934592     # 8GB å­˜å‚¨é™åˆ¶
    - --auto-compaction-mode=periodic      # è‡ªåŠ¨å‹ç¼©æ¨¡å¼
    - --auto-compaction-retention=300s     # å‹ç¼©ä¿ç•™æ—¶é—´
    
    # ç½‘ç»œä¼˜åŒ–
    - --heartbeat-interval=100             # å¿ƒè·³é—´éš” 100ms
    - --election-timeout=1000              # é€‰ä¸¾è¶…æ—¶ 1s
    
    # å¿«ç…§ä¼˜åŒ–
    - --snapshot-count=10000               # å¿«ç…§è§¦å‘é˜ˆå€¼
    
    # æ—¥å¿—ä¼˜åŒ–
    - --log-level=warn                     # æ—¥å¿—çº§åˆ«
    
    resources:
      requests:
        cpu: 100m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 2Gi
    
    volumeMounts:
    - name: etcd-data
      mountPath: /var/lib/etcd
      
  volumes:
  - name: etcd-data
    hostPath:
      path: /var/lib/etcd
      type: DirectoryOrCreate
```

### 5.3 è°ƒåº¦å™¨ä¼˜åŒ–

```yaml
# è°ƒåº¦å™¨æ€§èƒ½ä¼˜åŒ–é…ç½®
apiVersion: kubescheduler.config.k8s.io/v1beta3
kind: KubeSchedulerConfiguration
profiles:
- schedulerName: default-scheduler
  plugins:
    # å¯ç”¨é«˜æ•ˆæ’ä»¶
    filter:
      enabled:
      - name: NodeResourcesFit
      - name: NodeAffinity
      - name: PodTopologySpread
    score:
      enabled:
      - name: NodeResourcesFit
      - name: NodeAffinity
      - name: PodTopologySpread
  
  # è°ƒåº¦æ€§èƒ½å‚æ•°
  pluginConfig:
  - name: NodeResourcesFit
    args:
      scoringStrategy:
        type: LeastAllocated  # æœ€å°‘åˆ†é…ç­–ç•¥
        
# å¹¶å‘è°ƒåº¦é…ç½®
parallelism: 16              # å¹¶å‘è°ƒåº¦æ•°é‡
percentageOfNodesToScore: 50 # è¯„åˆ†èŠ‚ç‚¹ç™¾åˆ†æ¯”
```

## ğŸ“ˆ ç›‘æ§å’Œå¯è§‚æµ‹æ€§

### 6.1 å…³é”®æŒ‡æ ‡ç›‘æ§

```yaml
# Prometheus ç›‘æ§é…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
    - "kubernetes-rules.yml"
    
    scrape_configs:
    # API Server ç›‘æ§
    - job_name: 'kubernetes-apiservers'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - default
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https
      
    # Kubelet ç›‘æ§
    - job_name: 'kubernetes-nodes'
      kubernetes_sd_configs:
      - role: node
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      
    # Pod ç›‘æ§
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
```

### 6.2 å‘Šè­¦è§„åˆ™

```yaml
# Kubernetes å‘Šè­¦è§„åˆ™
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubernetes-rules
data:
  kubernetes-rules.yml: |
    groups:
    - name: kubernetes-system
      rules:
      # API Server å‘Šè­¦
      - alert: KubernetesAPIServerDown
        expr: up{job="kubernetes-apiservers"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Kubernetes API Server is down"
          description: "API Server has been down for more than 5 minutes"
      
      - alert: KubernetesAPIServerHighLatency
        expr: histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket[5m])) by (le)) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Kubernetes API Server high latency"
          description: "API Server 99th percentile latency is {{ $value }} seconds"
      
      # etcd å‘Šè­¦
      - alert: EtcdClusterDown
        expr: up{job="etcd"} == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "etcd cluster is down"
          description: "etcd cluster has been down for more than 5 minutes"
      
      - alert: EtcdHighLatency
        expr: histogram_quantile(0.99, sum(rate(etcd_disk_wal_fsync_duration_seconds_bucket[5m])) by (le)) > 0.5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "etcd high disk latency"
          description: "etcd disk latency is {{ $value }} seconds"
      
      # èŠ‚ç‚¹å‘Šè­¦
      - alert: KubernetesNodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Kubernetes node not ready"
          description: "Node {{ $labels.node }} has been not ready for more than 5 minutes"
      
      # Pod å‘Šè­¦
      - alert: KubernetesPodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Kubernetes pod crash looping"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
```

## ğŸ›¡ï¸ å®‰å…¨æœ€ä½³å®è·µ

### 7.1 RBAC æƒé™æ§åˆ¶

```yaml
# æœ€å°æƒé™åŸåˆ™çš„ RBAC é…ç½®
---
# æœåŠ¡è´¦æˆ·
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-service-account
  namespace: default

---
# è§’è‰²å®šä¹‰
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: app-role
rules:
# Pod ç›¸å…³æƒé™
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get"]
# ConfigMap æƒé™
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list"]
# Secret æƒé™ï¼ˆåªè¯»ï¼‰
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]

---
# è§’è‰²ç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-role-binding
  namespace: default
subjects:
- kind: ServiceAccount
  name: app-service-account
  namespace: default
roleRef:
  kind: Role
  name: app-role
  apiGroup: rbac.authorization.k8s.io

---
# é›†ç¾¤çº§åˆ«è§’è‰²ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: node-reader
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["metrics.k8s.io"]
  resources: ["nodes", "pods"]
  verbs: ["get", "list"]

---
# é›†ç¾¤è§’è‰²ç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: node-reader-binding
subjects:
- kind: ServiceAccount
  name: monitoring-service-account
  namespace: kube-system
roleRef:
  kind: ClusterRole
  name: node-reader
  apiGroup: rbac.authorization.k8s.io
```

### 7.2 ç½‘ç»œç­–ç•¥

```yaml
# ç½‘ç»œéš”ç¦»ç­–ç•¥
---
# é»˜è®¤æ‹’ç»æ‰€æœ‰æµé‡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
# å…è®¸ç‰¹å®šåº”ç”¨é—´é€šä¿¡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 8080

---
# å…è®¸è®¿é—®å¤–éƒ¨æœåŠ¡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-external-access
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: web-app
  policyTypes:
  - Egress
  egress:
  # å…è®¸ DNS æŸ¥è¯¢
  - to: []
    ports:
    - protocol: UDP
      port: 53
  # å…è®¸ HTTPS è®¿é—®
  - to: []
    ports:
    - protocol: TCP
      port: 443
  # å…è®¸è®¿é—®ç‰¹å®šå¤–éƒ¨æœåŠ¡
  - to:
    - namespaceSelector:
        matchLabels:
          name: external-services
    ports:
    - protocol: TCP
      port: 80
```

### 7.3 Pod å®‰å…¨ç­–ç•¥

```yaml
# Pod å®‰å…¨æ ‡å‡†é…ç½®
apiVersion: v1
kind: Namespace
metadata:
  name: secure-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted

---
# å®‰å…¨çš„ Pod é…ç½®ç¤ºä¾‹
apiVersion: v1
kind: Pod
metadata:
  name: secure-pod
  namespace: secure-namespace
spec:
  serviceAccountName: limited-service-account
  
  # å®‰å…¨ä¸Šä¸‹æ–‡
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault
  
  containers:
  - name: app
    image: nginx:1.21-alpine
    
    # å®¹å™¨å®‰å…¨ä¸Šä¸‹æ–‡
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      runAsUser: 1000
      capabilities:
        drop:
        - ALL
    
    # èµ„æºé™åˆ¶
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi
    
    # åªè¯»æ ¹æ–‡ä»¶ç³»ç»Ÿéœ€è¦ä¸´æ—¶ç›®å½•
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-cache-nginx
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  
  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-cache-nginx
    emptyDir: {}
  - name: var-run
    emptyDir: {}
```

## ğŸ“š æ€»ç»“

Kubernetes ä½œä¸ºç°ä»£å®¹å™¨ç¼–æ’å¹³å°ï¼Œå…¶æ¶æ„è®¾è®¡ä½“ç°äº†ä»¥ä¸‹æ ¸å¿ƒç†å¿µï¼š

### è®¾è®¡åŸåˆ™
1. **å£°æ˜å¼ç®¡ç†**ï¼šç”¨æˆ·å£°æ˜æœŸæœ›çŠ¶æ€ï¼Œç³»ç»Ÿè‡ªåŠ¨ç»´æŠ¤
2. **æ§åˆ¶å™¨æ¨¡å¼**ï¼šé€šè¿‡æ§åˆ¶å¾ªç¯å®ç°çŠ¶æ€åè°ƒ
3. **API é©±åŠ¨**ï¼šæ‰€æœ‰æ“ä½œé€šè¿‡ç»Ÿä¸€çš„ REST API
4. **æ’ä»¶åŒ–æ¶æ„**ï¼šæ”¯æŒæ‰©å±•å’Œå®šåˆ¶åŒ–
5. **åˆ†å¸ƒå¼è®¾è®¡**ï¼šé«˜å¯ç”¨å’Œå¯æ‰©å±•æ€§

### æ ¸å¿ƒä¼˜åŠ¿
1. **è‡ªåŠ¨åŒ–è¿ç»´**ï¼šè‡ªåŠ¨å¤„ç†æ•…éšœæ¢å¤å’Œæ‰©ç¼©å®¹
2. **èµ„æºæŠ½è±¡**ï¼šæä¾›ç»Ÿä¸€çš„èµ„æºç®¡ç†æ¥å£
3. **ç”Ÿæ€ä¸°å¯Œ**ï¼šåºå¤§çš„äº‘åŸç”Ÿç”Ÿæ€ç³»ç»Ÿ
4. **æ ‡å‡†åŒ–**ï¼šCNCF æ ‡å‡†ï¼Œå‚å•†ä¸­ç«‹
5. **å¯ç§»æ¤æ€§**ï¼šè·¨äº‘ã€è·¨å¹³å°éƒ¨ç½²

### æœ€ä½³å®è·µ
1. **å®‰å…¨ä¼˜å…ˆ**ï¼šå®æ–½æœ€å°æƒé™åŸåˆ™å’Œç½‘ç»œéš”ç¦»
2. **ç›‘æ§å®Œå–„**ï¼šå»ºç«‹å…¨é¢çš„ç›‘æ§å’Œå‘Šè­¦ä½“ç³»
3. **èµ„æºç®¡ç†**ï¼šåˆç†è®¾ç½®èµ„æºè¯·æ±‚å’Œé™åˆ¶
4. **é«˜å¯ç”¨è®¾è®¡**ï¼šå¤šå‰¯æœ¬å’Œè·¨åŒºåŸŸéƒ¨ç½²
5. **æŒç»­ä¼˜åŒ–**ï¼šå®šæœŸè¯„ä¼°å’Œä¼˜åŒ–æ€§èƒ½

é€šè¿‡æ·±å…¥ç†è§£ Kubernetes çš„æ¶æ„è®¾è®¡å’Œæºç å®ç°ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°è¿ç”¨è¿™ä¸ªå¼ºå¤§çš„å¹³å°ï¼Œæ„å»ºç¨³å®šã€é«˜æ•ˆã€å®‰å…¨çš„äº‘åŸç”Ÿåº”ç”¨ç³»ç»Ÿã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´09æœˆ27æ—¥  
**é€‚ç”¨ç‰ˆæœ¬**: Kubernetes 1.29+
