#!/usr/bin/env python3
"""
ä¸ºç¼ºå°‘ Front Matter çš„ Markdown æ–‡ä»¶æ·»åŠ  YAML Front Matter
è‡ªåŠ¨ä»æ ‡é¢˜æå–ä¿¡æ¯å¹¶ç”Ÿæˆåˆé€‚çš„å…ƒæ•°æ®
"""

import re
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional


def extract_info_from_content(content: str, filename: str) -> Dict:
    """ä»å†…å®¹å’Œæ–‡ä»¶åä¸­æå–ä¿¡æ¯"""
    
    # æå–ç¬¬ä¸€ä¸ªæ ‡é¢˜ä½œä¸º title
    title_match = re.search(r'^#\s+(.+?)$', content, re.MULTILINE)
    if title_match:
        title = title_match.group(1).strip()
    else:
        # ä»æ–‡ä»¶åç”Ÿæˆ title
        title = filename.replace('.md', '').replace('-', ' ')
    
    # ä»æ–‡ä»¶åæå–é¡¹ç›®å’Œæ¨¡å—ä¿¡æ¯
    filename_lower = filename.lower()
    
    # é¡¹ç›®æ˜ å°„
    project_map = {
        'autogpt': 'AutoGPT',
        'dify': 'Dify',
        'docker': 'Docker',
        'eino': 'Eino',
        'elasticsearch': 'Elasticsearch',
        'etcd': 'etcd',
        'fastapi': 'FastAPI',
        'go': 'Go',
        'grpc-go': 'gRPC-Go',
        'kafka': 'Apache Kafka',
        'kitex': 'Kitex',
        'kubernetes': 'Kubernetes',
        'langchain': 'LangChain',
        'langgraph': 'LangGraph',
        'milvus': 'Milvus',
        'nginx': 'Nginx',
        'openaiagent': 'OpenAI Agent',
        'pgvector': 'pgvector',
        'rocksdb': 'RocksDB',
    }
    
    # åˆ†ç±»æ˜ å°„
    category_map = {
        'autogpt': ['AutoGPT', 'AIåº”ç”¨å¼€å‘'],
        'dify': ['Dify', 'AIåº”ç”¨å¼€å‘'],
        'docker': ['Docker', 'å®¹å™¨æŠ€æœ¯'],
        'eino': ['Eino', 'AIæ¡†æ¶', 'Go'],
        'elasticsearch': ['Elasticsearch', 'æœç´¢å¼•æ“', 'åˆ†å¸ƒå¼ç³»ç»Ÿ'],
        'etcd': ['etcd', 'åˆ†å¸ƒå¼ç³»ç»Ÿ', 'é”®å€¼å­˜å‚¨'],
        'fastapi': ['FastAPI', 'Python', 'Webæ¡†æ¶'],
        'go': ['Go', 'ç¼–ç¨‹è¯­è¨€', 'è¿è¡Œæ—¶'],
        'grpc-go': ['gRPC', 'Go', 'RPCæ¡†æ¶'],
        'kafka': ['Kafka', 'æ¶ˆæ¯é˜Ÿåˆ—', 'åˆ†å¸ƒå¼ç³»ç»Ÿ'],
        'kitex': ['Kitex', 'Go', 'RPCæ¡†æ¶'],
        'kubernetes': ['Kubernetes', 'å®¹å™¨ç¼–æ’', 'äº‘åŸç”Ÿ'],
        'langchain': ['LangChain', 'AIæ¡†æ¶', 'Python'],
        'langgraph': ['LangGraph', 'AIæ¡†æ¶', 'Python'],
        'milvus': ['Milvus', 'å‘é‡æ•°æ®åº“', 'åˆ†å¸ƒå¼ç³»ç»Ÿ'],
        'nginx': ['Nginx', 'WebæœåŠ¡å™¨', 'C'],
        'openaiagent': ['OpenAI', 'AI Agent', 'Python'],
        'pgvector': ['PostgreSQL', 'å‘é‡æ£€ç´¢', 'æ•°æ®åº“'],
        'rocksdb': ['RocksDB', 'å­˜å‚¨å¼•æ“', 'C++'],
    }
    
    # æ ‡ç­¾ç”Ÿæˆ
    tags = []
    categories = []
    project_name = ''
    
    for key, name in project_map.items():
        if key in filename_lower:
            project_name = name
            tags.append(name)
            categories = category_map.get(key, [name])
            break
    
    # æ ¹æ®æ–‡ä»¶åæ·»åŠ æ›´å¤šæ ‡ç­¾
    if 'api' in filename_lower:
        tags.extend(['APIè®¾è®¡', 'æ¥å£æ–‡æ¡£'])
    if 'æ•°æ®ç»“æ„' in filename or 'datastructure' in filename_lower:
        tags.extend(['æ•°æ®ç»“æ„', 'UML'])
    if 'æ—¶åºå›¾' in filename or 'sequence' in filename_lower:
        tags.extend(['æ—¶åºå›¾', 'æµç¨‹åˆ†æ'])
    if 'æ¦‚è§ˆ' in filename or 'overview' in filename_lower:
        tags.extend(['æ¶æ„è®¾è®¡', 'æ¦‚è§ˆ'])
    if 'æ€»è§ˆ' in filename:
        tags.extend(['æºç å‰–æ', 'æ¶æ„åˆ†æ'])
    if 'æœ€ä½³å®è·µ' in filename or 'best-practice' in filename_lower:
        tags.extend(['æœ€ä½³å®è·µ', 'å®æˆ˜ç»éªŒ'])
    
    # æ·»åŠ "æºç åˆ†æ"æ ‡ç­¾
    tags.append('æºç åˆ†æ')
    
    # å»é‡
    tags = list(dict.fromkeys(tags))  # ä¿æŒé¡ºåºå»é‡
    
    # ç”Ÿæˆæè¿°
    description = f"{project_name} æºç å‰–æ - {title}" if project_name else f"æºç å‰–æ - {title}"
    
    # ç¡®å®š series
    series = None
    if project_name:
        series = f"{project_name.lower()}-source-analysis"
    
    return {
        'title': title,
        'date': datetime.now().strftime('%Y-%m-%dT%H:%M:%S+08:00'),
        'draft': False,
        'tags': tags[:8],  # æœ€å¤š 8 ä¸ªæ ‡ç­¾
        'categories': categories[:3] if categories else [project_name] if project_name else ['æŠ€æœ¯æ–‡æ¡£'],
        'series': series,
        'description': description,
        'author': 'æºç åˆ†æ',
        'weight': 500,
        'ShowToc': True,
        'TocOpen': True,
    }


def generate_front_matter(info: Dict) -> str:
    """ç”Ÿæˆ YAML Front Matter"""
    fm_lines = ['---']
    
    # åŸºæœ¬å­—æ®µ
    fm_lines.append(f'title: "{info["title"]}"')
    fm_lines.append(f'date: {info["date"]}')
    fm_lines.append(f'draft: {str(info["draft"]).lower()}')
    
    # æ ‡ç­¾
    if info['tags']:
        fm_lines.append('tags:')
        for tag in info['tags']:
            fm_lines.append(f'  - {tag}')
    
    # åˆ†ç±»
    if info['categories']:
        fm_lines.append('categories:')
        for cat in info['categories']:
            fm_lines.append(f'  - {cat}')
    
    # ç³»åˆ—
    if info.get('series'):
        fm_lines.append(f'series: "{info["series"]}"')
    
    # å…¶ä»–å­—æ®µ
    fm_lines.append(f'description: "{info["description"]}"')
    fm_lines.append(f'author: "{info["author"]}"')
    fm_lines.append(f'weight: {info["weight"]}')
    fm_lines.append(f'ShowToc: {str(info["ShowToc"]).lower()}')
    fm_lines.append(f'TocOpen: {str(info["TocOpen"]).lower()}')
    
    fm_lines.append('---')
    return '\n'.join(fm_lines)


def add_front_matter(file_path: Path, dry_run: bool = False) -> bool:
    """ä¸ºæ–‡ä»¶æ·»åŠ  Front Matter"""
    try:
        content = file_path.read_text(encoding='utf-8')
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ Front Matter
        if content.startswith('---'):
            return False
        
        # æå–ä¿¡æ¯
        info = extract_info_from_content(content, file_path.name)
        
        # ç”Ÿæˆ Front Matter
        front_matter = generate_front_matter(info)
        
        # ç»„åˆæ–°å†…å®¹
        new_content = front_matter + '\n\n' + content
        
        if not dry_run:
            file_path.write_text(new_content, encoding='utf-8')
        
        return True
    
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥ {file_path.name}: {e}", file=sys.stderr)
        return False


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸º Markdown æ–‡ä»¶æ·»åŠ  Front Matter')
    parser.add_argument('path', type=str, help='è¦å¤„ç†çš„ç›®å½•è·¯å¾„')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶')
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    args = parser.parse_args()
    
    path = Path(args.path)
    if not path.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}", file=sys.stderr)
        sys.exit(1)
    
    # æ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶
    md_files = sorted(path.rglob('*.md'))
    
    print(f"ğŸ” æ£€æŸ¥ {len(md_files)} ä¸ª Markdown æ–‡ä»¶")
    
    if args.dry_run:
        print("ğŸ”§ è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸ä¼šä¿®æ”¹æ–‡ä»¶ï¼‰\n")
    else:
        print("ğŸ”§ å¼€å§‹æ·»åŠ  Front Matter\n")
    
    modified_count = 0
    skipped_count = 0
    
    for file_path in md_files:
        # è¯»å–å‰å‡ è¡Œæ£€æŸ¥
        try:
            content = file_path.read_text(encoding='utf-8')
            if content.startswith('---'):
                skipped_count += 1
                if args.verbose:
                    print(f"â­ï¸  è·³è¿‡ï¼ˆå·²æœ‰ Front Matterï¼‰: {file_path.name}")
                continue
        except:
            continue
        
        if add_front_matter(file_path, args.dry_run):
            modified_count += 1
            print(f"âœ… {file_path.name}")
            
            if args.verbose:
                # æ˜¾ç¤ºç”Ÿæˆçš„ä¿¡æ¯
                info = extract_info_from_content(content, file_path.name)
                print(f"   æ ‡é¢˜: {info['title']}")
                print(f"   åˆ†ç±»: {', '.join(info['categories'])}")
                print(f"   æ ‡ç­¾: {', '.join(info['tags'][:5])}...")
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“Š å¤„ç†æ‘˜è¦")
    print("="*80)
    print(f"æ£€æŸ¥æ–‡ä»¶æ•°:    {len(md_files)}")
    print(f"âœ… å·²æ·»åŠ :     {modified_count}")
    print(f"â­ï¸  å·²è·³è¿‡:     {skipped_count}")
    print("="*80)
    
    if args.dry_run:
        print("\nğŸ’¡ ä½¿ç”¨ä¸å¸¦ --dry-run å‚æ•°è¿è¡Œä»¥å®é™…ä¿®æ”¹æ–‡ä»¶")
    else:
        print(f"\nâœ… æˆåŠŸä¸º {modified_count} ä¸ªæ–‡ä»¶æ·»åŠ  Front Matter")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())

