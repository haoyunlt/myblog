#!/usr/bin/env python3
"""
åˆå¹¶é¡¹ç›®æ–‡æ¡£è„šæœ¬
å°†æ¯ä¸ªé¡¹ç›®-æ¨¡å—çš„æ¦‚è§ˆã€APIã€æ•°æ®ç»“æ„ã€æ—¶åºå›¾åˆå¹¶æˆä¸€ä¸ªæ–‡æ¡£
"""
import os
import re
from pathlib import Path
from collections import defaultdict
from datetime import datetime

# é…ç½®
POSTS_DIR = Path(__file__).parent.parent / "content" / "posts"
BACKUP_DIR = Path(__file__).parent.parent / "content" / "posts_backup"

# æ–‡æ¡£ç±»å‹æ˜ å°„
DOC_TYPES = {
    "æ¦‚è§ˆ": {"order": 1, "section_title": "## æ¨¡å—æ¦‚è§ˆ"},
    "API": {"order": 2, "section_title": "## APIæ¥å£"},
    "æ•°æ®ç»“æ„": {"order": 3, "section_title": "## æ•°æ®ç»“æ„"},
    "æ—¶åºå›¾": {"order": 4, "section_title": "## æ—¶åºå›¾"},
}


def parse_filename(filename):
    """
    è§£ææ–‡ä»¶åï¼Œè¯†åˆ«é¡¹ç›®åã€æ¨¡å—åã€æ–‡æ¡£ç±»å‹
    
    æ”¯æŒçš„æ¨¡å¼ï¼š
    - é¡¹ç›®å-åºå·-æ¨¡å—å-æ–‡æ¡£ç±»å‹.md
    - é¡¹ç›®å-æ¨¡å—å-æ–‡æ¡£ç±»å‹.md
    
    è¿”å›: (project, module, doc_type) æˆ– None
    """
    # ç§»é™¤.mdåç¼€
    name = filename.replace(".md", "")
    
    # è·³è¿‡ç‰¹æ®Šæ–‡æ¡£
    if name.endswith("-00-æ€»è§ˆ") or name.endswith("-æ€»è§ˆ") or name == "00-æ€»è§ˆ":
        return None
    
    # æ¨¡å¼1: é¡¹ç›®å-åºå·-æ¨¡å—å-æ–‡æ¡£ç±»å‹
    pattern1 = r"^(.+?)-(\d{2})-(.+?)-(æ¦‚è§ˆ|API|æ•°æ®ç»“æ„|æ—¶åºå›¾)$"
    match = re.match(pattern1, name)
    if match:
        project, seq, module, doc_type = match.groups()
        return (project, f"{seq}-{module}", doc_type)
    
    # æ¨¡å¼2: é¡¹ç›®å-æ¨¡å—å-æ–‡æ¡£ç±»å‹ (æ— åºå·)
    pattern2 = r"^(.+?)-(.+?)-(æ¦‚è§ˆ|API|æ•°æ®ç»“æ„|æ—¶åºå›¾)$"
    match = re.match(pattern2, name)
    if match:
        project, module, doc_type = match.groups()
        # è·³è¿‡å·²çŸ¥çš„æ€»è§ˆæ–‡æ¡£
        if module in ["00-æ€»è§ˆ", "æ€»è§ˆ"]:
            return None
        return (project, module, doc_type)
    
    return None


def read_markdown_file(filepath):
    """è¯»å–markdownæ–‡ä»¶ï¼Œè¿”å›front matterå’Œcontent"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åˆ†ç¦»front matterå’Œæ­£æ–‡
    parts = content.split("---\n", 2)
    if len(parts) >= 3 and parts[0] == "":
        front_matter = parts[1]
        body = parts[2]
    else:
        front_matter = ""
        body = content
    
    return front_matter, body


def extract_body_content(body):
    """æå–æ­£æ–‡å†…å®¹ï¼Œè·³è¿‡ç¬¬ä¸€ä¸ªæ ‡é¢˜ï¼ˆå› ä¸ºä¼šé‡æ–°ç”Ÿæˆï¼‰"""
    lines = body.split("\n")
    
    # è·³è¿‡ç¬¬ä¸€ä¸ª # æ ‡é¢˜
    result_lines = []
    found_first_title = False
    
    for line in lines:
        if not found_first_title and line.startswith("# "):
            found_first_title = True
            continue
        if found_first_title:
            result_lines.append(line)
    
    return "\n".join(result_lines).strip()


def merge_documents(project, module, docs):
    """åˆå¹¶å•ä¸ªæ¨¡å—çš„æ‰€æœ‰æ–‡æ¡£"""
    
    # æŒ‰æ–‡æ¡£ç±»å‹æ’åº
    sorted_docs = sorted(
        docs.items(),
        key=lambda x: DOC_TYPES.get(x[0], {"order": 99})["order"]
    )
    
    # è·å–ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„front matterä½œä¸ºåŸºç¡€
    first_filepath = sorted_docs[0][1]
    front_matter, _ = read_markdown_file(first_filepath)
    
    # ä¿®æ”¹front matter
    front_matter_lines = front_matter.split("\n")
    new_front_matter = []
    
    for line in front_matter_lines:
        if line.startswith("title:"):
            # ç§»é™¤åŸæ ‡é¢˜ä¸­çš„æ–‡æ¡£ç±»å‹åç¼€
            new_front_matter.append(f'title: "{project}-{module}"')
        elif line.startswith("date:"):
            new_front_matter.append(f"date: {datetime.now().strftime('%Y-%m-%dT%H:%M:%S+08:00')}")
        elif line.startswith("description:"):
            new_front_matter.append(f'description: "{project} æºç å‰–æ - {module}"')
        elif line.startswith("author:"):
            new_front_matter.append(f'author: "æºç åˆ†æ"')
        else:
            new_front_matter.append(line)
    
    # æ„å»ºåˆå¹¶åçš„å†…å®¹
    merged_content = []
    merged_content.append("---")
    merged_content.append("\n".join(new_front_matter))
    merged_content.append("---")
    merged_content.append("")
    merged_content.append(f"# {project}-{module}")
    merged_content.append("")
    
    # æ·»åŠ å„ä¸ªç« èŠ‚
    for doc_type, filepath in sorted_docs:
        section_title = DOC_TYPES.get(doc_type, {}).get("section_title", f"## {doc_type}")
        _, body = read_markdown_file(filepath)
        content = extract_body_content(body)
        
        merged_content.append(section_title)
        merged_content.append("")
        merged_content.append(content)
        merged_content.append("")
        merged_content.append("---")
        merged_content.append("")
    
    return "\n".join(merged_content)


def main():
    print("ğŸ“š å¼€å§‹æ‰«ææ–‡æ¡£ç›®å½•...")
    
    # æ‰«ææ‰€æœ‰æ–‡æ¡£
    docs_map = defaultdict(lambda: defaultdict(dict))
    
    for filepath in POSTS_DIR.glob("*.md"):
        parsed = parse_filename(filepath.name)
        if parsed:
            project, module, doc_type = parsed
            docs_map[project][module][doc_type] = filepath
    
    print(f"âœ… æ‰¾åˆ° {len(docs_map)} ä¸ªé¡¹ç›®")
    
    # ç»Ÿè®¡éœ€è¦åˆå¹¶çš„æ¨¡å—
    merge_count = 0
    for project, modules in docs_map.items():
        for module, docs in modules.items():
            if len(docs) > 1:
                merge_count += 1
    
    print(f"ğŸ“ éœ€è¦åˆå¹¶ {merge_count} ä¸ªæ¨¡å—")
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    if not BACKUP_DIR.exists():
        BACKUP_DIR.mkdir(parents=True)
        print(f"ğŸ“ åˆ›å»ºå¤‡ä»½ç›®å½•: {BACKUP_DIR}")
    
    # åˆå¹¶æ–‡æ¡£
    merged_files = []
    deleted_files = []
    
    for project, modules in sorted(docs_map.items()):
        for module, docs in sorted(modules.items()):
            if len(docs) <= 1:
                continue
            
            print(f"\nğŸ”„ åˆå¹¶ {project}-{module}...")
            print(f"   åŒ…å«æ–‡æ¡£ç±»å‹: {', '.join(docs.keys())}")
            
            # ç”Ÿæˆåˆå¹¶åçš„å†…å®¹
            merged_content = merge_documents(project, module, docs)
            
            # å†™å…¥æ–°æ–‡ä»¶
            output_filename = f"{project}-{module}.md"
            output_filepath = POSTS_DIR / output_filename
            
            with open(output_filepath, 'w', encoding='utf-8') as f:
                f.write(merged_content)
            
            merged_files.append(output_filename)
            print(f"   âœ… ç”Ÿæˆåˆå¹¶æ–‡æ¡£: {output_filename}")
            
            # å¤‡ä»½å¹¶åˆ é™¤åŸæ–‡ä»¶
            for doc_type, filepath in docs.items():
                backup_path = BACKUP_DIR / filepath.name
                filepath.rename(backup_path)
                deleted_files.append(filepath.name)
                print(f"   ğŸ—‘ï¸  å¤‡ä»½åŸæ–‡ä»¶: {filepath.name} -> {backup_path.name}")
    
    # æ€»ç»“
    print("\n" + "="*70)
    print(f"âœ¨ åˆå¹¶å®Œæˆï¼")
    print(f"   - ç”Ÿæˆåˆå¹¶æ–‡æ¡£: {len(merged_files)} ä¸ª")
    print(f"   - å¤‡ä»½åŸæ–‡ä»¶: {len(deleted_files)} ä¸ª")
    print(f"   - å¤‡ä»½ä½ç½®: {BACKUP_DIR}")
    print("="*70)
    
    if merged_files:
        print("\nç”Ÿæˆçš„åˆå¹¶æ–‡æ¡£åˆ—è¡¨ï¼š")
        for filename in sorted(merged_files):
            print(f"  - {filename}")


if __name__ == "__main__":
    main()

